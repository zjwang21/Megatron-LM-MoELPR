W1020 05:04:00.544870 140340654527424 torch/distributed/run.py:757] 
W1020 05:04:00.544870 140340654527424 torch/distributed/run.py:757] *****************************************
W1020 05:04:00.544870 140340654527424 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1020 05:04:00.544870 140340654527424 torch/distributed/run.py:757] *****************************************
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
using world size: 8, data-parallel size: 8, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0
WARNING: overriding default arguments for no_load_rng:True                        with no_load_rng:True
WARNING: overriding default arguments for no_load_optim:True                        with no_load_optim:True
WARNING: overriding default arguments for micro_batch_size:1                        with micro_batch_size:4
WARNING: overriding default arguments for exit_on_missing_checkpoint:True                        with exit_on_missing_checkpoint:False
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adaptive_seq_len ................................ True
  add_bias_linear ................................. False
  add_position_embedding .......................... False
  add_qkv_bias .................................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... False
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.0
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ False
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  bsz ............................................. 12
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/root/work/huangxin/nanda/Megatron-LM/llamamoe/data/data-bin/elhutr_qwen2.5_30b_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... True
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 1000000
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  enable_shared_expert ............................ True
  encoder_num_layers .............................. 36
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 2048
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1000
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 4
  ffn_hidden_size ................................. 11008
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 1024
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... True
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.0
  hidden_size ..................................... 2048
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-init-experts-exp12-TP1PP1EP4
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 5e-05
  lr_decay_iters .................................. 5000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 300
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 32768
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.001
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_ffn_hidden_size ............................. 2752
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_lpr_loss_coeff .............................. 0.001
  moe_lpr_stage ................................... 1
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 4
  moe_token_dispatcher_type ....................... alltoall
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  moelpr_train_embeddings ......................... False
  nccl_communicator_config_path ................... None
  no_load_optim ................................... True
  no_load_rng ..................................... True
  no_persist_layer_norm ........................... False
  no_save_optim ................................... True
  no_save_rng ..................................... True
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... RMSNorm
  num_attention_heads ............................. 16
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... 12
  num_fewshot ..................................... 10
  num_layers ...................................... 36
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 2
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. True
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ True
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... rope
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  results_path .................................... /root/work/huangxin/nanda/Megatron-LM/llamamoe/eval/results/mcore_qwen2.5-3B-instruct-init-experst-nonzero-share-12exp-hellaswag_long.json
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 1000000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-init-experts-exp12-TP1PP1EP4
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 99990,8,2
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... True
  swin_backbone_type .............................. tiny
  task_list ....................................... hellaswag_hu,hellaswag_el
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. /root/work/huangxin/nanda/models/Qwen/Qwen2.5-3B-Instruct
  tokenizer_type .................................. HuggingFaceTokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 5000
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. True
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... None
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
  zero_expert_down_proj ........................... False
-------------------- end of arguments ---------------------
> building HuggingFaceTokenizer tokenizer ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
 > padded vocab (size: 151936) with 0 dummy tokens (new size: 151936)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.023 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.011 seconds
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
building GPT model ...
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
GPTModel(
  (embedding): LanguageModelEmbedding(
    (word_embeddings): VocabParallelEmbedding()
    (embedding_dropout): Dropout(p=0.0, inplace=False)
  )
  (rotary_pos_emb): RotaryEmbedding()
  (decoder): TransformerBlock(
    (layers): ModuleList(
      (0-35): 36 x TransformerLayer(
        (input_layernorm): IdentityOp()
        (self_attention): SelfAttention(
          (core_attention): TEDotProductAttention(
            (flash_attention): FlashAttention()
            (fused_attention): FusedAttention()
            (unfused_attention): UnfusedDotProductAttention(
              (scale_mask_softmax): FusedScaleMaskSoftmax()
              (attention_dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (linear_proj): TERowParallelLinear()
          (linear_qkv): TELayerNormColumnParallelLinear()
          (q_layernorm): IdentityOp()
          (k_layernorm): IdentityOp()
        )
        (pre_cross_attn_layernorm): IdentityOp()
        (cross_attention): IdentityOp()
        (cross_attn_bda): IdentityFuncOp()
        (pre_mlp_layernorm): RMSNorm()
        (mlp): MoELayer(
          (router): TopKRouter()
          (shared_expert_gate): LanguageRouter()
          (shared_expert): MLP(
            (linear_fc1): ColumnParallelLinear()
            (linear_fc2): RowParallelLinear()
          )
          (experts): SequentialMLP(
            (local_experts): ModuleList(
              (0-2): 3 x MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
            )
          )
        )
      )
    )
    (final_layernorm): RMSNorm()
  )
  (output_layer): ColumnParallelLinear()
)
Fine-tuning method: MoE-LPR stage 1
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[Rank 5] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 0] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 6] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 2] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 3] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 4913065984
[Rank 4] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 1] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 7] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
 loading checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-init-experts-exp12-TP1PP1EP4 at iteration 12000
 checkpoint version 3.0
  successfully loaded checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-init-experts-exp12-TP1PP1EP4 [ t 0, p 0 ] at iteration 12000
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
  0%|          | 0/9572 [00:00<?, ?it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  0%|          | 12/9572 [00:17<3:46:25,  1.42s/it]  0%|          | 24/9572 [00:27<2:55:06,  1.10s/it]  0%|          | 36/9572 [00:38<2:39:08,  1.00s/it]  1%|          | 48/9572 [00:48<2:30:03,  1.06it/s]  1%|          | 60/9572 [00:58<2:25:00,  1.09it/s]  1%|          | 72/9572 [01:09<2:22:26,  1.11it/s]  1%|          | 84/9572 [01:19<2:20:39,  1.12it/s]  1%|          | 96/9572 [01:29<2:18:37,  1.14it/s]  1%|          | 108/9572 [01:40<2:18:25,  1.14it/s]  1%|▏         | 120/9572 [01:50<2:16:53,  1.15it/s]  1%|▏         | 132/9572 [02:01<2:16:43,  1.15it/s]  2%|▏         | 144/9572 [02:11<2:16:38,  1.15it/s]  2%|▏         | 156/9572 [02:22<2:16:53,  1.15it/s]  2%|▏         | 168/9572 [02:32<2:16:00,  1.15it/s]  2%|▏         | 180/9572 [02:42<2:16:15,  1.15it/s]  2%|▏         | 192/9572 [02:53<2:15:57,  1.15it/s]  2%|▏         | 204/9572 [03:03<2:16:22,  1.14it/s]  2%|▏         | 216/9572 [03:14<2:15:43,  1.15it/s]  2%|▏         | 228/9572 [03:24<2:15:55,  1.15it/s]  3%|▎         | 240/9572 [03:34<2:14:45,  1.15it/s]  3%|▎         | 252/9572 [03:45<2:15:01,  1.15it/s]  3%|▎         | 264/9572 [03:55<2:14:25,  1.15it/s]  3%|▎         | 276/9572 [04:06<2:14:29,  1.15it/s]  3%|▎         | 288/9572 [04:16<2:13:28,  1.16it/s]  3%|▎         | 300/9572 [04:26<2:13:51,  1.15it/s]  3%|▎         | 312/9572 [04:37<2:13:11,  1.16it/s]  3%|▎         | 324/9572 [04:47<2:13:05,  1.16it/s]  4%|▎         | 336/9572 [04:57<2:12:40,  1.16it/s]  4%|▎         | 348/9572 [05:08<2:12:34,  1.16it/s]  4%|▍         | 360/9572 [05:18<2:11:54,  1.16it/s]  4%|▍         | 372/9572 [05:28<2:12:20,  1.16it/s]  4%|▍         | 384/9572 [05:39<2:11:25,  1.17it/s]  4%|▍         | 396/9572 [05:49<2:11:49,  1.16it/s]  4%|▍         | 408/9572 [05:59<2:11:10,  1.16it/s]  4%|▍         | 420/9572 [06:10<2:11:22,  1.16it/s]  5%|▍         | 432/9572 [06:20<2:11:04,  1.16it/s]  5%|▍         | 444/9572 [06:30<2:11:06,  1.16it/s]  5%|▍         | 456/9572 [06:41<2:10:33,  1.16it/s]  5%|▍         | 468/9572 [06:51<2:10:52,  1.16it/s]  5%|▌         | 480/9572 [07:01<2:10:34,  1.16it/s]  5%|▌         | 492/9572 [07:12<2:10:52,  1.16it/s]  5%|▌         | 504/9572 [07:22<2:10:11,  1.16it/s]  5%|▌         | 516/9572 [07:33<2:10:38,  1.16it/s]  6%|▌         | 528/9572 [07:43<2:10:16,  1.16it/s]  6%|▌         | 540/9572 [07:53<2:10:40,  1.15it/s]  6%|▌         | 552/9572 [08:04<2:10:22,  1.15it/s]  6%|▌         | 564/9572 [08:14<2:09:54,  1.16it/s]  6%|▌         | 576/9572 [08:25<2:10:12,  1.15it/s]  6%|▌         | 588/9572 [08:35<2:10:01,  1.15it/s]  6%|▋         | 600/9572 [08:45<2:09:42,  1.15it/s]  6%|▋         | 612/9572 [08:56<2:09:31,  1.15it/s]  7%|▋         | 624/9572 [09:06<2:09:15,  1.15it/s]  7%|▋         | 636/9572 [09:17<2:09:08,  1.15it/s]  7%|▋         | 648/9572 [09:27<2:09:09,  1.15it/s]  7%|▋         | 660/9572 [09:38<2:09:00,  1.15it/s]  7%|▋         | 672/9572 [09:48<2:08:29,  1.15it/s]  7%|▋         | 684/9572 [09:58<2:08:31,  1.15it/s]  7%|▋         | 696/9572 [10:09<2:07:58,  1.16it/s]  7%|▋         | 708/9572 [10:19<2:07:48,  1.16it/s]  8%|▊         | 720/9572 [10:29<2:07:44,  1.15it/s]  8%|▊         | 732/9572 [10:40<2:07:06,  1.16it/s]  8%|▊         | 744/9572 [10:50<2:07:07,  1.16it/s]  8%|▊         | 756/9572 [11:01<2:07:43,  1.15it/s]  8%|▊         | 768/9572 [11:11<2:07:34,  1.15it/s]  8%|▊         | 780/9572 [11:22<2:07:24,  1.15it/s]  8%|▊         | 792/9572 [11:32<2:06:57,  1.15it/s]  8%|▊         | 804/9572 [11:42<2:06:32,  1.15it/s]  9%|▊         | 816/9572 [11:53<2:07:04,  1.15it/s]  9%|▊         | 828/9572 [12:03<2:06:52,  1.15it/s]  9%|▉         | 840/9572 [12:14<2:06:35,  1.15it/s]  9%|▉         | 852/9572 [12:24<2:06:10,  1.15it/s]  9%|▉         | 864/9572 [12:35<2:06:15,  1.15it/s]  9%|▉         | 876/9572 [12:45<2:05:49,  1.15it/s]  9%|▉         | 888/9572 [12:55<2:05:32,  1.15it/s]  9%|▉         | 900/9572 [13:06<2:05:18,  1.15it/s] 10%|▉         | 912/9572 [13:16<2:05:00,  1.15it/s] 10%|▉         | 924/9572 [13:27<2:04:57,  1.15it/s] 10%|▉         | 936/9572 [13:37<2:04:45,  1.15it/s] 10%|▉         | 948/9572 [13:47<2:04:39,  1.15it/s] 10%|█         | 960/9572 [13:58<2:04:25,  1.15it/s] 10%|█         | 972/9572 [14:08<2:04:11,  1.15it/s] 10%|█         | 984/9572 [14:19<2:04:23,  1.15it/s] 10%|█         | 996/9572 [14:29<2:04:12,  1.15it/s] 11%|█         | 1008/9572 [14:39<2:03:58,  1.15it/s] 11%|█         | 1020/9572 [14:50<2:03:31,  1.15it/s] 11%|█         | 1032/9572 [15:00<2:03:21,  1.15it/s] 11%|█         | 1044/9572 [15:11<2:03:02,  1.16it/s] 11%|█         | 1056/9572 [15:21<2:02:47,  1.16it/s] 11%|█         | 1068/9572 [15:31<2:03:01,  1.15it/s] 11%|█▏        | 1080/9572 [15:42<2:02:50,  1.15it/s] 11%|█▏        | 1092/9572 [15:52<2:03:00,  1.15it/s] 12%|█▏        | 1104/9572 [16:03<2:02:42,  1.15it/s] 12%|█▏        | 1116/9572 [16:13<2:02:36,  1.15it/s] 12%|█▏        | 1128/9572 [16:24<2:02:13,  1.15it/s] 12%|█▏        | 1140/9572 [16:34<2:02:17,  1.15it/s] 12%|█▏        | 1152/9572 [16:44<2:01:41,  1.15it/s] 12%|█▏        | 1164/9572 [16:55<2:01:48,  1.15it/s] 12%|█▏        | 1176/9572 [17:05<2:01:46,  1.15it/s] 12%|█▏        | 1188/9572 [17:16<2:01:43,  1.15it/s] 13%|█▎        | 1200/9572 [17:26<2:01:23,  1.15it/s] 13%|█▎        | 1212/9572 [17:37<2:01:04,  1.15it/s] 13%|█▎        | 1224/9572 [17:47<2:00:52,  1.15it/s] 13%|█▎        | 1236/9572 [17:57<2:00:33,  1.15it/s] 13%|█▎        | 1248/9572 [18:08<2:00:26,  1.15it/s] 13%|█▎        | 1260/9572 [18:18<2:00:08,  1.15it/s] 13%|█▎        | 1272/9572 [18:29<2:00:24,  1.15it/s] 13%|█▎        | 1284/9572 [18:39<2:00:16,  1.15it/s] 14%|█▎        | 1296/9572 [18:50<1:59:52,  1.15it/s] 14%|█▎        | 1308/9572 [19:00<1:59:27,  1.15it/s] 14%|█▍        | 1320/9572 [19:10<1:59:18,  1.15it/s] 14%|█▍        | 1332/9572 [19:21<1:59:42,  1.15it/s] 14%|█▍        | 1344/9572 [19:31<1:59:00,  1.15it/s] 14%|█▍        | 1356/9572 [19:42<1:59:08,  1.15it/s] 14%|█▍        | 1368/9572 [19:52<1:58:48,  1.15it/s] 14%|█▍        | 1380/9572 [20:03<1:58:39,  1.15it/s] 15%|█▍        | 1392/9572 [20:13<1:58:09,  1.15it/s] 15%|█▍        | 1404/9572 [20:23<1:58:13,  1.15it/s] 15%|█▍        | 1416/9572 [20:34<1:57:49,  1.15it/s] 15%|█▍        | 1428/9572 [20:44<1:57:46,  1.15it/s] 15%|█▌        | 1440/9572 [20:55<1:57:44,  1.15it/s] 15%|█▌        | 1452/9572 [21:05<1:57:27,  1.15it/s] 15%|█▌        | 1464/9572 [21:15<1:57:18,  1.15it/s] 15%|█▌        | 1476/9572 [21:26<1:56:34,  1.16it/s] 16%|█▌        | 1488/9572 [21:36<1:56:49,  1.15it/s] 16%|█▌        | 1500/9572 [21:47<1:56:30,  1.15it/s] 16%|█▌        | 1512/9572 [21:57<1:56:31,  1.15it/s] 16%|█▌        | 1524/9572 [22:07<1:55:52,  1.16it/s] 16%|█▌        | 1536/9572 [22:18<1:55:44,  1.16it/s] 16%|█▌        | 1548/9572 [22:28<1:56:02,  1.15it/s] 16%|█▋        | 1560/9572 [22:39<1:55:40,  1.15it/s] 16%|█▋        | 1572/9572 [22:49<1:55:08,  1.16it/s] 17%|█▋        | 1584/9572 [22:59<1:55:08,  1.16it/s] 17%|█▋        | 1596/9572 [23:10<1:55:04,  1.16it/s] 17%|█▋        | 1608/9572 [23:20<1:54:46,  1.16it/s] 17%|█▋        | 1620/9572 [23:30<1:54:48,  1.15it/s] 17%|█▋        | 1632/9572 [23:41<1:54:37,  1.15it/s] 17%|█▋        | 1644/9572 [23:51<1:54:22,  1.16it/s] 17%|█▋        | 1656/9572 [24:02<1:54:20,  1.15it/s] 17%|█▋        | 1668/9572 [24:12<1:53:54,  1.16it/s] 18%|█▊        | 1680/9572 [24:22<1:53:36,  1.16it/s] 18%|█▊        | 1692/9572 [24:33<1:53:50,  1.15it/s] 18%|█▊        | 1704/9572 [24:43<1:53:24,  1.16it/s] 18%|█▊        | 1716/9572 [24:54<1:53:23,  1.15it/s] 18%|█▊        | 1728/9572 [25:04<1:52:58,  1.16it/s] 18%|█▊        | 1740/9572 [25:14<1:53:11,  1.15it/s] 18%|█▊        | 1752/9572 [25:25<1:53:10,  1.15it/s] 18%|█▊        | 1764/9572 [25:35<1:52:41,  1.15it/s] 19%|█▊        | 1776/9572 [25:45<1:52:19,  1.16it/s] 19%|█▊        | 1788/9572 [25:56<1:51:58,  1.16it/s] 19%|█▉        | 1800/9572 [26:06<1:51:46,  1.16it/s] 19%|█▉        | 1812/9572 [26:16<1:51:40,  1.16it/s] 19%|█▉        | 1824/9572 [26:27<1:51:27,  1.16it/s] 19%|█▉        | 1836/9572 [26:37<1:51:33,  1.16it/s] 19%|█▉        | 1848/9572 [26:48<1:51:17,  1.16it/s] 19%|█▉        | 1860/9572 [26:58<1:51:02,  1.16it/s] 20%|█▉        | 1872/9572 [27:08<1:51:06,  1.16it/s] 20%|█▉        | 1884/9572 [27:19<1:50:43,  1.16it/s] 20%|█▉        | 1896/9572 [27:29<1:50:50,  1.15it/s] 20%|█▉        | 1908/9572 [27:40<1:50:39,  1.15it/s] 20%|██        | 1920/9572 [27:50<1:50:23,  1.16it/s] 20%|██        | 1932/9572 [28:00<1:50:05,  1.16it/s] 20%|██        | 1944/9572 [28:11<1:50:02,  1.16it/s] 20%|██        | 1956/9572 [28:21<1:49:57,  1.15it/s] 21%|██        | 1968/9572 [28:32<1:49:41,  1.16it/s] 21%|██        | 1980/9572 [28:42<1:49:29,  1.16it/s] 21%|██        | 1992/9572 [28:52<1:49:13,  1.16it/s] 21%|██        | 2004/9572 [29:03<1:49:00,  1.16it/s] 21%|██        | 2016/9572 [29:13<1:49:10,  1.15it/s] 21%|██        | 2028/9572 [29:23<1:48:54,  1.15it/s] 21%|██▏       | 2040/9572 [29:34<1:48:35,  1.16it/s] 21%|██▏       | 2052/9572 [29:44<1:48:12,  1.16it/s] 22%|██▏       | 2064/9572 [29:54<1:47:58,  1.16it/s] 22%|██▏       | 2076/9572 [30:05<1:48:03,  1.16it/s] 22%|██▏       | 2088/9572 [30:15<1:47:51,  1.16it/s] 22%|██▏       | 2100/9572 [30:26<1:47:38,  1.16it/s] 22%|██▏       | 2112/9572 [30:36<1:47:17,  1.16it/s] 22%|██▏       | 2124/9572 [30:46<1:47:34,  1.15it/s] 22%|██▏       | 2136/9572 [30:57<1:47:23,  1.15it/s] 22%|██▏       | 2148/9572 [31:07<1:46:55,  1.16it/s] 23%|██▎       | 2160/9572 [31:18<1:47:00,  1.15it/s] 23%|██▎       | 2172/9572 [31:28<1:46:53,  1.15it/s] 23%|██▎       | 2184/9572 [31:39<1:47:03,  1.15it/s] 23%|██▎       | 2196/9572 [31:49<1:46:28,  1.15it/s] 23%|██▎       | 2208/9572 [31:59<1:46:25,  1.15it/s] 23%|██▎       | 2220/9572 [32:10<1:46:21,  1.15it/s] 23%|██▎       | 2232/9572 [32:20<1:45:58,  1.15it/s] 23%|██▎       | 2244/9572 [32:30<1:45:39,  1.16it/s] 24%|██▎       | 2256/9572 [32:41<1:45:25,  1.16it/s] 24%|██▎       | 2268/9572 [32:51<1:45:16,  1.16it/s] 24%|██▍       | 2280/9572 [33:02<1:45:26,  1.15it/s] 24%|██▍       | 2292/9572 [33:12<1:45:02,  1.16it/s] 24%|██▍       | 2304/9572 [33:22<1:44:45,  1.16it/s] 24%|██▍       | 2316/9572 [33:33<1:44:38,  1.16it/s] 24%|██▍       | 2328/9572 [33:43<1:44:21,  1.16it/s] 24%|██▍       | 2340/9572 [33:54<1:44:35,  1.15it/s] 25%|██▍       | 2352/9572 [34:04<1:44:25,  1.15it/s] 25%|██▍       | 2364/9572 [34:14<1:44:07,  1.15it/s] 25%|██▍       | 2376/9572 [34:25<1:43:49,  1.16it/s] 25%|██▍       | 2388/9572 [34:35<1:43:49,  1.15it/s] 25%|██▌       | 2400/9572 [34:45<1:43:22,  1.16it/s] 25%|██▌       | 2412/9572 [34:56<1:43:13,  1.16it/s] 25%|██▌       | 2424/9572 [35:06<1:42:51,  1.16it/s] 25%|██▌       | 2436/9572 [35:17<1:42:47,  1.16it/s] 26%|██▌       | 2448/9572 [35:27<1:42:40,  1.16it/s] 26%|██▌       | 2460/9572 [35:37<1:42:25,  1.16it/s] 26%|██▌       | 2472/9572 [35:48<1:42:27,  1.15it/s] 26%|██▌       | 2484/9572 [35:58<1:42:09,  1.16it/s] 26%|██▌       | 2496/9572 [36:09<1:42:09,  1.15it/s] 26%|██▌       | 2508/9572 [36:19<1:42:05,  1.15it/s] 26%|██▋       | 2520/9572 [36:29<1:41:48,  1.15it/s] 26%|██▋       | 2532/9572 [36:40<1:41:31,  1.16it/s] 27%|██▋       | 2544/9572 [36:50<1:41:14,  1.16it/s] 27%|██▋       | 2556/9572 [37:00<1:41:02,  1.16it/s] 27%|██▋       | 2568/9572 [37:11<1:41:07,  1.15it/s] 27%|██▋       | 2580/9572 [37:21<1:40:49,  1.16it/s] 27%|██▋       | 2592/9572 [37:32<1:40:38,  1.16it/s] 27%|██▋       | 2604/9572 [37:42<1:40:26,  1.16it/s] 27%|██▋       | 2616/9572 [37:52<1:40:10,  1.16it/s] 27%|██▋       | 2628/9572 [38:03<1:39:45,  1.16it/s] 28%|██▊       | 2640/9572 [38:13<1:39:56,  1.16it/s] 28%|██▊       | 2652/9572 [38:23<1:39:49,  1.16it/s] 28%|██▊       | 2664/9572 [38:34<1:39:33,  1.16it/s] 28%|██▊       | 2676/9572 [38:44<1:40:03,  1.15it/s] 28%|██▊       | 2688/9572 [38:55<1:39:52,  1.15it/s] 28%|██▊       | 2700/9572 [39:05<1:39:47,  1.15it/s] 28%|██▊       | 2712/9572 [39:16<1:39:12,  1.15it/s] 28%|██▊       | 2724/9572 [39:26<1:38:51,  1.15it/s] 29%|██▊       | 2736/9572 [39:36<1:38:38,  1.16it/s] 29%|██▊       | 2748/9572 [39:47<1:38:27,  1.16it/s] 29%|██▉       | 2760/9572 [39:57<1:38:25,  1.15it/s] 29%|██▉       | 2772/9572 [40:08<1:38:13,  1.15it/s] 29%|██▉       | 2784/9572 [40:18<1:37:50,  1.16it/s] 29%|██▉       | 2796/9572 [40:28<1:37:46,  1.16it/s] 29%|██▉       | 2808/9572 [40:39<1:37:28,  1.16it/s] 29%|██▉       | 2820/9572 [40:49<1:37:17,  1.16it/s] 30%|██▉       | 2832/9572 [40:59<1:37:01,  1.16it/s] 30%|██▉       | 2844/9572 [41:10<1:37:08,  1.15it/s] 30%|██▉       | 2856/9572 [41:20<1:36:53,  1.16it/s] 30%|██▉       | 2868/9572 [41:31<1:36:37,  1.16it/s] 30%|███       | 2880/9572 [41:41<1:36:15,  1.16it/s] 30%|███       | 2892/9572 [41:51<1:36:30,  1.15it/s] 30%|███       | 2904/9572 [42:02<1:36:24,  1.15it/s] 30%|███       | 2916/9572 [42:12<1:36:25,  1.15it/s] 31%|███       | 2928/9572 [42:23<1:36:05,  1.15it/s] 31%|███       | 2940/9572 [42:33<1:35:53,  1.15it/s] 31%|███       | 2952/9572 [42:43<1:35:43,  1.15it/s] 31%|███       | 2964/9572 [42:54<1:35:36,  1.15it/s] 31%|███       | 2976/9572 [43:04<1:35:11,  1.15it/s] 31%|███       | 2988/9572 [43:15<1:35:37,  1.15it/s] 31%|███▏      | 3000/9572 [43:25<1:34:55,  1.15it/s] 31%|███▏      | 3012/9572 [43:36<1:34:56,  1.15it/s] 32%|███▏      | 3024/9572 [43:46<1:34:50,  1.15it/s] 32%|███▏      | 3036/9572 [43:56<1:34:38,  1.15it/s] 32%|███▏      | 3048/9572 [44:07<1:34:33,  1.15it/s] 32%|███▏      | 3060/9572 [44:17<1:34:21,  1.15it/s] 32%|███▏      | 3072/9572 [44:28<1:34:03,  1.15it/s] 32%|███▏      | 3084/9572 [44:38<1:33:44,  1.15it/s] 32%|███▏      | 3096/9572 [44:49<1:33:40,  1.15it/s] 32%|███▏      | 3108/9572 [44:59<1:33:26,  1.15it/s] 33%|███▎      | 3120/9572 [45:09<1:33:30,  1.15it/s] 33%|███▎      | 3132/9572 [45:20<1:33:07,  1.15it/s] 33%|███▎      | 3144/9572 [45:30<1:32:49,  1.15it/s] 33%|███▎      | 3156/9572 [45:41<1:32:43,  1.15it/s] 33%|███▎      | 3168/9572 [45:51<1:32:15,  1.16it/s] 33%|███▎      | 3180/9572 [46:01<1:32:03,  1.16it/s] 33%|███▎      | 3192/9572 [46:12<1:31:56,  1.16it/s] 33%|███▎      | 3204/9572 [46:22<1:31:54,  1.15it/s] 34%|███▎      | 3216/9572 [46:32<1:31:33,  1.16it/s] 34%|███▎      | 3228/9572 [46:43<1:31:27,  1.16it/s] 34%|███▍      | 3240/9572 [46:53<1:31:27,  1.15it/s] 34%|███▍      | 3252/9572 [47:04<1:31:08,  1.16it/s] 34%|███▍      | 3264/9572 [47:14<1:30:58,  1.16it/s] 34%|███▍      | 3276/9572 [47:24<1:30:54,  1.15it/s] 34%|███▍      | 3288/9572 [47:35<1:30:31,  1.16it/s] 34%|███▍      | 3300/9572 [47:45<1:30:21,  1.16it/s] 35%|███▍      | 3312/9572 [47:55<1:30:11,  1.16it/s] 35%|███▍      | 3324/9572 [48:06<1:30:09,  1.16it/s] 35%|███▍      | 3336/9572 [48:16<1:29:48,  1.16it/s] 35%|███▍      | 3348/9572 [48:27<1:29:40,  1.16it/s] 35%|███▌      | 3360/9572 [48:37<1:29:31,  1.16it/s] 35%|███▌      | 3372/9572 [48:47<1:29:07,  1.16it/s] 35%|███▌      | 3384/9572 [48:58<1:29:30,  1.15it/s] 35%|███▌      | 3396/9572 [49:08<1:29:03,  1.16it/s] 36%|███▌      | 3408/9572 [49:19<1:28:56,  1.16it/s] 36%|███▌      | 3420/9572 [49:29<1:28:35,  1.16it/s] 36%|███▌      | 3432/9572 [49:39<1:28:27,  1.16it/s] 36%|███▌      | 3444/9572 [49:50<1:28:07,  1.16it/s] 36%|███▌      | 3456/9572 [50:00<1:27:44,  1.16it/s] 36%|███▌      | 3468/9572 [50:10<1:27:51,  1.16it/s] 36%|███▋      | 3480/9572 [50:21<1:27:22,  1.16it/s] 36%|███▋      | 3492/9572 [50:31<1:28:06,  1.15it/s] 37%|███▋      | 3504/9572 [50:42<1:27:41,  1.15it/s] 37%|███▋      | 3516/9572 [50:52<1:27:23,  1.15it/s] 37%|███▋      | 3528/9572 [51:02<1:27:24,  1.15it/s] 37%|███▋      | 3540/9572 [51:13<1:27:08,  1.15it/s] 37%|███▋      | 3552/9572 [51:23<1:26:50,  1.16it/s] 37%|███▋      | 3564/9572 [51:34<1:26:51,  1.15it/s] 37%|███▋      | 3576/9572 [51:44<1:26:22,  1.16it/s] 37%|███▋      | 3588/9572 [51:54<1:26:02,  1.16it/s] 38%|███▊      | 3600/9572 [52:05<1:26:05,  1.16it/s] 38%|███▊      | 3612/9572 [52:15<1:26:04,  1.15it/s] 38%|███▊      | 3624/9572 [52:25<1:25:46,  1.16it/s] 38%|███▊      | 3636/9572 [52:36<1:25:41,  1.15it/s] 38%|███▊      | 3648/9572 [52:46<1:25:25,  1.16it/s] 38%|███▊      | 3660/9572 [52:57<1:25:13,  1.16it/s] 38%|███▊      | 3672/9572 [53:07<1:25:16,  1.15it/s] 38%|███▊      | 3684/9572 [53:17<1:24:57,  1.15it/s] 39%|███▊      | 3696/9572 [53:28<1:24:50,  1.15it/s] 39%|███▊      | 3708/9572 [53:38<1:24:31,  1.16it/s] 39%|███▉      | 3720/9572 [53:49<1:24:36,  1.15it/s] 39%|███▉      | 3732/9572 [53:59<1:24:19,  1.15it/s] 39%|███▉      | 3744/9572 [54:09<1:24:09,  1.15it/s] 39%|███▉      | 3756/9572 [54:20<1:24:01,  1.15it/s] 39%|███▉      | 3768/9572 [54:30<1:23:27,  1.16it/s] 39%|███▉      | 3780/9572 [54:40<1:23:11,  1.16it/s] 40%|███▉      | 3792/9572 [54:51<1:23:06,  1.16it/s] 40%|███▉      | 3804/9572 [55:01<1:22:48,  1.16it/s] 40%|███▉      | 3816/9572 [55:11<1:22:49,  1.16it/s] 40%|███▉      | 3828/9572 [55:22<1:22:30,  1.16it/s] 40%|████      | 3840/9572 [55:32<1:22:34,  1.16it/s] 40%|████      | 3852/9572 [55:42<1:22:21,  1.16it/s] 40%|████      | 3864/9572 [55:53<1:22:05,  1.16it/s] 40%|████      | 3876/9572 [56:03<1:21:29,  1.16it/s] 41%|████      | 3888/9572 [56:14<1:21:51,  1.16it/s] 41%|████      | 3900/9572 [56:24<1:21:34,  1.16it/s] 41%|████      | 3912/9572 [56:34<1:21:08,  1.16it/s] 41%|████      | 3924/9572 [56:45<1:21:17,  1.16it/s] 41%|████      | 3936/9572 [56:55<1:21:14,  1.16it/s] 41%|████      | 3948/9572 [57:05<1:20:38,  1.16it/s] 41%|████▏     | 3960/9572 [57:16<1:20:59,  1.15it/s] 41%|████▏     | 3972/9572 [57:26<1:20:26,  1.16it/s] 42%|████▏     | 3984/9572 [57:36<1:20:06,  1.16it/s] 42%|████▏     | 3996/9572 [57:47<1:20:14,  1.16it/s] 42%|████▏     | 4008/9572 [57:57<1:20:04,  1.16it/s] 42%|████▏     | 4020/9572 [58:07<1:19:40,  1.16it/s] 42%|████▏     | 4032/9572 [58:18<1:19:24,  1.16it/s] 42%|████▏     | 4044/9572 [58:28<1:19:10,  1.16it/s] 42%|████▏     | 4056/9572 [58:38<1:19:12,  1.16it/s] 42%|████▏     | 4068/9572 [58:49<1:18:49,  1.16it/s] 43%|████▎     | 4080/9572 [58:59<1:18:39,  1.16it/s] 43%|████▎     | 4092/9572 [59:09<1:18:17,  1.17it/s] 43%|████▎     | 4104/9572 [59:19<1:18:00,  1.17it/s] 43%|████▎     | 4116/9572 [59:30<1:18:22,  1.16it/s] 43%|████▎     | 4128/9572 [59:40<1:17:51,  1.17it/s] 43%|████▎     | 4140/9572 [59:50<1:17:55,  1.16it/s] 43%|████▎     | 4152/9572 [1:00:01<1:17:45,  1.16it/s] 44%|████▎     | 4164/9572 [1:00:11<1:17:29,  1.16it/s] 44%|████▎     | 4176/9572 [1:00:21<1:17:33,  1.16it/s] 44%|████▍     | 4188/9572 [1:00:32<1:17:25,  1.16it/s] 44%|████▍     | 4200/9572 [1:00:42<1:17:10,  1.16it/s] 44%|████▍     | 4212/9572 [1:00:52<1:16:56,  1.16it/s] 44%|████▍     | 4224/9572 [1:01:03<1:16:58,  1.16it/s] 44%|████▍     | 4236/9572 [1:01:13<1:16:52,  1.16it/s] 44%|████▍     | 4248/9572 [1:01:24<1:16:51,  1.15it/s] 45%|████▍     | 4260/9572 [1:01:34<1:16:38,  1.16it/s] 45%|████▍     | 4272/9572 [1:01:44<1:16:25,  1.16it/s] 45%|████▍     | 4284/9572 [1:01:55<1:16:19,  1.15it/s] 45%|████▍     | 4296/9572 [1:02:05<1:16:03,  1.16it/s] 45%|████▌     | 4308/9572 [1:02:15<1:15:34,  1.16it/s] 45%|████▌     | 4320/9572 [1:02:26<1:15:36,  1.16it/s] 45%|████▌     | 4332/9572 [1:02:36<1:15:31,  1.16it/s] 45%|████▌     | 4344/9572 [1:02:47<1:15:04,  1.16it/s] 46%|████▌     | 4356/9572 [1:02:57<1:15:03,  1.16it/s] 46%|████▌     | 4368/9572 [1:03:07<1:15:01,  1.16it/s] 46%|████▌     | 4380/9572 [1:03:18<1:14:36,  1.16it/s] 46%|████▌     | 4392/9572 [1:03:28<1:14:30,  1.16it/s] 46%|████▌     | 4404/9572 [1:03:38<1:14:31,  1.16it/s] 46%|████▌     | 4416/9572 [1:03:49<1:14:23,  1.16it/s] 46%|████▋     | 4428/9572 [1:03:59<1:14:10,  1.16it/s] 46%|████▋     | 4440/9572 [1:04:10<1:13:57,  1.16it/s] 47%|████▋     | 4452/9572 [1:04:20<1:13:31,  1.16it/s] 47%|████▋     | 4464/9572 [1:04:30<1:13:31,  1.16it/s] 47%|████▋     | 4476/9572 [1:04:41<1:13:26,  1.16it/s] 47%|████▋     | 4488/9572 [1:04:51<1:13:05,  1.16it/s] 47%|████▋     | 4500/9572 [1:05:01<1:12:51,  1.16it/s] 47%|████▋     | 4512/9572 [1:05:12<1:12:52,  1.16it/s] 47%|████▋     | 4524/9572 [1:05:22<1:12:32,  1.16it/s] 47%|████▋     | 4536/9572 [1:05:32<1:12:15,  1.16it/s] 48%|████▊     | 4548/9572 [1:05:43<1:12:22,  1.16it/s] 48%|████▊     | 4560/9572 [1:05:53<1:12:01,  1.16it/s] 48%|████▊     | 4572/9572 [1:06:03<1:11:57,  1.16it/s] 48%|████▊     | 4584/9572 [1:06:14<1:11:57,  1.16it/s] 48%|████▊     | 4596/9572 [1:06:24<1:11:34,  1.16it/s] 48%|████▊     | 4608/9572 [1:06:34<1:11:10,  1.16it/s] 48%|████▊     | 4620/9572 [1:06:45<1:11:05,  1.16it/s] 48%|████▊     | 4632/9572 [1:06:55<1:10:51,  1.16it/s] 49%|████▊     | 4644/9572 [1:07:05<1:10:34,  1.16it/s] 49%|████▊     | 4656/9572 [1:07:16<1:10:25,  1.16it/s] 49%|████▉     | 4668/9572 [1:07:26<1:10:17,  1.16it/s] 49%|████▉     | 4680/9572 [1:07:36<1:09:48,  1.17it/s] 49%|████▉     | 4692/9572 [1:07:47<1:10:19,  1.16it/s] 49%|████▉     | 4704/9572 [1:07:57<1:10:04,  1.16it/s] 49%|████▉     | 4716/9572 [1:08:07<1:09:38,  1.16it/s] 49%|████▉     | 4728/9572 [1:08:18<1:09:40,  1.16it/s] 50%|████▉     | 4740/9572 [1:08:28<1:09:35,  1.16it/s] 50%|████▉     | 4752/9572 [1:08:39<1:09:20,  1.16it/s] 50%|████▉     | 4764/9572 [1:08:49<1:09:28,  1.15it/s] 50%|████▉     | 4776/9572 [1:08:59<1:09:12,  1.16it/s] 50%|█████     | 4788/9572 [1:09:10<1:08:57,  1.16it/s] 50%|█████     | 4800/9572 [1:09:20<1:08:52,  1.15it/s] 50%|█████     | 4812/9572 [1:09:31<1:08:37,  1.16it/s] 50%|█████     | 4824/9572 [1:09:41<1:08:16,  1.16it/s] 51%|█████     | 4836/9572 [1:09:51<1:08:05,  1.16it/s] 51%|█████     | 4848/9572 [1:10:02<1:08:05,  1.16it/s] 51%|█████     | 4860/9572 [1:10:12<1:07:39,  1.16it/s] 51%|█████     | 4872/9572 [1:10:22<1:07:52,  1.15it/s] 51%|█████     | 4884/9572 [1:10:33<1:07:31,  1.16it/s] 51%|█████     | 4896/9572 [1:10:43<1:07:04,  1.16it/s] 51%|█████▏    | 4908/9572 [1:10:53<1:06:53,  1.16it/s] 51%|█████▏    | 4920/9572 [1:11:04<1:06:56,  1.16it/s] 52%|█████▏    | 4932/9572 [1:11:14<1:06:39,  1.16it/s] 52%|█████▏    | 4944/9572 [1:11:25<1:06:49,  1.15it/s] 52%|█████▏    | 4956/9572 [1:11:35<1:06:21,  1.16it/s] 52%|█████▏    | 4968/9572 [1:11:45<1:06:10,  1.16it/s] 52%|█████▏    | 4980/9572 [1:11:56<1:06:04,  1.16it/s] 52%|█████▏    | 4992/9572 [1:12:06<1:06:09,  1.15it/s] 52%|█████▏    | 5004/9572 [1:12:16<1:06:04,  1.15it/s] 52%|█████▏    | 5016/9572 [1:12:27<1:05:59,  1.15it/s] 53%|█████▎    | 5028/9572 [1:12:37<1:05:48,  1.15it/s] 53%|█████▎    | 5040/9572 [1:12:48<1:05:35,  1.15it/s] 53%|█████▎    | 5052/9572 [1:12:58<1:05:21,  1.15it/s] 53%|█████▎    | 5064/9572 [1:13:08<1:04:56,  1.16it/s] 53%|█████▎    | 5076/9572 [1:13:19<1:04:45,  1.16it/s] 53%|█████▎    | 5088/9572 [1:13:29<1:04:24,  1.16it/s] 53%|█████▎    | 5100/9572 [1:13:39<1:04:11,  1.16it/s] 53%|█████▎    | 5112/9572 [1:13:50<1:04:05,  1.16it/s] 54%|█████▎    | 5124/9572 [1:14:00<1:03:48,  1.16it/s] 54%|█████▎    | 5136/9572 [1:14:10<1:03:28,  1.16it/s] 54%|█████▍    | 5148/9572 [1:14:21<1:03:14,  1.17it/s] 54%|█████▍    | 5160/9572 [1:14:31<1:03:05,  1.17it/s] 54%|█████▍    | 5172/9572 [1:14:41<1:02:48,  1.17it/s] 54%|█████▍    | 5184/9572 [1:14:51<1:02:39,  1.17it/s] 54%|█████▍    | 5196/9572 [1:15:02<1:02:20,  1.17it/s] 54%|█████▍    | 5208/9572 [1:15:12<1:02:08,  1.17it/s] 55%|█████▍    | 5220/9572 [1:15:22<1:01:56,  1.17it/s] 55%|█████▍    | 5232/9572 [1:15:32<1:01:46,  1.17it/s] 55%|█████▍    | 5244/9572 [1:15:43<1:01:35,  1.17it/s] 55%|█████▍    | 5256/9572 [1:15:53<1:01:20,  1.17it/s] 55%|█████▌    | 5268/9572 [1:16:03<1:01:08,  1.17it/s] 55%|█████▌    | 5280/9572 [1:16:13<1:00:58,  1.17it/s] 55%|█████▌    | 5292/9572 [1:16:23<1:00:53,  1.17it/s] 55%|█████▌    | 5304/9572 [1:16:34<1:00:47,  1.17it/s] 56%|█████▌    | 5316/9572 [1:16:44<1:00:35,  1.17it/s] 56%|█████▌    | 5328/9572 [1:16:54<1:00:28,  1.17it/s] 56%|█████▌    | 5340/9572 [1:17:05<1:00:26,  1.17it/s] 56%|█████▌    | 5352/9572 [1:17:15<1:00:11,  1.17it/s] 56%|█████▌    | 5364/9572 [1:17:25<59:58,  1.17it/s]  /root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 56%|█████▌    | 5376/9572 [1:17:35<59:50,  1.17it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 56%|█████▋    | 5388/9572 [1:17:46<59:33,  1.17it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 56%|█████▋    | 5400/9572 [1:17:56<59:20,  1.17it/s] 57%|█████▋    | 5412/9572 [1:18:06<59:10,  1.17it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 57%|█████▋    | 5424/9572 [1:18:17<59:53,  1.15it/s] 57%|█████▋    | 5436/9572 [1:18:27<59:28,  1.16it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 57%|█████▋    | 5448/9572 [1:18:38<1:00:08,  1.14it/s] 57%|█████▋    | 5460/9572 [1:18:48<59:25,  1.15it/s]   57%|█████▋    | 5472/9572 [1:18:58<58:56,  1.16it/s] 57%|█████▋    | 5484/9572 [1:19:08<58:25,  1.17it/s] 57%|█████▋    | 5496/9572 [1:19:19<58:03,  1.17it/s] 58%|█████▊    | 5508/9572 [1:19:29<57:43,  1.17it/s] 58%|█████▊    | 5520/9572 [1:19:39<57:25,  1.18it/s] 58%|█████▊    | 5532/9572 [1:19:49<57:07,  1.18it/s] 58%|█████▊    | 5544/9572 [1:19:59<56:55,  1.18it/s] 58%|█████▊    | 5556/9572 [1:20:09<56:35,  1.18it/s] 58%|█████▊    | 5568/9572 [1:20:19<56:17,  1.19it/s] 58%|█████▊    | 5580/9572 [1:20:29<55:58,  1.19it/s] 58%|█████▊    | 5592/9572 [1:20:39<55:39,  1.19it/s] 59%|█████▊    | 5604/9572 [1:20:49<55:15,  1.20it/s] 59%|█████▊    | 5616/9572 [1:20:59<55:03,  1.20it/s] 59%|█████▉    | 5628/9572 [1:21:09<54:51,  1.20it/s] 59%|█████▉    | 5640/9572 [1:21:19<54:33,  1.20it/s] 59%|█████▉    | 5652/9572 [1:21:29<54:25,  1.20it/s] 59%|█████▉    | 5664/9572 [1:21:39<54:06,  1.20it/s] 59%|█████▉    | 5676/9572 [1:21:49<53:49,  1.21it/s] 59%|█████▉    | 5688/9572 [1:21:59<53:32,  1.21it/s] 60%|█████▉    | 5700/9572 [1:22:09<53:16,  1.21it/s] 60%|█████▉    | 5712/9572 [1:22:19<52:58,  1.21it/s] 60%|█████▉    | 5724/9572 [1:22:29<52:44,  1.22it/s] 60%|█████▉    | 5736/9572 [1:22:38<52:32,  1.22it/s] 60%|██████    | 5748/9572 [1:22:48<52:15,  1.22it/s] 60%|██████    | 5760/9572 [1:22:58<52:00,  1.22it/s] 60%|██████    | 5772/9572 [1:23:08<51:45,  1.22it/s] 60%|██████    | 5784/9572 [1:23:17<51:27,  1.23it/s] 61%|██████    | 5796/9572 [1:23:27<51:13,  1.23it/s] 61%|██████    | 5808/9572 [1:23:37<51:03,  1.23it/s] 61%|██████    | 5820/9572 [1:23:47<50:48,  1.23it/s] 61%|██████    | 5832/9572 [1:23:56<50:30,  1.23it/s] 61%|██████    | 5844/9572 [1:24:06<50:21,  1.23it/s] 61%|██████    | 5856/9572 [1:24:16<50:03,  1.24it/s] 61%|██████▏   | 5868/9572 [1:24:25<49:48,  1.24it/s] 61%|██████▏   | 5880/9572 [1:24:35<49:42,  1.24it/s] 62%|██████▏   | 5892/9572 [1:24:45<49:27,  1.24it/s] 62%|██████▏   | 5904/9572 [1:24:54<49:11,  1.24it/s] 62%|██████▏   | 5916/9572 [1:25:04<48:58,  1.24it/s] 62%|██████▏   | 5928/9572 [1:25:14<48:49,  1.24it/s] 62%|██████▏   | 5940/9572 [1:25:23<48:29,  1.25it/s] 62%|██████▏   | 5952/9572 [1:25:33<48:18,  1.25it/s] 62%|██████▏   | 5964/9572 [1:25:42<48:03,  1.25it/s] 62%|██████▏   | 5976/9572 [1:25:52<47:48,  1.25it/s] 63%|██████▎   | 5988/9572 [1:26:01<47:36,  1.25it/s] 63%|██████▎   | 6000/9572 [1:26:11<47:32,  1.25it/s] 63%|██████▎   | 6012/9572 [1:26:20<47:14,  1.26it/s] 63%|██████▎   | 6024/9572 [1:26:30<46:59,  1.26it/s] 63%|██████▎   | 6036/9572 [1:26:39<46:48,  1.26it/s] 63%|██████▎   | 6048/9572 [1:26:49<46:38,  1.26it/s] 63%|██████▎   | 6060/9572 [1:26:58<46:25,  1.26it/s] 63%|██████▎   | 6072/9572 [1:27:08<46:13,  1.26it/s] 64%|██████▎   | 6084/9572 [1:27:17<46:02,  1.26it/s] 64%|██████▎   | 6096/9572 [1:27:27<45:54,  1.26it/s] 64%|██████▍   | 6108/9572 [1:27:36<45:39,  1.26it/s] 64%|██████▍   | 6120/9572 [1:27:46<45:28,  1.27it/s] 64%|██████▍   | 6132/9572 [1:27:55<45:17,  1.27it/s] 64%|██████▍   | 6144/9572 [1:28:05<45:04,  1.27it/s] 64%|██████▍   | 6156/9572 [1:28:14<44:55,  1.27it/s] 64%|██████▍   | 6168/9572 [1:28:24<44:45,  1.27it/s] 65%|██████▍   | 6180/9572 [1:28:33<44:34,  1.27it/s] 65%|██████▍   | 6192/9572 [1:28:43<44:22,  1.27it/s] 65%|██████▍   | 6204/9572 [1:28:52<44:09,  1.27it/s] 65%|██████▍   | 6216/9572 [1:29:01<44:00,  1.27it/s] 65%|██████▌   | 6228/9572 [1:29:11<43:48,  1.27it/s] 65%|██████▌   | 6240/9572 [1:29:20<43:39,  1.27it/s] 65%|██████▌   | 6252/9572 [1:29:30<43:28,  1.27it/s] 65%|██████▌   | 6264/9572 [1:29:39<43:18,  1.27it/s] 66%|██████▌   | 6276/9572 [1:29:48<43:06,  1.27it/s] 66%|██████▌   | 6288/9572 [1:29:58<42:54,  1.28it/s] 66%|██████▌   | 6300/9572 [1:30:07<42:42,  1.28it/s] 66%|██████▌   | 6312/9572 [1:30:17<42:26,  1.28it/s] 66%|██████▌   | 6324/9572 [1:30:26<42:21,  1.28it/s] 66%|██████▌   | 6336/9572 [1:30:35<42:12,  1.28it/s] 66%|██████▋   | 6348/9572 [1:30:45<41:54,  1.28it/s] 66%|██████▋   | 6360/9572 [1:30:54<41:42,  1.28it/s] 67%|██████▋   | 6372/9572 [1:31:03<41:30,  1.28it/s] 67%|██████▋   | 6384/9572 [1:31:13<41:20,  1.29it/s] 67%|██████▋   | 6396/9572 [1:31:22<41:05,  1.29it/s] 67%|██████▋   | 6408/9572 [1:31:31<40:57,  1.29it/s] 67%|██████▋   | 6420/9572 [1:31:41<40:44,  1.29it/s] 67%|██████▋   | 6432/9572 [1:31:50<40:32,  1.29it/s] 67%|██████▋   | 6444/9572 [1:31:59<40:21,  1.29it/s] 67%|██████▋   | 6456/9572 [1:32:08<40:03,  1.30it/s] 68%|██████▊   | 6468/9572 [1:32:18<39:59,  1.29it/s] 68%|██████▊   | 6480/9572 [1:32:27<39:48,  1.29it/s] 68%|██████▊   | 6492/9572 [1:32:36<39:33,  1.30it/s] 68%|██████▊   | 6504/9572 [1:32:45<39:30,  1.29it/s] 68%|██████▊   | 6516/9572 [1:32:55<39:17,  1.30it/s] 68%|██████▊   | 6528/9572 [1:33:04<39:03,  1.30it/s] 68%|██████▊   | 6540/9572 [1:33:13<38:56,  1.30it/s] 68%|██████▊   | 6552/9572 [1:33:22<38:48,  1.30it/s] 69%|██████▊   | 6564/9572 [1:33:31<38:33,  1.30it/s] 69%|██████▊   | 6576/9572 [1:33:41<38:25,  1.30it/s] 69%|██████▉   | 6588/9572 [1:33:50<38:10,  1.30it/s] 69%|██████▉   | 6600/9572 [1:33:59<37:55,  1.31it/s] 69%|██████▉   | 6612/9572 [1:34:08<37:48,  1.31it/s] 69%|██████▉   | 6624/9572 [1:34:17<37:37,  1.31it/s] 69%|██████▉   | 6636/9572 [1:34:27<37:21,  1.31it/s] 69%|██████▉   | 6648/9572 [1:34:36<37:17,  1.31it/s] 70%|██████▉   | 6660/9572 [1:34:45<37:08,  1.31it/s] 70%|██████▉   | 6672/9572 [1:34:54<36:53,  1.31it/s] 70%|██████▉   | 6684/9572 [1:35:03<36:45,  1.31it/s] 70%|██████▉   | 6696/9572 [1:35:12<36:35,  1.31it/s] 70%|███████   | 6708/9572 [1:35:21<36:20,  1.31it/s] 70%|███████   | 6720/9572 [1:35:31<36:11,  1.31it/s] 70%|███████   | 6732/9572 [1:35:40<36:05,  1.31it/s] 70%|███████   | 6744/9572 [1:35:49<35:45,  1.32it/s] 71%|███████   | 6756/9572 [1:35:58<35:38,  1.32it/s] 71%|███████   | 6768/9572 [1:36:07<35:30,  1.32it/s] 71%|███████   | 6780/9572 [1:36:16<35:14,  1.32it/s] 71%|███████   | 6792/9572 [1:36:25<34:59,  1.32it/s] 71%|███████   | 6804/9572 [1:36:34<34:50,  1.32it/s] 71%|███████   | 6816/9572 [1:36:43<34:31,  1.33it/s] 71%|███████▏  | 6828/9572 [1:36:52<34:34,  1.32it/s] 71%|███████▏  | 6840/9572 [1:37:01<34:29,  1.32it/s] 72%|███████▏  | 6852/9572 [1:37:10<34:13,  1.32it/s] 72%|███████▏  | 6864/9572 [1:37:19<34:03,  1.33it/s] 72%|███████▏  | 6876/9572 [1:37:28<33:57,  1.32it/s] 72%|███████▏  | 6888/9572 [1:37:37<33:39,  1.33it/s] 72%|███████▏  | 6900/9572 [1:37:47<33:33,  1.33it/s] 72%|███████▏  | 6912/9572 [1:37:56<33:28,  1.32it/s] 72%|███████▏  | 6924/9572 [1:38:05<33:09,  1.33it/s] 72%|███████▏  | 6936/9572 [1:38:14<32:59,  1.33it/s] 73%|███████▎  | 6948/9572 [1:38:23<32:56,  1.33it/s] 73%|███████▎  | 6960/9572 [1:38:31<32:33,  1.34it/s] 73%|███████▎  | 6972/9572 [1:38:40<32:26,  1.34it/s] 73%|███████▎  | 6984/9572 [1:38:50<32:24,  1.33it/s] 73%|███████▎  | 6996/9572 [1:38:58<32:05,  1.34it/s] 73%|███████▎  | 7008/9572 [1:39:07<31:54,  1.34it/s] 73%|███████▎  | 7020/9572 [1:39:16<31:51,  1.34it/s] 73%|███████▎  | 7032/9572 [1:39:25<31:32,  1.34it/s] 74%|███████▎  | 7044/9572 [1:39:34<31:23,  1.34it/s] 74%|███████▎  | 7056/9572 [1:39:43<31:20,  1.34it/s] 74%|███████▍  | 7068/9572 [1:39:52<30:59,  1.35it/s] 74%|███████▍  | 7080/9572 [1:40:01<30:49,  1.35it/s] 74%|███████▍  | 7092/9572 [1:40:10<30:46,  1.34it/s] 74%|███████▍  | 7104/9572 [1:40:19<30:29,  1.35it/s] 74%|███████▍  | 7116/9572 [1:40:28<30:25,  1.35it/s] 74%|███████▍  | 7128/9572 [1:40:37<30:23,  1.34it/s] 75%|███████▍  | 7140/9572 [1:40:45<30:00,  1.35it/s] 75%|███████▍  | 7152/9572 [1:40:54<29:52,  1.35it/s] 75%|███████▍  | 7164/9572 [1:41:03<29:49,  1.35it/s] 75%|███████▍  | 7176/9572 [1:41:12<29:30,  1.35it/s] 75%|███████▌  | 7188/9572 [1:41:21<29:21,  1.35it/s] 75%|███████▌  | 7200/9572 [1:41:30<29:23,  1.35it/s] 75%|███████▌  | 7212/9572 [1:41:39<28:57,  1.36it/s] 75%|███████▌  | 7224/9572 [1:41:47<28:53,  1.35it/s] 76%|███████▌  | 7236/9572 [1:41:56<28:52,  1.35it/s] 76%|███████▌  | 7248/9572 [1:42:05<28:32,  1.36it/s] 76%|███████▌  | 7260/9572 [1:42:14<28:27,  1.35it/s] 76%|███████▌  | 7272/9572 [1:42:23<28:30,  1.34it/s] 76%|███████▌  | 7284/9572 [1:42:32<28:08,  1.36it/s] 76%|███████▌  | 7296/9572 [1:42:41<28:00,  1.35it/s] 76%|███████▋  | 7308/9572 [1:42:50<27:59,  1.35it/s] 76%|███████▋  | 7320/9572 [1:42:58<27:35,  1.36it/s] 77%|███████▋  | 7332/9572 [1:43:07<27:31,  1.36it/s] 77%|███████▋  | 7344/9572 [1:43:16<27:30,  1.35it/s] 77%|███████▋  | 7356/9572 [1:43:25<27:07,  1.36it/s] 77%|███████▋  | 7368/9572 [1:43:34<27:03,  1.36it/s] 77%|███████▋  | 7380/9572 [1:43:43<27:01,  1.35it/s] 77%|███████▋  | 7392/9572 [1:43:51<26:36,  1.37it/s] 77%|███████▋  | 7404/9572 [1:44:00<26:31,  1.36it/s] 77%|███████▋  | 7416/9572 [1:44:09<26:28,  1.36it/s] 78%|███████▊  | 7428/9572 [1:44:18<26:05,  1.37it/s] 78%|███████▊  | 7440/9572 [1:44:27<26:01,  1.37it/s] 78%|███████▊  | 7452/9572 [1:44:35<26:00,  1.36it/s] 78%|███████▊  | 7464/9572 [1:44:44<25:35,  1.37it/s] 78%|███████▊  | 7476/9572 [1:44:53<25:33,  1.37it/s] 78%|███████▊  | 7488/9572 [1:45:02<25:33,  1.36it/s] 78%|███████▊  | 7500/9572 [1:45:10<25:09,  1.37it/s] 78%|███████▊  | 7512/9572 [1:45:19<25:00,  1.37it/s] 79%|███████▊  | 7524/9572 [1:45:28<25:01,  1.36it/s] 79%|███████▊  | 7536/9572 [1:45:37<24:37,  1.38it/s] 79%|███████▉  | 7548/9572 [1:45:45<24:30,  1.38it/s] 79%|███████▉  | 7560/9572 [1:45:54<24:35,  1.36it/s] 79%|███████▉  | 7572/9572 [1:46:03<24:10,  1.38it/s] 79%|███████▉  | 7584/9572 [1:46:12<24:08,  1.37it/s] 79%|███████▉  | 7596/9572 [1:46:20<24:07,  1.37it/s] 79%|███████▉  | 7608/9572 [1:46:29<23:42,  1.38it/s] 80%|███████▉  | 7620/9572 [1:46:38<23:36,  1.38it/s] 80%|███████▉  | 7632/9572 [1:46:47<23:36,  1.37it/s] 80%|███████▉  | 7644/9572 [1:46:55<23:14,  1.38it/s] 80%|███████▉  | 7656/9572 [1:47:04<23:05,  1.38it/s] 80%|████████  | 7668/9572 [1:47:13<23:07,  1.37it/s] 80%|████████  | 7680/9572 [1:47:21<22:43,  1.39it/s] 80%|████████  | 7692/9572 [1:47:30<22:37,  1.38it/s] 80%|████████  | 7704/9572 [1:47:39<22:41,  1.37it/s] 81%|████████  | 7716/9572 [1:47:47<22:20,  1.38it/s] 81%|████████  | 7728/9572 [1:47:56<22:08,  1.39it/s] 81%|████████  | 7740/9572 [1:48:05<22:09,  1.38it/s] 81%|████████  | 7752/9572 [1:48:13<21:48,  1.39it/s] 81%|████████  | 7764/9572 [1:48:22<21:41,  1.39it/s] 81%|████████  | 7776/9572 [1:48:31<21:43,  1.38it/s] 81%|████████▏ | 7788/9572 [1:48:39<21:19,  1.39it/s] 81%|████████▏ | 7800/9572 [1:48:48<21:11,  1.39it/s] 82%|████████▏ | 7812/9572 [1:48:56<21:13,  1.38it/s] 82%|████████▏ | 7824/9572 [1:49:05<20:49,  1.40it/s] 82%|████████▏ | 7836/9572 [1:49:13<20:42,  1.40it/s] 82%|████████▏ | 7848/9572 [1:49:22<20:45,  1.38it/s] 82%|████████▏ | 7860/9572 [1:49:31<20:22,  1.40it/s] 82%|████████▏ | 7872/9572 [1:49:39<20:12,  1.40it/s] 82%|████████▏ | 7884/9572 [1:49:48<20:18,  1.38it/s] 82%|████████▏ | 7896/9572 [1:49:56<19:55,  1.40it/s] 83%|████████▎ | 7908/9572 [1:50:05<19:46,  1.40it/s] 83%|████████▎ | 7920/9572 [1:50:14<19:50,  1.39it/s] 83%|████████▎ | 7932/9572 [1:50:22<19:28,  1.40it/s] 83%|████████▎ | 7944/9572 [1:50:31<19:15,  1.41it/s] 83%|████████▎ | 7956/9572 [1:50:39<19:24,  1.39it/s] 83%|████████▎ | 7968/9572 [1:50:48<19:00,  1.41it/s] 83%|████████▎ | 7980/9572 [1:50:56<18:51,  1.41it/s] 83%|████████▎ | 7992/9572 [1:51:05<19:03,  1.38it/s] 84%|████████▎ | 8004/9572 [1:51:14<18:38,  1.40it/s] 84%|████████▎ | 8016/9572 [1:51:22<18:27,  1.40it/s] 84%|████████▍ | 8028/9572 [1:51:31<18:33,  1.39it/s] 84%|████████▍ | 8040/9572 [1:51:39<18:08,  1.41it/s] 84%|████████▍ | 8052/9572 [1:51:48<18:00,  1.41it/s] 84%|████████▍ | 8064/9572 [1:51:57<18:05,  1.39it/s] 84%|████████▍ | 8076/9572 [1:52:05<17:39,  1.41it/s] 84%|████████▍ | 8088/9572 [1:52:13<17:30,  1.41it/s] 85%|████████▍ | 8100/9572 [1:52:22<17:40,  1.39it/s] 85%|████████▍ | 8112/9572 [1:52:30<17:14,  1.41it/s] 85%|████████▍ | 8124/9572 [1:52:39<17:06,  1.41it/s] 85%|████████▍ | 8136/9572 [1:52:48<17:10,  1.39it/s] 85%|████████▌ | 8148/9572 [1:52:56<16:43,  1.42it/s] 85%|████████▌ | 8160/9572 [1:53:04<16:34,  1.42it/s] 85%|████████▌ | 8172/9572 [1:53:13<16:43,  1.39it/s] 85%|████████▌ | 8184/9572 [1:53:22<16:19,  1.42it/s] 86%|████████▌ | 8196/9572 [1:53:30<16:08,  1.42it/s] 86%|████████▌ | 8208/9572 [1:53:39<16:13,  1.40it/s] 86%|████████▌ | 8220/9572 [1:53:47<15:50,  1.42it/s] 86%|████████▌ | 8232/9572 [1:53:55<15:37,  1.43it/s] 86%|████████▌ | 8244/9572 [1:54:04<15:42,  1.41it/s] 86%|████████▋ | 8256/9572 [1:54:12<15:18,  1.43it/s] 86%|████████▋ | 8268/9572 [1:54:20<15:11,  1.43it/s] 87%|████████▋ | 8280/9572 [1:54:29<15:16,  1.41it/s] 87%|████████▋ | 8292/9572 [1:54:37<14:52,  1.43it/s] 87%|████████▋ | 8304/9572 [1:54:46<14:40,  1.44it/s] 87%|████████▋ | 8316/9572 [1:54:54<14:48,  1.41it/s] 87%|████████▋ | 8328/9572 [1:55:02<14:24,  1.44it/s] 87%|████████▋ | 8340/9572 [1:55:11<14:15,  1.44it/s] 87%|████████▋ | 8352/9572 [1:55:20<14:21,  1.42it/s] 87%|████████▋ | 8364/9572 [1:55:27<13:58,  1.44it/s] 88%|████████▊ | 8376/9572 [1:55:36<13:45,  1.45it/s] 88%|████████▊ | 8388/9572 [1:55:45<13:54,  1.42it/s] 88%|████████▊ | 8400/9572 [1:55:53<13:32,  1.44it/s] 88%|████████▊ | 8412/9572 [1:56:01<13:20,  1.45it/s] 88%|████████▊ | 8424/9572 [1:56:10<13:26,  1.42it/s] 88%|████████▊ | 8436/9572 [1:56:17<13:02,  1.45it/s] 88%|████████▊ | 8448/9572 [1:56:26<12:51,  1.46it/s] 88%|████████▊ | 8460/9572 [1:56:34<12:56,  1.43it/s] 89%|████████▊ | 8472/9572 [1:56:42<12:37,  1.45it/s] 89%|████████▊ | 8484/9572 [1:56:50<12:23,  1.46it/s] 89%|████████▉ | 8496/9572 [1:56:59<12:30,  1.43it/s] 89%|████████▉ | 8508/9572 [1:57:07<12:10,  1.46it/s] 89%|████████▉ | 8520/9572 [1:57:15<11:56,  1.47it/s] 89%|████████▉ | 8532/9572 [1:57:24<12:02,  1.44it/s] 89%|████████▉ | 8544/9572 [1:57:32<11:41,  1.47it/s] 89%|████████▉ | 8556/9572 [1:57:40<11:30,  1.47it/s] 90%|████████▉ | 8568/9572 [1:57:48<11:36,  1.44it/s] 90%|████████▉ | 8580/9572 [1:57:56<11:15,  1.47it/s] 90%|████████▉ | 8592/9572 [1:58:04<11:04,  1.47it/s] 90%|████████▉ | 8604/9572 [1:58:13<11:05,  1.45it/s] 90%|█████████ | 8616/9572 [1:58:21<10:46,  1.48it/s] 90%|█████████ | 8628/9572 [1:58:29<10:35,  1.49it/s] 90%|█████████ | 8640/9572 [1:58:37<10:39,  1.46it/s] 90%|█████████ | 8652/9572 [1:58:45<10:20,  1.48it/s] 91%|█████████ | 8664/9572 [1:58:53<10:07,  1.49it/s] 91%|█████████ | 8676/9572 [1:59:01<10:12,  1.46it/s] 91%|█████████ | 8688/9572 [1:59:09<09:55,  1.49it/s] 91%|█████████ | 8700/9572 [1:59:17<09:41,  1.50it/s] 91%|█████████ | 8712/9572 [1:59:26<09:45,  1.47it/s] 91%|█████████ | 8724/9572 [1:59:33<09:27,  1.50it/s] 91%|█████████▏| 8736/9572 [1:59:41<09:14,  1.51it/s] 91%|█████████▏| 8748/9572 [1:59:50<09:18,  1.48it/s] 92%|█████████▏| 8760/9572 [1:59:57<09:02,  1.50it/s] 92%|█████████▏| 8772/9572 [2:00:05<08:47,  1.52it/s] 92%|█████████▏| 8784/9572 [2:00:14<08:51,  1.48it/s] 92%|█████████▏| 8796/9572 [2:00:21<08:36,  1.50it/s] 92%|█████████▏| 8808/9572 [2:00:29<08:21,  1.52it/s] 92%|█████████▏| 8820/9572 [2:00:37<08:24,  1.49it/s] 92%|█████████▏| 8832/9572 [2:00:45<08:10,  1.51it/s] 92%|█████████▏| 8844/9572 [2:00:53<07:55,  1.53it/s] 93%|█████████▎| 8856/9572 [2:01:01<07:57,  1.50it/s] 93%|█████████▎| 8868/9572 [2:01:09<07:44,  1.52it/s] 93%|█████████▎| 8880/9572 [2:01:16<07:30,  1.54it/s] 93%|█████████▎| 8892/9572 [2:01:25<07:30,  1.51it/s] 93%|█████████▎| 8904/9572 [2:01:32<07:17,  1.53it/s] 93%|█████████▎| 8916/9572 [2:01:40<07:03,  1.55it/s] 93%|█████████▎| 8928/9572 [2:01:48<07:04,  1.52it/s] 93%|█████████▎| 8940/9572 [2:01:56<06:52,  1.53it/s] 94%|█████████▎| 8952/9572 [2:02:03<06:37,  1.56it/s] 94%|█████████▎| 8964/9572 [2:02:11<06:38,  1.53it/s] 94%|█████████▍| 8976/9572 [2:02:19<06:27,  1.54it/s] 94%|█████████▍| 8988/9572 [2:02:26<06:12,  1.57it/s] 94%|█████████▍| 9000/9572 [2:02:34<06:11,  1.54it/s] 94%|█████████▍| 9012/9572 [2:02:42<06:01,  1.55it/s] 94%|█████████▍| 9024/9572 [2:02:49<05:47,  1.58it/s] 94%|█████████▍| 9036/9572 [2:02:57<05:45,  1.55it/s] 95%|█████████▍| 9048/9572 [2:03:05<05:35,  1.56it/s] 95%|█████████▍| 9060/9572 [2:03:12<05:22,  1.59it/s] 95%|█████████▍| 9072/9572 [2:03:20<05:18,  1.57it/s] 95%|█████████▍| 9084/9572 [2:03:28<05:09,  1.58it/s] 95%|█████████▌| 9096/9572 [2:03:35<04:56,  1.60it/s] 95%|█████████▌| 9108/9572 [2:03:43<04:53,  1.58it/s] 95%|█████████▌| 9120/9572 [2:03:50<04:44,  1.59it/s] 95%|█████████▌| 9132/9572 [2:03:57<04:31,  1.62it/s] 96%|█████████▌| 9144/9572 [2:04:05<04:26,  1.61it/s] 96%|█████████▌| 9156/9572 [2:04:12<04:18,  1.61it/s] 96%|█████████▌| 9168/9572 [2:04:19<04:07,  1.63it/s] 96%|█████████▌| 9180/9572 [2:04:27<04:02,  1.62it/s] 96%|█████████▌| 9192/9572 [2:04:34<03:54,  1.62it/s] 96%|█████████▌| 9204/9572 [2:04:41<03:43,  1.65it/s] 96%|█████████▋| 9216/9572 [2:04:49<03:37,  1.64it/s] 96%|█████████▋| 9228/9572 [2:04:56<03:30,  1.64it/s] 97%|█████████▋| 9240/9572 [2:05:03<03:19,  1.66it/s] 97%|█████████▋| 9252/9572 [2:05:10<03:12,  1.66it/s] 97%|█████████▋| 9264/9572 [2:05:17<03:05,  1.66it/s] 97%|█████████▋| 9276/9572 [2:05:24<02:56,  1.68it/s] 97%|█████████▋| 9288/9572 [2:05:32<02:50,  1.67it/s] 97%|█████████▋| 9300/9572 [2:05:39<02:43,  1.67it/s] 97%|█████████▋| 9312/9572 [2:05:46<02:35,  1.67it/s] 97%|█████████▋| 9324/9572 [2:05:53<02:27,  1.68it/s] 98%|█████████▊| 9336/9572 [2:06:00<02:19,  1.69it/s] 98%|█████████▊| 9348/9572 [2:06:07<02:12,  1.69it/s] 98%|█████████▊| 9360/9572 [2:06:14<02:04,  1.71it/s] 98%|█████████▊| 9372/9572 [2:06:21<01:57,  1.71it/s] 98%|█████████▊| 9384/9572 [2:06:28<01:49,  1.71it/s] 98%|█████████▊| 9396/9572 [2:06:35<01:41,  1.73it/s] 98%|█████████▊| 9408/9572 [2:06:42<01:34,  1.74it/s] 98%|█████████▊| 9420/9572 [2:06:49<01:27,  1.74it/s] 99%|█████████▊| 9432/9572 [2:06:55<01:19,  1.76it/s] 99%|█████████▊| 9444/9572 [2:07:02<01:12,  1.77it/s] 99%|█████████▉| 9456/9572 [2:07:09<01:05,  1.77it/s] 99%|█████████▉| 9468/9572 [2:07:15<00:58,  1.79it/s] 99%|█████████▉| 9480/9572 [2:07:22<00:51,  1.80it/s] 99%|█████████▉| 9492/9572 [2:07:28<00:44,  1.80it/s] 99%|█████████▉| 9504/9572 [2:07:35<00:37,  1.82it/s] 99%|█████████▉| 9516/9572 [2:07:41<00:30,  1.83it/s]100%|█████████▉| 9528/9572 [2:07:48<00:23,  1.84it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
100%|█████████▉| 9540/9572 [2:07:54<00:16,  1.88it/s]100%|█████████▉| 9552/9572 [2:07:59<00:10,  1.95it/s]100%|█████████▉| 9564/9572 [2:08:05<00:03,  2.01it/s]100%|██████████| 9572/9572 [2:08:05<00:00,  1.25it/s]
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
fatal: not a git repository (or any of the parent directories): .git
{'hellaswag_el': {'alias': 'hellaswag_el', 'acc,none': 0.39465283320031924, 'acc_stderr,none': 0.004882148715447124, 'acc_norm,none': 0.49960095770151636, 'acc_norm_stderr,none': 0.0049942583092571595}, 'hellaswag_hu': {'alias': 'hellaswag_hu', 'acc,none': 0.38184011404759294, 'acc_stderr,none': 0.0050879330872811435, 'acc_norm,none': 0.48546989801513324, 'acc_norm_stderr,none': 0.005234036574307749}}
