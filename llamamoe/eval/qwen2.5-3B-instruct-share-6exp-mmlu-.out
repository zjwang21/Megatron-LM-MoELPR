W1006 10:33:10.973120 139981849813952 torch/distributed/run.py:757] 
W1006 10:33:10.973120 139981849813952 torch/distributed/run.py:757] *****************************************
W1006 10:33:10.973120 139981849813952 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1006 10:33:10.973120 139981849813952 torch/distributed/run.py:757] *****************************************
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
using world size: 8, data-parallel size: 8, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0
WARNING: overriding default arguments for no_load_rng:True                        with no_load_rng:True
WARNING: overriding default arguments for no_load_optim:True                        with no_load_optim:True
WARNING: overriding default arguments for micro_batch_size:1                        with micro_batch_size:4
WARNING: overriding default arguments for exit_on_missing_checkpoint:True                        with exit_on_missing_checkpoint:False
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adaptive_seq_len ................................ True
  add_bias_linear ................................. False
  add_position_embedding .......................... False
  add_qkv_bias .................................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... False
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.0
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ False
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  bsz ............................................. 12
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/root/work/huangxin/nanda/Megatron-LM/llamamoe/data/data-bin/elhutr_qwen2.5_30b_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... True
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 1000000
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  enable_shared_expert ............................ True
  encoder_num_layers .............................. 36
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 2048
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1000
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 2
  ffn_hidden_size ................................. 11008
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 1024
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... True
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.0
  hidden_size ..................................... 2048
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 5e-05
  lr_decay_iters .................................. 5000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 300
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 32768
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.001
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_ffn_hidden_size ............................. 5504
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_lpr_loss_coeff .............................. 0.001
  moe_lpr_stage ................................... 1
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... alltoall
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  moelpr_train_embeddings ......................... False
  nccl_communicator_config_path ................... None
  no_load_optim ................................... True
  no_load_rng ..................................... True
  no_persist_layer_norm ........................... False
  no_save_optim ................................... True
  no_save_rng ..................................... True
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... RMSNorm
  num_attention_heads ............................. 16
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... 6
  num_fewshot ..................................... 5
  num_layers ...................................... 36
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 2
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. True
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ True
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... rope
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  results_path .................................... /root/work/huangxin/nanda/Megatron-LM/llamamoe/eval/results/mcore_qwen2.5-3B-instruct-share-6exp-mmlu_expanded.json
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 1000000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 99990,8,2
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... True
  swin_backbone_type .............................. tiny
  task_list ....................................... m_mmlu_el,m_mmlu_hu,m_mmlu_tr
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. /root/work/huangxin/nanda/models/Qwen/Qwen2.5-3B-Instruct
  tokenizer_type .................................. HuggingFaceTokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 5000
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. True
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... None
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
  zero_expert_down_proj ........................... False
-------------------- end of arguments ---------------------
> building HuggingFaceTokenizer tokenizer ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
 > padded vocab (size: 151936) with 0 dummy tokens (new size: 151936)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.028 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.014 seconds
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
building GPT model ...
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
GPTModel(
  (embedding): LanguageModelEmbedding(
    (word_embeddings): VocabParallelEmbedding()
    (embedding_dropout): Dropout(p=0.0, inplace=False)
  )
  (rotary_pos_emb): RotaryEmbedding()
  (decoder): TransformerBlock(
    (layers): ModuleList(
      (0-35): 36 x TransformerLayer(
        (input_layernorm): IdentityOp()
        (self_attention): SelfAttention(
          (core_attention): TEDotProductAttention(
            (flash_attention): FlashAttention()
            (fused_attention): FusedAttention()
            (unfused_attention): UnfusedDotProductAttention(
              (scale_mask_softmax): FusedScaleMaskSoftmax()
              (attention_dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (linear_proj): TERowParallelLinear()
          (linear_qkv): TELayerNormColumnParallelLinear()
          (q_layernorm): IdentityOp()
          (k_layernorm): IdentityOp()
        )
        (pre_cross_attn_layernorm): IdentityOp()
        (cross_attention): IdentityOp()
        (cross_attn_bda): IdentityFuncOp()
        (pre_mlp_layernorm): RMSNorm()
        (mlp): MoELayer(
          (router): TopKRouter()
          (shared_expert_gate): LanguageRouter()
          (shared_expert): MLP(
            (linear_fc1): ColumnParallelLinear()
            (linear_fc2): RowParallelLinear()
          )
          (experts): SequentialMLP(
            (local_experts): ModuleList(
              (0-2): 3 x MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
            )
          )
        )
      )
    )
    (final_layernorm): RMSNorm()
  )
  (output_layer): ColumnParallelLinear()
)
Fine-tuning method: MoE-LPR stage 1
[Rank 3] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 2] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 5] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 0] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 6] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 4] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 1] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 7] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6738718720
 loading checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2 at iteration 12000
 checkpoint version 3.0
  successfully loaded checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2 [ t 0, p 0 ] at iteration 12000
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
  0%|          | 0/20300 [00:00<?, ?it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  0%|          | 12/20300 [00:15<7:30:16,  1.33s/it]  0%|          | 24/20300 [00:25<5:50:51,  1.04s/it]  0%|          | 36/20300 [00:35<5:12:29,  1.08it/s]  0%|          | 48/20300 [00:44<4:52:55,  1.15it/s]  0%|          | 60/20300 [00:54<4:44:50,  1.18it/s]  0%|          | 72/20300 [01:03<4:38:24,  1.21it/s]  0%|          | 84/20300 [01:13<4:33:01,  1.23it/s]  0%|          | 96/20300 [01:22<4:32:13,  1.24it/s]  1%|          | 108/20300 [01:32<4:30:11,  1.25it/s]  1%|          | 120/20300 [01:41<4:28:07,  1.25it/s]  1%|          | 132/20300 [01:51<4:29:00,  1.25it/s]  1%|          | 144/20300 [02:01<4:28:27,  1.25it/s]  1%|          | 156/20300 [02:10<4:27:09,  1.26it/s]  1%|          | 168/20300 [02:20<4:28:23,  1.25it/s]  1%|          | 180/20300 [02:29<4:28:30,  1.25it/s]  1%|          | 192/20300 [02:39<4:27:32,  1.25it/s]  1%|          | 204/20300 [02:49<4:28:07,  1.25it/s]  1%|          | 216/20300 [02:58<4:28:07,  1.25it/s]  1%|          | 228/20300 [03:08<4:27:05,  1.25it/s]  1%|          | 240/20300 [03:17<4:26:56,  1.25it/s]  1%|          | 252/20300 [03:27<4:26:41,  1.25it/s]  1%|▏         | 264/20300 [03:36<4:25:33,  1.26it/s]  1%|▏         | 276/20300 [03:46<4:25:15,  1.26it/s]  1%|▏         | 288/20300 [03:55<4:25:32,  1.26it/s]  1%|▏         | 300/20300 [04:05<4:24:44,  1.26it/s]  2%|▏         | 312/20300 [04:14<4:24:26,  1.26it/s]  2%|▏         | 324/20300 [04:24<4:24:36,  1.26it/s]  2%|▏         | 336/20300 [04:33<4:24:17,  1.26it/s]  2%|▏         | 348/20300 [04:43<4:23:28,  1.26it/s]  2%|▏         | 360/20300 [04:52<4:23:10,  1.26it/s]  2%|▏         | 372/20300 [05:02<4:22:47,  1.26it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 384/20300 [05:11<4:22:14,  1.27it/s]  2%|▏         | 396/20300 [05:21<4:21:58,  1.27it/s]  2%|▏         | 408/20300 [05:30<4:22:42,  1.26it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 420/20300 [05:40<4:23:36,  1.26it/s]  2%|▏         | 432/20300 [05:50<4:24:26,  1.25it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 444/20300 [05:59<4:24:55,  1.25it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 456/20300 [06:10<4:31:53,  1.22it/s]  2%|▏         | 468/20300 [06:20<4:30:37,  1.22it/s]  2%|▏         | 480/20300 [06:29<4:29:29,  1.23it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 492/20300 [06:39<4:28:02,  1.23it/s]  2%|▏         | 504/20300 [06:49<4:26:40,  1.24it/s]  3%|▎         | 516/20300 [06:58<4:25:32,  1.24it/s]  3%|▎         | 528/20300 [07:08<4:23:47,  1.25it/s]  3%|▎         | 540/20300 [07:17<4:22:06,  1.26it/s]  3%|▎         | 552/20300 [07:26<4:20:50,  1.26it/s]  3%|▎         | 564/20300 [07:36<4:19:39,  1.27it/s]  3%|▎         | 576/20300 [07:45<4:18:36,  1.27it/s]  3%|▎         | 588/20300 [07:54<4:17:16,  1.28it/s]  3%|▎         | 600/20300 [08:04<4:15:30,  1.29it/s]  3%|▎         | 612/20300 [08:13<4:13:49,  1.29it/s]  3%|▎         | 624/20300 [08:22<4:12:31,  1.30it/s]  3%|▎         | 636/20300 [08:31<4:11:04,  1.31it/s]  3%|▎         | 648/20300 [08:40<4:09:39,  1.31it/s]  3%|▎         | 660/20300 [08:49<4:08:35,  1.32it/s]  3%|▎         | 672/20300 [08:58<4:07:40,  1.32it/s]  3%|▎         | 684/20300 [09:07<4:06:38,  1.33it/s]  3%|▎         | 696/20300 [09:16<4:05:30,  1.33it/s]  3%|▎         | 708/20300 [09:25<4:03:52,  1.34it/s]  4%|▎         | 720/20300 [09:34<4:02:30,  1.35it/s]  4%|▎         | 732/20300 [09:42<4:01:05,  1.35it/s]  4%|▎         | 744/20300 [09:51<3:59:52,  1.36it/s]  4%|▎         | 756/20300 [10:00<3:58:50,  1.36it/s]  4%|▍         | 768/20300 [10:09<3:57:41,  1.37it/s]  4%|▍         | 780/20300 [10:17<3:56:35,  1.38it/s]  4%|▍         | 792/20300 [10:26<3:55:40,  1.38it/s]  4%|▍         | 804/20300 [10:34<3:54:36,  1.39it/s]  4%|▍         | 816/20300 [10:43<3:53:38,  1.39it/s]  4%|▍         | 828/20300 [10:52<3:52:28,  1.40it/s]  4%|▍         | 840/20300 [11:00<3:51:37,  1.40it/s]  4%|▍         | 852/20300 [11:08<3:50:45,  1.40it/s]  4%|▍         | 864/20300 [11:17<3:50:07,  1.41it/s]  4%|▍         | 876/20300 [11:25<3:49:10,  1.41it/s]  4%|▍         | 888/20300 [11:34<3:48:19,  1.42it/s]  4%|▍         | 900/20300 [11:42<3:47:41,  1.42it/s]  4%|▍         | 912/20300 [11:51<3:47:20,  1.42it/s]  5%|▍         | 924/20300 [11:59<3:46:24,  1.43it/s]  5%|▍         | 936/20300 [12:07<3:45:24,  1.43it/s]  5%|▍         | 948/20300 [12:16<3:44:12,  1.44it/s]  5%|▍         | 960/20300 [12:24<3:42:51,  1.45it/s]  5%|▍         | 972/20300 [12:32<3:41:15,  1.46it/s]  5%|▍         | 984/20300 [12:40<3:40:27,  1.46it/s]  5%|▍         | 996/20300 [12:48<3:38:54,  1.47it/s]  5%|▍         | 1008/20300 [12:56<3:38:07,  1.47it/s]  5%|▌         | 1020/20300 [13:04<3:37:16,  1.48it/s]  5%|▌         | 1032/20300 [13:12<3:36:13,  1.49it/s]  5%|▌         | 1044/20300 [13:20<3:35:58,  1.49it/s]  5%|▌         | 1056/20300 [13:28<3:35:30,  1.49it/s]  5%|▌         | 1068/20300 [13:36<3:34:42,  1.49it/s]  5%|▌         | 1080/20300 [13:44<3:34:13,  1.50it/s]  5%|▌         | 1092/20300 [13:52<3:33:47,  1.50it/s]  5%|▌         | 1104/20300 [14:00<3:32:50,  1.50it/s]  5%|▌         | 1116/20300 [14:08<3:31:50,  1.51it/s]  6%|▌         | 1128/20300 [14:16<3:30:53,  1.52it/s]  6%|▌         | 1140/20300 [14:24<3:29:36,  1.52it/s]  6%|▌         | 1152/20300 [14:31<3:28:26,  1.53it/s]  6%|▌         | 1164/20300 [14:39<3:27:27,  1.54it/s]  6%|▌         | 1176/20300 [14:47<3:26:38,  1.54it/s]  6%|▌         | 1188/20300 [14:55<3:25:34,  1.55it/s]  6%|▌         | 1200/20300 [15:02<3:25:02,  1.55it/s]  6%|▌         | 1212/20300 [15:10<3:24:05,  1.56it/s]  6%|▌         | 1224/20300 [15:17<3:23:08,  1.57it/s]  6%|▌         | 1236/20300 [15:25<3:22:27,  1.57it/s]  6%|▌         | 1248/20300 [15:33<3:21:43,  1.57it/s]  6%|▌         | 1260/20300 [15:40<3:20:52,  1.58it/s]  6%|▋         | 1272/20300 [15:48<3:20:26,  1.58it/s]  6%|▋         | 1284/20300 [15:55<3:19:36,  1.59it/s]  6%|▋         | 1296/20300 [16:03<3:18:50,  1.59it/s]  6%|▋         | 1308/20300 [16:10<3:18:42,  1.59it/s]  7%|▋         | 1320/20300 [16:18<3:18:06,  1.60it/s]  7%|▋         | 1332/20300 [16:25<3:17:08,  1.60it/s]  7%|▋         | 1344/20300 [16:33<3:16:56,  1.60it/s]  7%|▋         | 1356/20300 [16:40<3:16:32,  1.61it/s]  7%|▋         | 1368/20300 [16:47<3:16:21,  1.61it/s]  7%|▋         | 1380/20300 [16:55<3:15:55,  1.61it/s]  7%|▋         | 1392/20300 [17:02<3:14:25,  1.62it/s]  7%|▋         | 1404/20300 [17:09<3:12:55,  1.63it/s]  7%|▋         | 1416/20300 [17:17<3:11:29,  1.64it/s]  7%|▋         | 1428/20300 [17:24<3:09:32,  1.66it/s]  7%|▋         | 1440/20300 [17:31<3:08:34,  1.67it/s]  7%|▋         | 1452/20300 [17:38<3:08:01,  1.67it/s]  7%|▋         | 1464/20300 [17:45<3:06:41,  1.68it/s]  7%|▋         | 1476/20300 [17:52<3:06:32,  1.68it/s]  7%|▋         | 1488/20300 [17:59<3:06:28,  1.68it/s]  7%|▋         | 1500/20300 [18:06<3:05:49,  1.69it/s]  7%|▋         | 1512/20300 [18:13<3:05:29,  1.69it/s]  8%|▊         | 1524/20300 [18:20<3:04:54,  1.69it/s]  8%|▊         | 1536/20300 [18:28<3:04:36,  1.69it/s]  8%|▊         | 1548/20300 [18:35<3:04:06,  1.70it/s]  8%|▊         | 1560/20300 [18:42<3:03:32,  1.70it/s]  8%|▊         | 1572/20300 [18:49<3:03:17,  1.70it/s]  8%|▊         | 1584/20300 [18:56<3:02:40,  1.71it/s]  8%|▊         | 1596/20300 [19:03<3:03:18,  1.70it/s]  8%|▊         | 1608/20300 [19:10<3:03:44,  1.70it/s]  8%|▊         | 1620/20300 [19:17<3:03:25,  1.70it/s]  8%|▊         | 1632/20300 [19:24<3:03:09,  1.70it/s]  8%|▊         | 1644/20300 [19:31<3:02:48,  1.70it/s]  8%|▊         | 1656/20300 [19:38<3:02:57,  1.70it/s]  8%|▊         | 1668/20300 [19:45<3:02:46,  1.70it/s]  8%|▊         | 1680/20300 [19:52<3:02:51,  1.70it/s]  8%|▊         | 1692/20300 [19:59<3:02:38,  1.70it/s]  8%|▊         | 1704/20300 [20:06<3:02:06,  1.70it/s]  8%|▊         | 1716/20300 [20:13<3:01:51,  1.70it/s]  9%|▊         | 1728/20300 [20:20<3:01:20,  1.71it/s]  9%|▊         | 1740/20300 [20:27<3:00:58,  1.71it/s]  9%|▊         | 1752/20300 [20:34<3:00:38,  1.71it/s]  9%|▊         | 1764/20300 [20:41<2:59:40,  1.72it/s]  9%|▊         | 1776/20300 [20:48<2:59:26,  1.72it/s]  9%|▉         | 1788/20300 [20:55<2:58:43,  1.73it/s]  9%|▉         | 1800/20300 [21:02<2:58:13,  1.73it/s]  9%|▉         | 1812/20300 [21:09<2:57:19,  1.74it/s]  9%|▉         | 1824/20300 [21:16<2:56:45,  1.74it/s]  9%|▉         | 1836/20300 [21:22<2:56:04,  1.75it/s]  9%|▉         | 1848/20300 [21:29<2:55:40,  1.75it/s]  9%|▉         | 1860/20300 [21:36<2:54:53,  1.76it/s]  9%|▉         | 1872/20300 [21:43<2:53:14,  1.77it/s]  9%|▉         | 1884/20300 [21:49<2:52:15,  1.78it/s]  9%|▉         | 1896/20300 [21:56<2:51:29,  1.79it/s]  9%|▉         | 1908/20300 [22:03<2:50:37,  1.80it/s]  9%|▉         | 1920/20300 [22:09<2:49:44,  1.80it/s] 10%|▉         | 1932/20300 [22:16<2:49:41,  1.80it/s] 10%|▉         | 1944/20300 [22:22<2:49:02,  1.81it/s] 10%|▉         | 1956/20300 [22:29<2:48:43,  1.81it/s] 10%|▉         | 1968/20300 [22:36<2:49:23,  1.80it/s] 10%|▉         | 1980/20300 [22:42<2:49:29,  1.80it/s] 10%|▉         | 1992/20300 [22:49<2:49:09,  1.80it/s] 10%|▉         | 2004/20300 [22:56<2:49:09,  1.80it/s] 10%|▉         | 2016/20300 [23:02<2:49:03,  1.80it/s] 10%|▉         | 2028/20300 [23:09<2:48:47,  1.80it/s] 10%|█         | 2040/20300 [23:16<2:48:38,  1.80it/s] 10%|█         | 2052/20300 [23:22<2:48:39,  1.80it/s] 10%|█         | 2064/20300 [23:29<2:48:25,  1.80it/s] 10%|█         | 2076/20300 [23:36<2:48:17,  1.80it/s] 10%|█         | 2088/20300 [23:42<2:48:07,  1.81it/s] 10%|█         | 2100/20300 [23:49<2:47:45,  1.81it/s] 10%|█         | 2112/20300 [23:55<2:47:23,  1.81it/s] 10%|█         | 2124/20300 [24:02<2:46:38,  1.82it/s] 11%|█         | 2136/20300 [24:09<2:46:08,  1.82it/s] 11%|█         | 2148/20300 [24:15<2:45:34,  1.83it/s] 11%|█         | 2160/20300 [24:22<2:44:54,  1.83it/s] 11%|█         | 2172/20300 [24:28<2:43:16,  1.85it/s] 11%|█         | 2184/20300 [24:34<2:42:38,  1.86it/s] 11%|█         | 2196/20300 [24:41<2:42:08,  1.86it/s] 11%|█         | 2208/20300 [24:47<2:40:08,  1.88it/s] 11%|█         | 2220/20300 [24:53<2:39:36,  1.89it/s] 11%|█         | 2232/20300 [25:00<2:39:40,  1.89it/s] 11%|█         | 2244/20300 [25:06<2:38:20,  1.90it/s] 11%|█         | 2256/20300 [25:12<2:37:42,  1.91it/s] 11%|█         | 2268/20300 [25:18<2:37:36,  1.91it/s] 11%|█         | 2280/20300 [25:25<2:36:46,  1.92it/s] 11%|█▏        | 2292/20300 [25:31<2:36:12,  1.92it/s] 11%|█▏        | 2304/20300 [25:37<2:36:13,  1.92it/s] 11%|█▏        | 2316/20300 [25:43<2:35:51,  1.92it/s] 11%|█▏        | 2328/20300 [25:49<2:35:03,  1.93it/s] 12%|█▏        | 2340/20300 [25:56<2:35:10,  1.93it/s] 12%|█▏        | 2352/20300 [26:02<2:35:23,  1.93it/s] 12%|█▏        | 2364/20300 [26:08<2:34:49,  1.93it/s] 12%|█▏        | 2376/20300 [26:14<2:35:38,  1.92it/s] 12%|█▏        | 2388/20300 [26:21<2:36:02,  1.91it/s] 12%|█▏        | 2400/20300 [26:27<2:35:32,  1.92it/s] 12%|█▏        | 2412/20300 [26:33<2:35:31,  1.92it/s] 12%|█▏        | 2424/20300 [26:39<2:35:13,  1.92it/s] 12%|█▏        | 2436/20300 [26:46<2:34:50,  1.92it/s] 12%|█▏        | 2448/20300 [26:52<2:34:25,  1.93it/s] 12%|█▏        | 2460/20300 [26:58<2:33:57,  1.93it/s] 12%|█▏        | 2472/20300 [27:04<2:33:42,  1.93it/s] 12%|█▏        | 2484/20300 [27:10<2:33:38,  1.93it/s] 12%|█▏        | 2496/20300 [27:17<2:33:27,  1.93it/s] 12%|█▏        | 2508/20300 [27:23<2:31:40,  1.96it/s] 12%|█▏        | 2520/20300 [27:29<2:30:45,  1.97it/s] 12%|█▏        | 2532/20300 [27:35<2:30:41,  1.97it/s] 13%|█▎        | 2544/20300 [27:41<2:29:56,  1.97it/s] 13%|█▎        | 2556/20300 [27:47<2:28:56,  1.99it/s] 13%|█▎        | 2568/20300 [27:53<2:28:30,  1.99it/s] 13%|█▎        | 2580/20300 [27:59<2:28:02,  1.99it/s] 13%|█▎        | 2592/20300 [28:05<2:27:19,  2.00it/s] 13%|█▎        | 2604/20300 [28:11<2:26:52,  2.01it/s] 13%|█▎        | 2616/20300 [28:16<2:26:11,  2.02it/s] 13%|█▎        | 2628/20300 [28:22<2:26:02,  2.02it/s] 13%|█▎        | 2640/20300 [28:28<2:25:46,  2.02it/s] 13%|█▎        | 2652/20300 [28:34<2:25:10,  2.03it/s] 13%|█▎        | 2664/20300 [28:40<2:24:31,  2.03it/s] 13%|█▎        | 2676/20300 [28:46<2:24:30,  2.03it/s] 13%|█▎        | 2688/20300 [28:52<2:24:20,  2.03it/s] 13%|█▎        | 2700/20300 [28:58<2:24:31,  2.03it/s] 13%|█▎        | 2712/20300 [29:04<2:25:17,  2.02it/s] 13%|█▎        | 2724/20300 [29:10<2:25:46,  2.01it/s] 13%|█▎        | 2736/20300 [29:16<2:26:05,  2.00it/s] 14%|█▎        | 2748/20300 [29:22<2:26:33,  2.00it/s] 14%|█▎        | 2760/20300 [29:28<2:26:34,  1.99it/s] 14%|█▎        | 2772/20300 [29:34<2:26:20,  2.00it/s] 14%|█▎        | 2784/20300 [29:40<2:26:31,  1.99it/s] 14%|█▍        | 2796/20300 [29:46<2:26:03,  2.00it/s] 14%|█▍        | 2808/20300 [29:52<2:25:39,  2.00it/s] 14%|█▍        | 2820/20300 [29:58<2:25:16,  2.01it/s] 14%|█▍        | 2832/20300 [30:04<2:25:09,  2.01it/s] 14%|█▍        | 2844/20300 [30:10<2:25:01,  2.01it/s] 14%|█▍        | 2856/20300 [30:16<2:24:45,  2.01it/s] 14%|█▍        | 2868/20300 [30:22<2:24:39,  2.01it/s] 14%|█▍        | 2880/20300 [30:28<2:24:40,  2.01it/s] 14%|█▍        | 2892/20300 [30:34<2:24:18,  2.01it/s] 14%|█▍        | 2904/20300 [30:40<2:23:58,  2.01it/s] 14%|█▍        | 2916/20300 [30:46<2:23:01,  2.03it/s] 14%|█▍        | 2928/20300 [30:51<2:21:52,  2.04it/s] 14%|█▍        | 2940/20300 [30:57<2:21:14,  2.05it/s] 15%|█▍        | 2952/20300 [31:03<2:20:50,  2.05it/s] 15%|█▍        | 2964/20300 [31:09<2:20:12,  2.06it/s] 15%|█▍        | 2976/20300 [31:15<2:19:50,  2.06it/s] 15%|█▍        | 2988/20300 [31:20<2:19:50,  2.06it/s] 15%|█▍        | 3000/20300 [31:26<2:19:42,  2.06it/s] 15%|█▍        | 3012/20300 [31:32<2:19:36,  2.06it/s] 15%|█▍        | 3024/20300 [31:38<2:19:30,  2.06it/s] 15%|█▍        | 3036/20300 [31:44<2:19:27,  2.06it/s] 15%|█▌        | 3048/20300 [31:49<2:19:22,  2.06it/s] 15%|█▌        | 3060/20300 [31:55<2:19:22,  2.06it/s] 15%|█▌        | 3072/20300 [32:01<2:19:12,  2.06it/s] 15%|█▌        | 3084/20300 [32:07<2:18:59,  2.06it/s] 15%|█▌        | 3096/20300 [32:13<2:19:00,  2.06it/s] 15%|█▌        | 3108/20300 [32:19<2:18:57,  2.06it/s] 15%|█▌        | 3120/20300 [32:24<2:19:01,  2.06it/s] 15%|█▌        | 3132/20300 [32:30<2:18:59,  2.06it/s] 15%|█▌        | 3144/20300 [32:36<2:18:59,  2.06it/s] 16%|█▌        | 3156/20300 [32:42<2:19:03,  2.05it/s] 16%|█▌        | 3168/20300 [32:48<2:19:07,  2.05it/s] 16%|█▌        | 3180/20300 [32:54<2:19:04,  2.05it/s] 16%|█▌        | 3192/20300 [32:59<2:18:42,  2.06it/s] 16%|█▌        | 3204/20300 [33:05<2:18:15,  2.06it/s] 16%|█▌        | 3216/20300 [33:11<2:17:56,  2.06it/s] 16%|█▌        | 3228/20300 [33:17<2:17:29,  2.07it/s] 16%|█▌        | 3240/20300 [33:23<2:17:16,  2.07it/s] 16%|█▌        | 3252/20300 [33:28<2:17:17,  2.07it/s] 16%|█▌        | 3264/20300 [33:34<2:17:19,  2.07it/s] 16%|█▌        | 3276/20300 [33:40<2:17:17,  2.07it/s] 16%|█▌        | 3288/20300 [33:46<2:17:14,  2.07it/s] 16%|█▋        | 3300/20300 [33:52<2:17:27,  2.06it/s] 16%|█▋        | 3312/20300 [33:57<2:17:12,  2.06it/s] 16%|█▋        | 3324/20300 [34:03<2:17:01,  2.06it/s] 16%|█▋        | 3336/20300 [34:09<2:17:05,  2.06it/s] 16%|█▋        | 3348/20300 [34:15<2:17:11,  2.06it/s] 17%|█▋        | 3360/20300 [34:21<2:17:20,  2.06it/s] 17%|█▋        | 3372/20300 [34:27<2:17:19,  2.05it/s] 17%|█▋        | 3384/20300 [34:32<2:17:16,  2.05it/s] 17%|█▋        | 3396/20300 [34:38<2:17:13,  2.05it/s] 17%|█▋        | 3408/20300 [34:44<2:17:06,  2.05it/s] 17%|█▋        | 3420/20300 [34:50<2:17:02,  2.05it/s] 17%|█▋        | 3432/20300 [34:56<2:16:55,  2.05it/s] 17%|█▋        | 3444/20300 [35:02<2:16:44,  2.05it/s] 17%|█▋        | 3456/20300 [35:08<2:16:31,  2.06it/s] 17%|█▋        | 3468/20300 [35:13<2:16:02,  2.06it/s] 17%|█▋        | 3480/20300 [35:19<2:15:35,  2.07it/s] 17%|█▋        | 3492/20300 [35:25<2:15:21,  2.07it/s] 17%|█▋        | 3504/20300 [35:31<2:15:14,  2.07it/s] 17%|█▋        | 3516/20300 [35:36<2:15:00,  2.07it/s] 17%|█▋        | 3528/20300 [35:42<2:14:51,  2.07it/s] 17%|█▋        | 3540/20300 [35:48<2:14:48,  2.07it/s] 17%|█▋        | 3552/20300 [35:54<2:14:43,  2.07it/s] 18%|█▊        | 3564/20300 [36:00<2:14:07,  2.08it/s] 18%|█▊        | 3576/20300 [36:05<2:13:13,  2.09it/s] 18%|█▊        | 3588/20300 [36:11<2:12:25,  2.10it/s] 18%|█▊        | 3600/20300 [36:16<2:11:44,  2.11it/s] 18%|█▊        | 3612/20300 [36:22<2:11:26,  2.12it/s] 18%|█▊        | 3624/20300 [36:28<2:11:18,  2.12it/s] 18%|█▊        | 3636/20300 [36:33<2:10:50,  2.12it/s] 18%|█▊        | 3648/20300 [36:39<2:10:37,  2.12it/s] 18%|█▊        | 3660/20300 [36:45<2:10:54,  2.12it/s] 18%|█▊        | 3672/20300 [36:50<2:10:27,  2.12it/s] 18%|█▊        | 3684/20300 [36:56<2:09:59,  2.13it/s] 18%|█▊        | 3696/20300 [37:02<2:10:00,  2.13it/s] 18%|█▊        | 3708/20300 [37:07<2:09:54,  2.13it/s] 18%|█▊        | 3720/20300 [37:13<2:09:40,  2.13it/s] 18%|█▊        | 3732/20300 [37:18<2:09:33,  2.13it/s] 18%|█▊        | 3744/20300 [37:24<2:09:46,  2.13it/s] 19%|█▊        | 3756/20300 [37:30<2:09:45,  2.13it/s] 19%|█▊        | 3768/20300 [37:35<2:10:00,  2.12it/s] 19%|█▊        | 3780/20300 [37:41<2:10:27,  2.11it/s] 19%|█▊        | 3792/20300 [37:47<2:10:20,  2.11it/s] 19%|█▊        | 3804/20300 [37:53<2:10:23,  2.11it/s] 19%|█▉        | 3816/20300 [37:58<2:10:31,  2.10it/s] 19%|█▉        | 3828/20300 [38:04<2:10:18,  2.11it/s] 19%|█▉        | 3840/20300 [38:10<2:10:20,  2.10it/s] 19%|█▉        | 3852/20300 [38:15<2:10:25,  2.10it/s] 19%|█▉        | 3864/20300 [38:21<2:10:11,  2.10it/s] 19%|█▉        | 3876/20300 [38:27<2:10:13,  2.10it/s] 19%|█▉        | 3888/20300 [38:33<2:10:03,  2.10it/s] 19%|█▉        | 3900/20300 [38:38<2:09:39,  2.11it/s] 19%|█▉        | 3912/20300 [38:44<2:09:23,  2.11it/s] 19%|█▉        | 3924/20300 [38:50<2:09:05,  2.11it/s] 19%|█▉        | 3936/20300 [38:55<2:09:19,  2.11it/s] 19%|█▉        | 3948/20300 [39:01<2:09:07,  2.11it/s] 20%|█▉        | 3960/20300 [39:07<2:08:45,  2.12it/s] 20%|█▉        | 3972/20300 [39:12<2:08:38,  2.12it/s] 20%|█▉        | 3984/20300 [39:18<2:08:25,  2.12it/s] 20%|█▉        | 3996/20300 [39:24<2:08:21,  2.12it/s] 20%|█▉        | 4008/20300 [39:29<2:08:27,  2.11it/s] 20%|█▉        | 4020/20300 [39:35<2:08:30,  2.11it/s] 20%|█▉        | 4032/20300 [39:41<2:08:17,  2.11it/s] 20%|█▉        | 4044/20300 [39:46<2:08:15,  2.11it/s] 20%|█▉        | 4056/20300 [39:52<2:08:18,  2.11it/s] 20%|██        | 4068/20300 [39:58<2:08:23,  2.11it/s] 20%|██        | 4080/20300 [40:04<2:08:48,  2.10it/s] 20%|██        | 4092/20300 [40:09<2:08:43,  2.10it/s] 20%|██        | 4104/20300 [40:15<2:08:49,  2.10it/s] 20%|██        | 4116/20300 [40:21<2:08:39,  2.10it/s] 20%|██        | 4128/20300 [40:26<2:08:20,  2.10it/s] 20%|██        | 4140/20300 [40:32<2:08:08,  2.10it/s] 20%|██        | 4152/20300 [40:38<2:07:55,  2.10it/s] 21%|██        | 4164/20300 [40:43<2:07:37,  2.11it/s] 21%|██        | 4176/20300 [40:49<2:07:32,  2.11it/s] 21%|██        | 4188/20300 [40:55<2:07:19,  2.11it/s] 21%|██        | 4200/20300 [41:00<2:06:50,  2.12it/s] 21%|██        | 4212/20300 [41:06<2:06:44,  2.12it/s] 21%|██        | 4224/20300 [41:12<2:06:45,  2.11it/s] 21%|██        | 4236/20300 [41:18<2:06:39,  2.11it/s] 21%|██        | 4248/20300 [41:23<2:06:34,  2.11it/s] 21%|██        | 4260/20300 [41:29<2:06:13,  2.12it/s] 21%|██        | 4272/20300 [41:34<2:05:12,  2.13it/s] 21%|██        | 4284/20300 [41:40<2:04:41,  2.14it/s] 21%|██        | 4296/20300 [41:45<2:03:46,  2.15it/s] 21%|██        | 4308/20300 [41:51<2:02:58,  2.17it/s] 21%|██▏       | 4320/20300 [41:56<2:02:54,  2.17it/s] 21%|██▏       | 4332/20300 [42:02<2:02:36,  2.17it/s] 21%|██▏       | 4344/20300 [42:07<2:02:04,  2.18it/s] 21%|██▏       | 4356/20300 [42:13<2:02:23,  2.17it/s] 22%|██▏       | 4368/20300 [42:18<2:02:05,  2.17it/s] 22%|██▏       | 4380/20300 [42:24<2:01:50,  2.18it/s] 22%|██▏       | 4392/20300 [42:29<2:01:52,  2.18it/s] 22%|██▏       | 4404/20300 [42:35<2:01:45,  2.18it/s] 22%|██▏       | 4416/20300 [42:40<2:01:37,  2.18it/s] 22%|██▏       | 4428/20300 [42:46<2:01:32,  2.18it/s] 22%|██▏       | 4440/20300 [42:52<2:01:35,  2.17it/s] 22%|██▏       | 4452/20300 [42:57<2:01:32,  2.17it/s] 22%|██▏       | 4464/20300 [43:03<2:01:34,  2.17it/s] 22%|██▏       | 4476/20300 [43:08<2:02:03,  2.16it/s] 22%|██▏       | 4488/20300 [43:14<2:02:11,  2.16it/s] 22%|██▏       | 4500/20300 [43:19<2:02:00,  2.16it/s] 22%|██▏       | 4512/20300 [43:25<2:01:57,  2.16it/s] 22%|██▏       | 4524/20300 [43:30<2:01:43,  2.16it/s] 22%|██▏       | 4536/20300 [43:36<2:01:36,  2.16it/s] 22%|██▏       | 4548/20300 [43:42<2:01:39,  2.16it/s] 22%|██▏       | 4560/20300 [43:47<2:01:39,  2.16it/s] 23%|██▎       | 4572/20300 [43:53<2:01:45,  2.15it/s] 23%|██▎       | 4584/20300 [43:58<2:01:48,  2.15it/s] 23%|██▎       | 4596/20300 [44:04<2:01:50,  2.15it/s] 23%|██▎       | 4608/20300 [44:10<2:01:42,  2.15it/s] 23%|██▎       | 4620/20300 [44:15<2:01:22,  2.15it/s] 23%|██▎       | 4632/20300 [44:21<2:01:01,  2.16it/s] 23%|██▎       | 4644/20300 [44:26<2:01:01,  2.16it/s] 23%|██▎       | 4656/20300 [44:32<2:01:06,  2.15it/s] 23%|██▎       | 4668/20300 [44:37<2:00:42,  2.16it/s] 23%|██▎       | 4680/20300 [44:43<2:00:31,  2.16it/s] 23%|██▎       | 4692/20300 [44:48<2:00:23,  2.16it/s] 23%|██▎       | 4704/20300 [44:54<2:00:16,  2.16it/s] 23%|██▎       | 4716/20300 [44:59<2:00:01,  2.16it/s] 23%|██▎       | 4728/20300 [45:05<1:59:59,  2.16it/s] 23%|██▎       | 4740/20300 [45:11<2:00:07,  2.16it/s] 23%|██▎       | 4752/20300 [45:16<1:59:55,  2.16it/s] 23%|██▎       | 4764/20300 [45:22<1:59:51,  2.16it/s] 24%|██▎       | 4776/20300 [45:27<1:59:47,  2.16it/s] 24%|██▎       | 4788/20300 [45:33<1:59:31,  2.16it/s] 24%|██▎       | 4800/20300 [45:38<1:59:31,  2.16it/s] 24%|██▎       | 4812/20300 [45:44<1:59:20,  2.16it/s] 24%|██▍       | 4824/20300 [45:49<1:59:18,  2.16it/s] 24%|██▍       | 4836/20300 [45:55<1:59:05,  2.16it/s] 24%|██▍       | 4848/20300 [46:01<1:58:55,  2.17it/s] 24%|██▍       | 4860/20300 [46:06<1:58:39,  2.17it/s] 24%|██▍       | 4872/20300 [46:12<1:58:30,  2.17it/s] 24%|██▍       | 4884/20300 [46:17<1:58:17,  2.17it/s] 24%|██▍       | 4896/20300 [46:23<1:58:13,  2.17it/s] 24%|██▍       | 4908/20300 [46:28<1:58:03,  2.17it/s] 24%|██▍       | 4920/20300 [46:34<1:57:49,  2.18it/s] 24%|██▍       | 4932/20300 [46:39<1:57:40,  2.18it/s] 24%|██▍       | 4944/20300 [46:45<1:57:35,  2.18it/s] 24%|██▍       | 4956/20300 [46:50<1:57:22,  2.18it/s] 24%|██▍       | 4968/20300 [46:56<1:57:14,  2.18it/s] 25%|██▍       | 4980/20300 [47:01<1:56:58,  2.18it/s] 25%|██▍       | 4992/20300 [47:07<1:56:41,  2.19it/s] 25%|██▍       | 5004/20300 [47:12<1:56:44,  2.18it/s] 25%|██▍       | 5016/20300 [47:18<1:56:38,  2.18it/s] 25%|██▍       | 5028/20300 [47:23<1:56:26,  2.19it/s] 25%|██▍       | 5040/20300 [47:29<1:56:16,  2.19it/s] 25%|██▍       | 5052/20300 [47:34<1:56:15,  2.19it/s] 25%|██▍       | 5064/20300 [47:40<1:56:09,  2.19it/s] 25%|██▌       | 5076/20300 [47:45<1:55:40,  2.19it/s] 25%|██▌       | 5088/20300 [47:50<1:55:16,  2.20it/s] 25%|██▌       | 5100/20300 [47:56<1:54:49,  2.21it/s] 25%|██▌       | 5112/20300 [48:01<1:54:37,  2.21it/s] 25%|██▌       | 5124/20300 [48:07<1:54:37,  2.21it/s] 25%|██▌       | 5136/20300 [48:12<1:54:52,  2.20it/s] 25%|██▌       | 5148/20300 [48:18<1:54:34,  2.20it/s] 25%|██▌       | 5160/20300 [48:23<1:54:28,  2.20it/s] 25%|██▌       | 5172/20300 [48:28<1:54:25,  2.20it/s] 26%|██▌       | 5184/20300 [48:34<1:54:19,  2.20it/s] 26%|██▌       | 5196/20300 [48:39<1:53:53,  2.21it/s] 26%|██▌       | 5208/20300 [48:45<1:52:43,  2.23it/s] 26%|██▌       | 5220/20300 [48:50<1:51:46,  2.25it/s] 26%|██▌       | 5232/20300 [48:55<1:51:24,  2.25it/s] 26%|██▌       | 5244/20300 [49:00<1:50:51,  2.26it/s] 26%|██▌       | 5256/20300 [49:06<1:50:47,  2.26it/s] 26%|██▌       | 5268/20300 [49:11<1:50:51,  2.26it/s] 26%|██▌       | 5280/20300 [49:16<1:50:39,  2.26it/s] 26%|██▌       | 5292/20300 [49:22<1:50:25,  2.27it/s] 26%|██▌       | 5304/20300 [49:27<1:50:18,  2.27it/s] 26%|██▌       | 5316/20300 [49:32<1:50:02,  2.27it/s] 26%|██▌       | 5328/20300 [49:37<1:49:52,  2.27it/s] 26%|██▋       | 5340/20300 [49:43<1:49:58,  2.27it/s] 26%|██▋       | 5352/20300 [49:48<1:49:36,  2.27it/s] 26%|██▋       | 5364/20300 [49:53<1:49:16,  2.28it/s] 26%|██▋       | 5376/20300 [49:58<1:48:51,  2.28it/s] 27%|██▋       | 5388/20300 [50:04<1:48:29,  2.29it/s] 27%|██▋       | 5400/20300 [50:09<1:48:00,  2.30it/s] 27%|██▋       | 5412/20300 [50:14<1:47:58,  2.30it/s] 27%|██▋       | 5424/20300 [50:19<1:47:56,  2.30it/s] 27%|██▋       | 5436/20300 [50:24<1:48:08,  2.29it/s] 27%|██▋       | 5448/20300 [50:30<1:48:37,  2.28it/s] 27%|██▋       | 5460/20300 [50:35<1:49:31,  2.26it/s] 27%|██▋       | 5472/20300 [50:41<1:50:14,  2.24it/s] 27%|██▋       | 5484/20300 [50:46<1:50:47,  2.23it/s] 27%|██▋       | 5496/20300 [50:52<1:51:18,  2.22it/s] 27%|██▋       | 5508/20300 [50:57<1:51:18,  2.21it/s] 27%|██▋       | 5520/20300 [51:02<1:51:13,  2.21it/s] 27%|██▋       | 5532/20300 [51:08<1:51:22,  2.21it/s] 27%|██▋       | 5544/20300 [51:13<1:50:38,  2.22it/s] 27%|██▋       | 5556/20300 [51:19<1:49:42,  2.24it/s] 27%|██▋       | 5568/20300 [51:24<1:48:57,  2.25it/s] 27%|██▋       | 5580/20300 [51:29<1:48:20,  2.26it/s] 28%|██▊       | 5592/20300 [51:34<1:47:49,  2.27it/s] 28%|██▊       | 5604/20300 [51:40<1:47:35,  2.28it/s] 28%|██▊       | 5616/20300 [51:45<1:47:18,  2.28it/s] 28%|██▊       | 5628/20300 [51:50<1:47:12,  2.28it/s] 28%|██▊       | 5640/20300 [51:55<1:47:14,  2.28it/s] 28%|██▊       | 5652/20300 [52:01<1:47:01,  2.28it/s] 28%|██▊       | 5664/20300 [52:06<1:47:12,  2.28it/s] 28%|██▊       | 5676/20300 [52:11<1:47:29,  2.27it/s] 28%|██▊       | 5688/20300 [52:16<1:47:31,  2.26it/s] 28%|██▊       | 5700/20300 [52:22<1:47:37,  2.26it/s] 28%|██▊       | 5712/20300 [52:27<1:47:36,  2.26it/s] 28%|██▊       | 5724/20300 [52:32<1:47:06,  2.27it/s] 28%|██▊       | 5736/20300 [52:38<1:47:01,  2.27it/s] 28%|██▊       | 5748/20300 [52:43<1:47:04,  2.27it/s] 28%|██▊       | 5760/20300 [52:48<1:46:46,  2.27it/s] 28%|██▊       | 5772/20300 [52:54<1:46:36,  2.27it/s] 28%|██▊       | 5784/20300 [52:59<1:46:30,  2.27it/s] 29%|██▊       | 5796/20300 [53:04<1:46:17,  2.27it/s] 29%|██▊       | 5808/20300 [53:09<1:46:12,  2.27it/s] 29%|██▊       | 5820/20300 [53:15<1:46:04,  2.28it/s] 29%|██▊       | 5832/20300 [53:20<1:45:53,  2.28it/s] 29%|██▉       | 5844/20300 [53:25<1:45:41,  2.28it/s] 29%|██▉       | 5856/20300 [53:30<1:45:49,  2.27it/s] 29%|██▉       | 5868/20300 [53:36<1:45:44,  2.27it/s] 29%|██▉       | 5880/20300 [53:41<1:45:27,  2.28it/s] 29%|██▉       | 5892/20300 [53:46<1:45:22,  2.28it/s] 29%|██▉       | 5904/20300 [53:51<1:45:03,  2.28it/s] 29%|██▉       | 5916/20300 [53:57<1:44:49,  2.29it/s] 29%|██▉       | 5928/20300 [54:02<1:44:54,  2.28it/s] 29%|██▉       | 5940/20300 [54:07<1:44:33,  2.29it/s] 29%|██▉       | 5952/20300 [54:12<1:44:15,  2.29it/s] 29%|██▉       | 5964/20300 [54:18<1:44:11,  2.29it/s] 29%|██▉       | 5976/20300 [54:23<1:45:12,  2.27it/s] 29%|██▉       | 5988/20300 [54:28<1:44:50,  2.28it/s] 30%|██▉       | 6000/20300 [54:33<1:44:16,  2.29it/s] 30%|██▉       | 6012/20300 [54:39<1:44:20,  2.28it/s] 30%|██▉       | 6024/20300 [54:44<1:44:34,  2.28it/s] 30%|██▉       | 6036/20300 [54:49<1:44:48,  2.27it/s] 30%|██▉       | 6048/20300 [54:55<1:44:15,  2.28it/s] 30%|██▉       | 6060/20300 [55:00<1:43:58,  2.28it/s] 30%|██▉       | 6072/20300 [55:05<1:43:41,  2.29it/s] 30%|██▉       | 6084/20300 [55:10<1:43:17,  2.29it/s] 30%|███       | 6096/20300 [55:15<1:43:01,  2.30it/s] 30%|███       | 6108/20300 [55:21<1:42:49,  2.30it/s] 30%|███       | 6120/20300 [55:26<1:42:49,  2.30it/s] 30%|███       | 6132/20300 [55:31<1:43:04,  2.29it/s] 30%|███       | 6144/20300 [55:36<1:43:04,  2.29it/s] 30%|███       | 6156/20300 [55:42<1:43:07,  2.29it/s] 30%|███       | 6168/20300 [55:47<1:43:09,  2.28it/s] 30%|███       | 6180/20300 [55:52<1:42:48,  2.29it/s] 31%|███       | 6192/20300 [55:57<1:42:11,  2.30it/s] 31%|███       | 6204/20300 [56:02<1:41:11,  2.32it/s] 31%|███       | 6216/20300 [56:07<1:40:24,  2.34it/s] 31%|███       | 6228/20300 [56:13<1:40:20,  2.34it/s] 31%|███       | 6240/20300 [56:18<1:39:58,  2.34it/s] 31%|███       | 6252/20300 [56:23<1:39:52,  2.34it/s] 31%|███       | 6264/20300 [56:28<1:40:03,  2.34it/s] 31%|███       | 6276/20300 [56:33<1:39:59,  2.34it/s] 31%|███       | 6288/20300 [56:38<1:39:47,  2.34it/s] 31%|███       | 6300/20300 [56:43<1:39:50,  2.34it/s] 31%|███       | 6312/20300 [56:48<1:39:47,  2.34it/s] 31%|███       | 6324/20300 [56:54<1:39:28,  2.34it/s] 31%|███       | 6336/20300 [56:59<1:39:38,  2.34it/s] 31%|███▏      | 6348/20300 [57:04<1:39:22,  2.34it/s] 31%|███▏      | 6360/20300 [57:09<1:39:12,  2.34it/s] 31%|███▏      | 6372/20300 [57:14<1:39:14,  2.34it/s] 31%|███▏      | 6384/20300 [57:19<1:38:59,  2.34it/s] 32%|███▏      | 6396/20300 [57:24<1:38:44,  2.35it/s] 32%|███▏      | 6408/20300 [57:29<1:38:25,  2.35it/s] 32%|███▏      | 6420/20300 [57:34<1:37:51,  2.36it/s] 32%|███▏      | 6432/20300 [57:39<1:37:33,  2.37it/s] 32%|███▏      | 6444/20300 [57:44<1:37:26,  2.37it/s] 32%|███▏      | 6456/20300 [57:50<1:37:57,  2.36it/s] 32%|███▏      | 6468/20300 [57:55<1:38:17,  2.35it/s] 32%|███▏      | 6480/20300 [58:00<1:38:28,  2.34it/s] 32%|███▏      | 6492/20300 [58:05<1:38:49,  2.33it/s] 32%|███▏      | 6504/20300 [58:10<1:39:00,  2.32it/s] 32%|███▏      | 6516/20300 [58:16<1:39:04,  2.32it/s] 32%|███▏      | 6528/20300 [58:21<1:39:14,  2.31it/s] 32%|███▏      | 6540/20300 [58:26<1:39:21,  2.31it/s] 32%|███▏      | 6552/20300 [58:31<1:39:37,  2.30it/s] 32%|███▏      | 6564/20300 [58:36<1:39:28,  2.30it/s] 32%|███▏      | 6576/20300 [58:42<1:38:48,  2.32it/s] 32%|███▏      | 6588/20300 [58:47<1:38:06,  2.33it/s] 33%|███▎      | 6600/20300 [58:52<1:37:30,  2.34it/s] 33%|███▎      | 6612/20300 [58:57<1:37:00,  2.35it/s] 33%|███▎      | 6624/20300 [59:02<1:36:43,  2.36it/s] 33%|███▎      | 6636/20300 [59:07<1:36:34,  2.36it/s] 33%|███▎      | 6648/20300 [59:12<1:36:31,  2.36it/s] 33%|███▎      | 6660/20300 [59:17<1:36:28,  2.36it/s] 33%|███▎      | 6672/20300 [59:22<1:36:20,  2.36it/s] 33%|███▎      | 6684/20300 [59:27<1:36:20,  2.36it/s] 33%|███▎      | 6696/20300 [59:32<1:36:26,  2.35it/s] 33%|███▎      | 6708/20300 [59:37<1:36:05,  2.36it/s] 33%|███▎      | 6720/20300 [59:43<1:35:48,  2.36it/s] 33%|███▎      | 6732/20300 [59:48<1:35:48,  2.36it/s] 33%|███▎      | 6744/20300 [59:53<1:35:44,  2.36it/s] 33%|███▎      | 6756/20300 [59:58<1:35:24,  2.37it/s] 33%|███▎      | 6768/20300 [1:00:03<1:35:09,  2.37it/s] 33%|███▎      | 6780/20300 [1:00:08<1:34:52,  2.38it/s] 33%|███▎      | 6792/20300 [1:00:13<1:34:14,  2.39it/s] 34%|███▎      | 6804/20300 [1:00:18<1:34:02,  2.39it/s] 34%|███▎      | 6816/20300 [1:00:23<1:34:01,  2.39it/s] 34%|███▎      | 6828/20300 [1:00:28<1:34:20,  2.38it/s] 34%|███▎      | 6840/20300 [1:00:33<1:34:55,  2.36it/s] 34%|███▍      | 6852/20300 [1:00:38<1:35:22,  2.35it/s] 34%|███▍      | 6864/20300 [1:00:43<1:35:38,  2.34it/s] 34%|███▍      | 6876/20300 [1:00:49<1:35:51,  2.33it/s] 34%|███▍      | 6888/20300 [1:00:54<1:35:55,  2.33it/s] 34%|███▍      | 6900/20300 [1:00:59<1:35:56,  2.33it/s] 34%|███▍      | 6912/20300 [1:01:04<1:36:05,  2.32it/s] 34%|███▍      | 6924/20300 [1:01:09<1:36:17,  2.32it/s] 34%|███▍      | 6936/20300 [1:01:15<1:36:17,  2.31it/s] 34%|███▍      | 6948/20300 [1:01:20<1:35:42,  2.32it/s] 34%|███▍      | 6960/20300 [1:01:25<1:34:56,  2.34it/s] 34%|███▍      | 6972/20300 [1:01:30<1:34:23,  2.35it/s] 34%|███▍      | 6984/20300 [1:01:35<1:33:40,  2.37it/s] 34%|███▍      | 6996/20300 [1:01:40<1:33:18,  2.38it/s] 35%|███▍      | 7008/20300 [1:01:45<1:33:13,  2.38it/s] 35%|███▍      | 7020/20300 [1:01:50<1:33:07,  2.38it/s] 35%|███▍      | 7032/20300 [1:01:55<1:32:55,  2.38it/s] 35%|███▍      | 7044/20300 [1:02:00<1:32:50,  2.38it/s] 35%|███▍      | 7056/20300 [1:02:05<1:32:48,  2.38it/s] 35%|███▍      | 7068/20300 [1:02:10<1:32:35,  2.38it/s] 35%|███▍      | 7080/20300 [1:02:15<1:32:36,  2.38it/s] 35%|███▍      | 7092/20300 [1:02:20<1:32:19,  2.38it/s] 35%|███▍      | 7104/20300 [1:02:25<1:31:52,  2.39it/s] 35%|███▌      | 7116/20300 [1:02:30<1:31:51,  2.39it/s] 35%|███▌      | 7128/20300 [1:02:35<1:31:42,  2.39it/s] 35%|███▌      | 7140/20300 [1:02:40<1:31:26,  2.40it/s] 35%|███▌      | 7152/20300 [1:02:45<1:31:38,  2.39it/s] 35%|███▌      | 7164/20300 [1:02:50<1:31:57,  2.38it/s] 35%|███▌      | 7176/20300 [1:02:55<1:32:40,  2.36it/s] 35%|███▌      | 7188/20300 [1:03:01<1:33:11,  2.34it/s] 35%|███▌      | 7200/20300 [1:03:06<1:33:24,  2.34it/s] 36%|███▌      | 7212/20300 [1:03:11<1:33:30,  2.33it/s] 36%|███▌      | 7224/20300 [1:03:16<1:33:12,  2.34it/s] 36%|███▌      | 7236/20300 [1:03:21<1:32:34,  2.35it/s] 36%|███▌      | 7248/20300 [1:03:26<1:31:56,  2.37it/s] 36%|███▌      | 7260/20300 [1:03:31<1:31:20,  2.38it/s] 36%|███▌      | 7272/20300 [1:03:36<1:31:04,  2.38it/s] 36%|███▌      | 7284/20300 [1:03:41<1:30:54,  2.39it/s] 36%|███▌      | 7296/20300 [1:03:46<1:30:40,  2.39it/s] 36%|███▌      | 7308/20300 [1:03:51<1:30:23,  2.40it/s] 36%|███▌      | 7320/20300 [1:03:56<1:30:19,  2.40it/s] 36%|███▌      | 7332/20300 [1:04:01<1:30:19,  2.39it/s] 36%|███▌      | 7344/20300 [1:04:06<1:30:19,  2.39it/s] 36%|███▌      | 7356/20300 [1:04:11<1:30:18,  2.39it/s] 36%|███▋      | 7368/20300 [1:04:16<1:30:10,  2.39it/s] 36%|███▋      | 7380/20300 [1:04:21<1:30:05,  2.39it/s] 36%|███▋      | 7392/20300 [1:04:26<1:30:16,  2.38it/s] 36%|███▋      | 7404/20300 [1:04:31<1:30:01,  2.39it/s] 37%|███▋      | 7416/20300 [1:04:36<1:29:55,  2.39it/s] 37%|███▋      | 7428/20300 [1:04:41<1:30:06,  2.38it/s] 37%|███▋      | 7440/20300 [1:04:46<1:30:01,  2.38it/s] 37%|███▋      | 7452/20300 [1:04:51<1:30:06,  2.38it/s] 37%|███▋      | 7464/20300 [1:04:57<1:30:12,  2.37it/s] 37%|███▋      | 7476/20300 [1:05:02<1:30:31,  2.36it/s] 37%|███▋      | 7488/20300 [1:05:07<1:31:00,  2.35it/s] 37%|███▋      | 7500/20300 [1:05:12<1:31:07,  2.34it/s] 37%|███▋      | 7512/20300 [1:05:17<1:31:19,  2.33it/s] 37%|███▋      | 7524/20300 [1:05:22<1:31:26,  2.33it/s] 37%|███▋      | 7536/20300 [1:05:27<1:31:16,  2.33it/s] 37%|███▋      | 7548/20300 [1:05:33<1:31:15,  2.33it/s] 37%|███▋      | 7560/20300 [1:05:38<1:31:17,  2.33it/s] 37%|███▋      | 7572/20300 [1:05:43<1:31:04,  2.33it/s] 37%|███▋      | 7584/20300 [1:05:48<1:31:08,  2.33it/s] 37%|███▋      | 7596/20300 [1:05:53<1:30:31,  2.34it/s] 37%|███▋      | 7608/20300 [1:05:58<1:29:42,  2.36it/s] 38%|███▊      | 7620/20300 [1:06:03<1:29:05,  2.37it/s] 38%|███▊      | 7632/20300 [1:06:08<1:28:33,  2.38it/s] 38%|███▊      | 7644/20300 [1:06:13<1:28:08,  2.39it/s] 38%|███▊      | 7656/20300 [1:06:18<1:27:48,  2.40it/s] 38%|███▊      | 7668/20300 [1:06:23<1:27:33,  2.40it/s] 38%|███▊      | 7680/20300 [1:06:28<1:27:39,  2.40it/s] 38%|███▊      | 7692/20300 [1:06:33<1:27:21,  2.41it/s] 38%|███▊      | 7704/20300 [1:06:38<1:27:10,  2.41it/s] 38%|███▊      | 7716/20300 [1:06:43<1:27:16,  2.40it/s] 38%|███▊      | 7728/20300 [1:06:48<1:27:08,  2.40it/s] 38%|███▊      | 7740/20300 [1:06:53<1:26:52,  2.41it/s] 38%|███▊      | 7752/20300 [1:06:58<1:26:57,  2.41it/s] 38%|███▊      | 7764/20300 [1:07:03<1:26:56,  2.40it/s] 38%|███▊      | 7776/20300 [1:07:08<1:27:01,  2.40it/s] 38%|███▊      | 7788/20300 [1:07:13<1:27:00,  2.40it/s] 38%|███▊      | 7800/20300 [1:07:18<1:26:54,  2.40it/s] 38%|███▊      | 7812/20300 [1:07:23<1:26:54,  2.39it/s] 39%|███▊      | 7824/20300 [1:07:28<1:26:49,  2.39it/s] 39%|███▊      | 7836/20300 [1:07:33<1:26:47,  2.39it/s] 39%|███▊      | 7848/20300 [1:07:38<1:27:15,  2.38it/s] 39%|███▊      | 7860/20300 [1:07:43<1:27:40,  2.36it/s] 39%|███▉      | 7872/20300 [1:07:48<1:27:52,  2.36it/s] 39%|███▉      | 7884/20300 [1:07:54<1:27:58,  2.35it/s] 39%|███▉      | 7896/20300 [1:07:59<1:28:01,  2.35it/s] 39%|███▉      | 7908/20300 [1:08:04<1:28:00,  2.35it/s] 39%|███▉      | 7920/20300 [1:08:09<1:27:49,  2.35it/s] 39%|███▉      | 7932/20300 [1:08:14<1:27:42,  2.35it/s] 39%|███▉      | 7944/20300 [1:08:19<1:27:39,  2.35it/s] 39%|███▉      | 7956/20300 [1:08:24<1:27:13,  2.36it/s] 39%|███▉      | 7968/20300 [1:08:29<1:26:41,  2.37it/s] 39%|███▉      | 7980/20300 [1:08:34<1:26:01,  2.39it/s] 39%|███▉      | 7992/20300 [1:08:39<1:25:45,  2.39it/s] 39%|███▉      | 8004/20300 [1:08:44<1:25:43,  2.39it/s] 39%|███▉      | 8016/20300 [1:08:49<1:25:16,  2.40it/s] 40%|███▉      | 8028/20300 [1:08:54<1:25:02,  2.41it/s] 40%|███▉      | 8040/20300 [1:08:59<1:25:13,  2.40it/s] 40%|███▉      | 8052/20300 [1:09:04<1:24:45,  2.41it/s] 40%|███▉      | 8064/20300 [1:09:09<1:24:33,  2.41it/s] 40%|███▉      | 8076/20300 [1:09:14<1:24:36,  2.41it/s] 40%|███▉      | 8088/20300 [1:09:19<1:24:01,  2.42it/s] 40%|███▉      | 8100/20300 [1:09:24<1:23:43,  2.43it/s] 40%|███▉      | 8112/20300 [1:09:29<1:23:57,  2.42it/s] 40%|████      | 8124/20300 [1:09:34<1:24:08,  2.41it/s] 40%|████      | 8136/20300 [1:09:39<1:24:34,  2.40it/s] 40%|████      | 8148/20300 [1:09:44<1:25:04,  2.38it/s] 40%|████      | 8160/20300 [1:09:49<1:25:15,  2.37it/s] 40%|████      | 8172/20300 [1:09:54<1:25:11,  2.37it/s] 40%|████      | 8184/20300 [1:09:59<1:25:15,  2.37it/s] 40%|████      | 8196/20300 [1:10:04<1:25:10,  2.37it/s] 40%|████      | 8208/20300 [1:10:09<1:25:08,  2.37it/s] 40%|████      | 8220/20300 [1:10:14<1:25:06,  2.37it/s] 41%|████      | 8232/20300 [1:10:19<1:24:33,  2.38it/s] 41%|████      | 8244/20300 [1:10:24<1:23:49,  2.40it/s] 41%|████      | 8256/20300 [1:10:29<1:23:29,  2.40it/s] 41%|████      | 8268/20300 [1:10:34<1:23:15,  2.41it/s] 41%|████      | 8280/20300 [1:10:39<1:22:42,  2.42it/s] 41%|████      | 8292/20300 [1:10:44<1:22:27,  2.43it/s] 41%|████      | 8304/20300 [1:10:49<1:22:40,  2.42it/s] 41%|████      | 8316/20300 [1:10:54<1:22:16,  2.43it/s] 41%|████      | 8328/20300 [1:10:59<1:22:07,  2.43it/s] 41%|████      | 8340/20300 [1:11:04<1:22:15,  2.42it/s] 41%|████      | 8352/20300 [1:11:09<1:21:53,  2.43it/s] 41%|████      | 8364/20300 [1:11:14<1:21:29,  2.44it/s] 41%|████▏     | 8376/20300 [1:11:19<1:21:39,  2.43it/s] 41%|████▏     | 8388/20300 [1:11:24<1:21:54,  2.42it/s] 41%|████▏     | 8400/20300 [1:11:29<1:22:20,  2.41it/s] 41%|████▏     | 8412/20300 [1:11:34<1:22:45,  2.39it/s] 41%|████▏     | 8424/20300 [1:11:39<1:23:00,  2.38it/s] 42%|████▏     | 8436/20300 [1:11:44<1:23:06,  2.38it/s] 42%|████▏     | 8448/20300 [1:11:49<1:23:13,  2.37it/s] 42%|████▏     | 8460/20300 [1:11:54<1:23:06,  2.37it/s] 42%|████▏     | 8472/20300 [1:11:59<1:22:52,  2.38it/s] 42%|████▏     | 8484/20300 [1:12:04<1:22:46,  2.38it/s] 42%|████▏     | 8496/20300 [1:12:09<1:22:32,  2.38it/s] 42%|████▏     | 8508/20300 [1:12:14<1:22:21,  2.39it/s] 42%|████▏     | 8520/20300 [1:12:19<1:22:10,  2.39it/s] 42%|████▏     | 8532/20300 [1:12:24<1:21:26,  2.41it/s] 42%|████▏     | 8544/20300 [1:12:29<1:20:54,  2.42it/s] 42%|████▏     | 8556/20300 [1:12:34<1:20:42,  2.43it/s] 42%|████▏     | 8568/20300 [1:12:39<1:20:10,  2.44it/s] 42%|████▏     | 8580/20300 [1:12:44<1:19:51,  2.45it/s] 42%|████▏     | 8592/20300 [1:12:49<1:20:01,  2.44it/s] 42%|████▏     | 8604/20300 [1:12:53<1:19:37,  2.45it/s] 42%|████▏     | 8616/20300 [1:12:58<1:19:14,  2.46it/s] 43%|████▎     | 8628/20300 [1:13:03<1:19:09,  2.46it/s] 43%|████▎     | 8640/20300 [1:13:08<1:19:18,  2.45it/s] 43%|████▎     | 8652/20300 [1:13:13<1:19:56,  2.43it/s] 43%|████▎     | 8664/20300 [1:13:18<1:20:23,  2.41it/s] 43%|████▎     | 8676/20300 [1:13:23<1:20:29,  2.41it/s] 43%|████▎     | 8688/20300 [1:13:28<1:20:35,  2.40it/s] 43%|████▎     | 8700/20300 [1:13:33<1:20:42,  2.40it/s] 43%|████▎     | 8712/20300 [1:13:38<1:20:36,  2.40it/s] 43%|████▎     | 8724/20300 [1:13:43<1:20:37,  2.39it/s] 43%|████▎     | 8736/20300 [1:13:48<1:20:41,  2.39it/s] 43%|████▎     | 8748/20300 [1:13:53<1:20:28,  2.39it/s] 43%|████▎     | 8760/20300 [1:13:58<1:20:22,  2.39it/s] 43%|████▎     | 8772/20300 [1:14:03<1:20:25,  2.39it/s] 43%|████▎     | 8784/20300 [1:14:08<1:19:58,  2.40it/s] 43%|████▎     | 8796/20300 [1:14:13<1:19:27,  2.41it/s] 43%|████▎     | 8808/20300 [1:14:18<1:19:13,  2.42it/s] 43%|████▎     | 8820/20300 [1:14:23<1:18:59,  2.42it/s] 44%|████▎     | 8832/20300 [1:14:28<1:18:39,  2.43it/s] 44%|████▎     | 8844/20300 [1:14:33<1:18:11,  2.44it/s] 44%|████▎     | 8856/20300 [1:14:38<1:17:59,  2.45it/s] 44%|████▎     | 8868/20300 [1:14:43<1:17:53,  2.45it/s] 44%|████▎     | 8880/20300 [1:14:48<1:17:37,  2.45it/s] 44%|████▍     | 8892/20300 [1:14:52<1:17:29,  2.45it/s] 44%|████▍     | 8904/20300 [1:14:57<1:17:33,  2.45it/s] 44%|████▍     | 8916/20300 [1:15:02<1:17:25,  2.45it/s] 44%|████▍     | 8928/20300 [1:15:07<1:17:39,  2.44it/s] 44%|████▍     | 8940/20300 [1:15:12<1:18:12,  2.42it/s] 44%|████▍     | 8952/20300 [1:15:17<1:18:23,  2.41it/s] 44%|████▍     | 8964/20300 [1:15:22<1:18:38,  2.40it/s] 44%|████▍     | 8976/20300 [1:15:27<1:18:43,  2.40it/s] 44%|████▍     | 8988/20300 [1:15:32<1:18:33,  2.40it/s] 44%|████▍     | 9000/20300 [1:15:37<1:18:33,  2.40it/s] 44%|████▍     | 9012/20300 [1:15:42<1:18:36,  2.39it/s] 44%|████▍     | 9024/20300 [1:15:47<1:18:32,  2.39it/s] 45%|████▍     | 9036/20300 [1:15:52<1:18:32,  2.39it/s] 45%|████▍     | 9048/20300 [1:15:57<1:18:29,  2.39it/s] 45%|████▍     | 9060/20300 [1:16:02<1:18:23,  2.39it/s] 45%|████▍     | 9072/20300 [1:16:07<1:18:13,  2.39it/s] 45%|████▍     | 9084/20300 [1:16:12<1:17:28,  2.41it/s] 45%|████▍     | 9096/20300 [1:16:17<1:17:04,  2.42it/s] 45%|████▍     | 9108/20300 [1:16:22<1:16:55,  2.43it/s] 45%|████▍     | 9120/20300 [1:16:27<1:16:20,  2.44it/s] 45%|████▍     | 9132/20300 [1:16:32<1:16:01,  2.45it/s] 45%|████▌     | 9144/20300 [1:16:37<1:15:58,  2.45it/s] 45%|████▌     | 9156/20300 [1:16:42<1:15:41,  2.45it/s] 45%|████▌     | 9168/20300 [1:16:47<1:15:25,  2.46it/s] 45%|████▌     | 9180/20300 [1:16:51<1:15:17,  2.46it/s] 45%|████▌     | 9192/20300 [1:16:56<1:15:04,  2.47it/s] 45%|████▌     | 9204/20300 [1:17:01<1:14:58,  2.47it/s] 45%|████▌     | 9216/20300 [1:17:06<1:14:53,  2.47it/s] 45%|████▌     | 9228/20300 [1:17:11<1:14:56,  2.46it/s] 46%|████▌     | 9240/20300 [1:17:16<1:15:14,  2.45it/s] 46%|████▌     | 9252/20300 [1:17:21<1:15:43,  2.43it/s] 46%|████▌     | 9264/20300 [1:17:26<1:15:58,  2.42it/s] 46%|████▌     | 9276/20300 [1:17:31<1:16:21,  2.41it/s] 46%|████▌     | 9288/20300 [1:17:36<1:16:37,  2.40it/s] 46%|████▌     | 9300/20300 [1:17:41<1:16:30,  2.40it/s] 46%|████▌     | 9312/20300 [1:17:46<1:16:21,  2.40it/s] 46%|████▌     | 9324/20300 [1:17:51<1:16:29,  2.39it/s] 46%|████▌     | 9336/20300 [1:17:56<1:16:23,  2.39it/s] 46%|████▌     | 9348/20300 [1:18:01<1:16:17,  2.39it/s] 46%|████▌     | 9360/20300 [1:18:06<1:16:09,  2.39it/s] 46%|████▌     | 9372/20300 [1:18:11<1:16:04,  2.39it/s] 46%|████▌     | 9384/20300 [1:18:16<1:15:30,  2.41it/s] 46%|████▋     | 9396/20300 [1:18:21<1:14:58,  2.42it/s] 46%|████▋     | 9408/20300 [1:18:26<1:14:29,  2.44it/s] 46%|████▋     | 9420/20300 [1:18:30<1:13:48,  2.46it/s] 46%|████▋     | 9432/20300 [1:18:35<1:13:34,  2.46it/s] 47%|████▋     | 9444/20300 [1:18:40<1:13:23,  2.47it/s] 47%|████▋     | 9456/20300 [1:18:45<1:13:00,  2.48it/s] 47%|████▋     | 9468/20300 [1:18:50<1:12:52,  2.48it/s] 47%|████▋     | 9480/20300 [1:18:55<1:12:46,  2.48it/s] 47%|████▋     | 9492/20300 [1:18:59<1:12:30,  2.48it/s] 47%|████▋     | 9504/20300 [1:19:04<1:12:24,  2.49it/s] 47%|████▋     | 9516/20300 [1:19:09<1:12:11,  2.49it/s] 47%|████▋     | 9528/20300 [1:19:14<1:12:12,  2.49it/s] 47%|████▋     | 9540/20300 [1:19:19<1:12:23,  2.48it/s] 47%|████▋     | 9552/20300 [1:19:24<1:12:39,  2.47it/s] 47%|████▋     | 9564/20300 [1:19:29<1:13:08,  2.45it/s] 47%|████▋     | 9576/20300 [1:19:34<1:13:32,  2.43it/s] 47%|████▋     | 9588/20300 [1:19:39<1:13:46,  2.42it/s] 47%|████▋     | 9600/20300 [1:19:44<1:13:51,  2.41it/s] 47%|████▋     | 9612/20300 [1:19:49<1:13:48,  2.41it/s] 47%|████▋     | 9624/20300 [1:19:54<1:13:42,  2.41it/s] 47%|████▋     | 9636/20300 [1:19:59<1:13:41,  2.41it/s] 48%|████▊     | 9648/20300 [1:20:04<1:13:50,  2.40it/s] 48%|████▊     | 9660/20300 [1:20:09<1:13:41,  2.41it/s] 48%|████▊     | 9672/20300 [1:20:14<1:12:59,  2.43it/s] 48%|████▊     | 9684/20300 [1:20:18<1:12:24,  2.44it/s] 48%|████▊     | 9696/20300 [1:20:23<1:11:59,  2.46it/s] 48%|████▊     | 9708/20300 [1:20:28<1:11:27,  2.47it/s] 48%|████▊     | 9720/20300 [1:20:33<1:11:17,  2.47it/s] 48%|████▊     | 9732/20300 [1:20:38<1:11:10,  2.47it/s] 48%|████▊     | 9744/20300 [1:20:42<1:10:50,  2.48it/s] 48%|████▊     | 9756/20300 [1:20:47<1:10:42,  2.49it/s] 48%|████▊     | 9768/20300 [1:20:52<1:10:31,  2.49it/s] 48%|████▊     | 9780/20300 [1:20:57<1:10:21,  2.49it/s] 48%|████▊     | 9792/20300 [1:21:02<1:10:18,  2.49it/s] 48%|████▊     | 9804/20300 [1:21:07<1:10:16,  2.49it/s] 48%|████▊     | 9816/20300 [1:21:11<1:10:06,  2.49it/s] 48%|████▊     | 9828/20300 [1:21:16<1:10:03,  2.49it/s] 48%|████▊     | 9840/20300 [1:21:21<1:10:15,  2.48it/s] 49%|████▊     | 9852/20300 [1:21:26<1:10:20,  2.48it/s] 49%|████▊     | 9864/20300 [1:21:31<1:10:28,  2.47it/s] 49%|████▊     | 9876/20300 [1:21:36<1:10:56,  2.45it/s] 49%|████▊     | 9888/20300 [1:21:41<1:11:13,  2.44it/s] 49%|████▉     | 9900/20300 [1:21:46<1:11:11,  2.43it/s] 49%|████▉     | 9912/20300 [1:21:51<1:11:07,  2.43it/s] 49%|████▉     | 9924/20300 [1:21:56<1:11:08,  2.43it/s] 49%|████▉     | 9936/20300 [1:22:01<1:11:10,  2.43it/s] 49%|████▉     | 9948/20300 [1:22:06<1:11:04,  2.43it/s] 49%|████▉     | 9960/20300 [1:22:10<1:10:35,  2.44it/s] 49%|████▉     | 9972/20300 [1:22:15<1:09:56,  2.46it/s] 49%|████▉     | 9984/20300 [1:22:20<1:09:44,  2.47it/s] 49%|████▉     | 9996/20300 [1:22:25<1:09:36,  2.47it/s] 49%|████▉     | 10008/20300 [1:22:30<1:08:47,  2.49it/s] 49%|████▉     | 10020/20300 [1:22:34<1:08:31,  2.50it/s] 49%|████▉     | 10032/20300 [1:22:39<1:08:31,  2.50it/s] 49%|████▉     | 10044/20300 [1:22:44<1:08:17,  2.50it/s] 50%|████▉     | 10056/20300 [1:22:49<1:07:51,  2.52it/s] 50%|████▉     | 10068/20300 [1:22:53<1:07:51,  2.51it/s] 50%|████▉     | 10080/20300 [1:22:58<1:07:47,  2.51it/s] 50%|████▉     | 10092/20300 [1:23:03<1:07:23,  2.52it/s] 50%|████▉     | 10104/20300 [1:23:08<1:07:25,  2.52it/s] 50%|████▉     | 10116/20300 [1:23:12<1:07:36,  2.51it/s] 50%|████▉     | 10128/20300 [1:23:17<1:07:42,  2.50it/s] 50%|████▉     | 10140/20300 [1:23:22<1:07:52,  2.50it/s] 50%|█████     | 10152/20300 [1:23:27<1:08:21,  2.47it/s] 50%|█████     | 10164/20300 [1:23:32<1:08:28,  2.47it/s] 50%|█████     | 10176/20300 [1:23:37<1:08:21,  2.47it/s] 50%|█████     | 10188/20300 [1:23:42<1:08:20,  2.47it/s] 50%|█████     | 10200/20300 [1:23:47<1:08:16,  2.47it/s] 50%|█████     | 10212/20300 [1:23:51<1:08:13,  2.46it/s] 50%|█████     | 10224/20300 [1:23:56<1:08:10,  2.46it/s] 50%|█████     | 10236/20300 [1:24:01<1:07:25,  2.49it/s] 50%|█████     | 10248/20300 [1:24:06<1:06:48,  2.51it/s] 51%|█████     | 10260/20300 [1:24:11<1:06:44,  2.51it/s] 51%|█████     | 10272/20300 [1:24:15<1:06:24,  2.52it/s] 51%|█████     | 10284/20300 [1:24:20<1:05:41,  2.54it/s] 51%|█████     | 10296/20300 [1:24:25<1:05:35,  2.54it/s] 51%|█████     | 10308/20300 [1:24:29<1:05:30,  2.54it/s] 51%|█████     | 10320/20300 [1:24:34<1:04:57,  2.56it/s] 51%|█████     | 10332/20300 [1:24:39<1:04:55,  2.56it/s] 51%|█████     | 10344/20300 [1:24:43<1:04:45,  2.56it/s] 51%|█████     | 10356/20300 [1:24:48<1:04:36,  2.56it/s] 51%|█████     | 10368/20300 [1:24:53<1:04:55,  2.55it/s] 51%|█████     | 10380/20300 [1:24:58<1:05:27,  2.53it/s] 51%|█████     | 10392/20300 [1:25:02<1:05:36,  2.52it/s] 51%|█████▏    | 10404/20300 [1:25:07<1:05:44,  2.51it/s] 51%|█████▏    | 10416/20300 [1:25:12<1:05:44,  2.51it/s] 51%|█████▏    | 10428/20300 [1:25:17<1:05:31,  2.51it/s] 51%|█████▏    | 10440/20300 [1:25:22<1:05:26,  2.51it/s] 51%|█████▏    | 10452/20300 [1:25:26<1:05:22,  2.51it/s] 52%|█████▏    | 10464/20300 [1:25:31<1:05:09,  2.52it/s] 52%|█████▏    | 10476/20300 [1:25:36<1:04:35,  2.53it/s] 52%|█████▏    | 10488/20300 [1:25:40<1:04:11,  2.55it/s] 52%|█████▏    | 10500/20300 [1:25:45<1:03:47,  2.56it/s] 52%|█████▏    | 10512/20300 [1:25:50<1:03:07,  2.58it/s] 52%|█████▏    | 10524/20300 [1:25:54<1:02:54,  2.59it/s] 52%|█████▏    | 10536/20300 [1:25:59<1:02:53,  2.59it/s] 52%|█████▏    | 10548/20300 [1:26:03<1:02:33,  2.60it/s] 52%|█████▏    | 10560/20300 [1:26:08<1:02:11,  2.61it/s] 52%|█████▏    | 10572/20300 [1:26:13<1:02:16,  2.60it/s] 52%|█████▏    | 10584/20300 [1:26:17<1:02:46,  2.58it/s] 52%|█████▏    | 10596/20300 [1:26:22<1:03:11,  2.56it/s] 52%|█████▏    | 10608/20300 [1:26:27<1:03:24,  2.55it/s] 52%|█████▏    | 10620/20300 [1:26:32<1:03:14,  2.55it/s] 52%|█████▏    | 10632/20300 [1:26:36<1:03:16,  2.55it/s] 52%|█████▏    | 10644/20300 [1:26:41<1:03:12,  2.55it/s] 52%|█████▏    | 10656/20300 [1:26:46<1:02:59,  2.55it/s] 53%|█████▎    | 10668/20300 [1:26:50<1:02:52,  2.55it/s] 53%|█████▎    | 10680/20300 [1:26:55<1:02:35,  2.56it/s] 53%|█████▎    | 10692/20300 [1:27:00<1:02:21,  2.57it/s] 53%|█████▎    | 10704/20300 [1:27:04<1:01:58,  2.58it/s] 53%|█████▎    | 10716/20300 [1:27:09<1:01:41,  2.59it/s] 53%|█████▎    | 10728/20300 [1:27:13<1:01:18,  2.60it/s] 53%|█████▎    | 10740/20300 [1:27:18<1:00:45,  2.62it/s] 53%|█████▎    | 10752/20300 [1:27:22<1:00:16,  2.64it/s] 53%|█████▎    | 10764/20300 [1:27:27<1:00:08,  2.64it/s] 53%|█████▎    | 10776/20300 [1:27:31<59:51,  2.65it/s]   53%|█████▎    | 10788/20300 [1:27:36<59:42,  2.66it/s] 53%|█████▎    | 10800/20300 [1:27:41<1:00:11,  2.63it/s] 53%|█████▎    | 10812/20300 [1:27:45<1:00:30,  2.61it/s] 53%|█████▎    | 10824/20300 [1:27:50<1:00:39,  2.60it/s] 53%|█████▎    | 10836/20300 [1:27:55<1:00:44,  2.60it/s] 53%|█████▎    | 10848/20300 [1:27:59<1:00:44,  2.59it/s] 53%|█████▎    | 10860/20300 [1:28:04<1:00:40,  2.59it/s] 54%|█████▎    | 10872/20300 [1:28:08<1:00:34,  2.59it/s] 54%|█████▎    | 10884/20300 [1:28:13<1:00:13,  2.61it/s] 54%|█████▎    | 10896/20300 [1:28:18<1:00:03,  2.61it/s] 54%|█████▎    | 10908/20300 [1:28:22<59:55,  2.61it/s]   54%|█████▍    | 10920/20300 [1:28:27<59:45,  2.62it/s] 54%|█████▍    | 10932/20300 [1:28:31<59:41,  2.62it/s] 54%|█████▍    | 10944/20300 [1:28:36<59:32,  2.62it/s] 54%|█████▍    | 10956/20300 [1:28:40<59:06,  2.63it/s] 54%|█████▍    | 10968/20300 [1:28:45<58:41,  2.65it/s] 54%|█████▍    | 10980/20300 [1:28:49<58:24,  2.66it/s] 54%|█████▍    | 10992/20300 [1:28:54<57:58,  2.68it/s] 54%|█████▍    | 11004/20300 [1:28:58<57:34,  2.69it/s] 54%|█████▍    | 11016/20300 [1:29:03<57:23,  2.70it/s] 54%|█████▍    | 11028/20300 [1:29:07<57:16,  2.70it/s] 54%|█████▍    | 11040/20300 [1:29:12<57:34,  2.68it/s] 54%|█████▍    | 11052/20300 [1:29:16<58:11,  2.65it/s] 55%|█████▍    | 11064/20300 [1:29:21<58:20,  2.64it/s] 55%|█████▍    | 11076/20300 [1:29:25<58:12,  2.64it/s] 55%|█████▍    | 11088/20300 [1:29:30<58:09,  2.64it/s] 55%|█████▍    | 11100/20300 [1:29:34<58:12,  2.63it/s] 55%|█████▍    | 11112/20300 [1:29:39<58:12,  2.63it/s] 55%|█████▍    | 11124/20300 [1:29:44<58:04,  2.63it/s] 55%|█████▍    | 11136/20300 [1:29:48<58:07,  2.63it/s] 55%|█████▍    | 11148/20300 [1:29:53<57:55,  2.63it/s] 55%|█████▍    | 11160/20300 [1:29:57<57:34,  2.65it/s] 55%|█████▌    | 11172/20300 [1:30:02<57:23,  2.65it/s] 55%|█████▌    | 11184/20300 [1:30:06<57:11,  2.66it/s] 55%|█████▌    | 11196/20300 [1:30:11<56:56,  2.66it/s] 55%|█████▌    | 11208/20300 [1:30:15<56:43,  2.67it/s] 55%|█████▌    | 11220/20300 [1:30:20<56:39,  2.67it/s] 55%|█████▌    | 11232/20300 [1:30:24<56:25,  2.68it/s] 55%|█████▌    | 11244/20300 [1:30:28<56:13,  2.68it/s] 55%|█████▌    | 11256/20300 [1:30:33<56:00,  2.69it/s] 56%|█████▌    | 11268/20300 [1:30:37<55:53,  2.69it/s] 56%|█████▌    | 11280/20300 [1:30:42<55:58,  2.69it/s] 56%|█████▌    | 11292/20300 [1:30:46<56:04,  2.68it/s] 56%|█████▌    | 11304/20300 [1:30:51<55:59,  2.68it/s] 56%|█████▌    | 11316/20300 [1:30:55<55:56,  2.68it/s] 56%|█████▌    | 11328/20300 [1:31:00<55:56,  2.67it/s] 56%|█████▌    | 11340/20300 [1:31:04<55:51,  2.67it/s] 56%|█████▌    | 11352/20300 [1:31:09<55:45,  2.67it/s] 56%|█████▌    | 11364/20300 [1:31:13<55:39,  2.68it/s] 56%|█████▌    | 11376/20300 [1:31:18<55:23,  2.69it/s] 56%|█████▌    | 11388/20300 [1:31:22<55:11,  2.69it/s] 56%|█████▌    | 11400/20300 [1:31:27<55:02,  2.69it/s] 56%|█████▌    | 11412/20300 [1:31:31<54:51,  2.70it/s] 56%|█████▋    | 11424/20300 [1:31:36<54:52,  2.70it/s] 56%|█████▋    | 11436/20300 [1:31:40<55:07,  2.68it/s] 56%|█████▋    | 11448/20300 [1:31:45<55:04,  2.68it/s] 56%|█████▋    | 11460/20300 [1:31:49<54:14,  2.72it/s] 57%|█████▋    | 11472/20300 [1:31:53<53:52,  2.73it/s] 57%|█████▋    | 11484/20300 [1:31:58<53:59,  2.72it/s] 57%|█████▋    | 11496/20300 [1:32:02<53:24,  2.75it/s] 57%|█████▋    | 11508/20300 [1:32:06<53:30,  2.74it/s] 57%|█████▋    | 11520/20300 [1:32:11<53:34,  2.73it/s] 57%|█████▋    | 11532/20300 [1:32:15<53:05,  2.75it/s] 57%|█████▋    | 11544/20300 [1:32:19<53:00,  2.75it/s] 57%|█████▋    | 11556/20300 [1:32:24<53:07,  2.74it/s] 57%|█████▋    | 11568/20300 [1:32:28<52:48,  2.76it/s] 57%|█████▋    | 11580/20300 [1:32:32<52:37,  2.76it/s] 57%|█████▋    | 11592/20300 [1:32:37<52:43,  2.75it/s] 57%|█████▋    | 11604/20300 [1:32:41<52:37,  2.75it/s] 57%|█████▋    | 11616/20300 [1:32:45<52:31,  2.76it/s] 57%|█████▋    | 11628/20300 [1:32:50<52:53,  2.73it/s] 57%|█████▋    | 11640/20300 [1:32:54<52:59,  2.72it/s] 57%|█████▋    | 11652/20300 [1:32:59<52:51,  2.73it/s] 57%|█████▋    | 11664/20300 [1:33:03<52:45,  2.73it/s] 58%|█████▊    | 11676/20300 [1:33:08<52:40,  2.73it/s] 58%|█████▊    | 11688/20300 [1:33:12<52:30,  2.73it/s] 58%|█████▊    | 11700/20300 [1:33:16<52:16,  2.74it/s] 58%|█████▊    | 11712/20300 [1:33:21<52:26,  2.73it/s] 58%|█████▊    | 11724/20300 [1:33:25<52:31,  2.72it/s] 58%|█████▊    | 11736/20300 [1:33:30<52:37,  2.71it/s] 58%|█████▊    | 11748/20300 [1:33:34<52:36,  2.71it/s] 58%|█████▊    | 11760/20300 [1:33:39<52:34,  2.71it/s] 58%|█████▊    | 11772/20300 [1:33:43<52:15,  2.72it/s] 58%|█████▊    | 11784/20300 [1:33:47<51:47,  2.74it/s] 58%|█████▊    | 11796/20300 [1:33:51<51:20,  2.76it/s] 58%|█████▊    | 11808/20300 [1:33:56<51:02,  2.77it/s] 58%|█████▊    | 11820/20300 [1:34:00<50:51,  2.78it/s] 58%|█████▊    | 11832/20300 [1:34:04<50:43,  2.78it/s] 58%|█████▊    | 11844/20300 [1:34:09<50:33,  2.79it/s] 58%|█████▊    | 11856/20300 [1:34:13<50:25,  2.79it/s] 58%|█████▊    | 11868/20300 [1:34:17<50:29,  2.78it/s] 59%|█████▊    | 11880/20300 [1:34:21<50:12,  2.80it/s] 59%|█████▊    | 11892/20300 [1:34:26<49:56,  2.81it/s] 59%|█████▊    | 11904/20300 [1:34:30<49:53,  2.81it/s] 59%|█████▊    | 11916/20300 [1:34:34<49:37,  2.82it/s] 59%|█████▉    | 11928/20300 [1:34:38<49:21,  2.83it/s] 59%|█████▉    | 11940/20300 [1:34:43<49:16,  2.83it/s] 59%|█████▉    | 11952/20300 [1:34:47<49:05,  2.83it/s] 59%|█████▉    | 11964/20300 [1:34:51<48:57,  2.84it/s] 59%|█████▉    | 11976/20300 [1:34:55<49:17,  2.81it/s] 59%|█████▉    | 11988/20300 [1:35:00<49:41,  2.79it/s] 59%|█████▉    | 12000/20300 [1:35:04<49:55,  2.77it/s] 59%|█████▉    | 12012/20300 [1:35:09<50:05,  2.76it/s] 59%|█████▉    | 12024/20300 [1:35:13<50:12,  2.75it/s] 59%|█████▉    | 12036/20300 [1:35:17<50:12,  2.74it/s] 59%|█████▉    | 12048/20300 [1:35:22<50:17,  2.73it/s] 59%|█████▉    | 12060/20300 [1:35:26<50:10,  2.74it/s] 59%|█████▉    | 12072/20300 [1:35:31<50:07,  2.74it/s] 60%|█████▉    | 12084/20300 [1:35:35<49:54,  2.74it/s] 60%|█████▉    | 12096/20300 [1:35:39<49:47,  2.75it/s] 60%|█████▉    | 12108/20300 [1:35:44<49:43,  2.75it/s] 60%|█████▉    | 12120/20300 [1:35:48<49:33,  2.75it/s] 60%|█████▉    | 12132/20300 [1:35:52<49:13,  2.77it/s] 60%|█████▉    | 12144/20300 [1:35:57<48:48,  2.78it/s] 60%|█████▉    | 12156/20300 [1:36:01<48:30,  2.80it/s] 60%|█████▉    | 12168/20300 [1:36:05<48:15,  2.81it/s] 60%|██████    | 12180/20300 [1:36:09<48:04,  2.81it/s] 60%|██████    | 12192/20300 [1:36:14<47:55,  2.82it/s] 60%|██████    | 12204/20300 [1:36:18<47:48,  2.82it/s] 60%|██████    | 12216/20300 [1:36:22<47:49,  2.82it/s] 60%|██████    | 12228/20300 [1:36:26<47:44,  2.82it/s] 60%|██████    | 12240/20300 [1:36:30<47:27,  2.83it/s] 60%|██████    | 12252/20300 [1:36:35<47:15,  2.84it/s] 60%|██████    | 12264/20300 [1:36:39<47:13,  2.84it/s] 60%|██████    | 12276/20300 [1:36:43<47:05,  2.84it/s] 61%|██████    | 12288/20300 [1:36:47<47:01,  2.84it/s] 61%|██████    | 12300/20300 [1:36:52<46:54,  2.84it/s] 61%|██████    | 12312/20300 [1:36:56<46:45,  2.85it/s] 61%|██████    | 12324/20300 [1:37:00<46:37,  2.85it/s] 61%|██████    | 12336/20300 [1:37:04<46:48,  2.84it/s] 61%|██████    | 12348/20300 [1:37:09<46:59,  2.82it/s] 61%|██████    | 12360/20300 [1:37:13<47:13,  2.80it/s] 61%|██████    | 12372/20300 [1:37:17<47:24,  2.79it/s] 61%|██████    | 12384/20300 [1:37:22<47:27,  2.78it/s] 61%|██████    | 12396/20300 [1:37:26<47:32,  2.77it/s] 61%|██████    | 12408/20300 [1:37:30<47:41,  2.76it/s] 61%|██████    | 12420/20300 [1:37:35<47:41,  2.75it/s] 61%|██████    | 12432/20300 [1:37:39<47:39,  2.75it/s] 61%|██████▏   | 12444/20300 [1:37:43<47:34,  2.75it/s] 61%|██████▏   | 12456/20300 [1:37:48<47:18,  2.76it/s] 61%|██████▏   | 12468/20300 [1:37:52<46:52,  2.78it/s] 61%|██████▏   | 12480/20300 [1:37:56<46:25,  2.81it/s] 62%|██████▏   | 12492/20300 [1:38:00<45:48,  2.84it/s] 62%|██████▏   | 12504/20300 [1:38:05<45:37,  2.85it/s] 62%|██████▏   | 12516/20300 [1:38:09<45:31,  2.85it/s] 62%|██████▏   | 12528/20300 [1:38:13<45:06,  2.87it/s] 62%|██████▏   | 12540/20300 [1:38:17<45:05,  2.87it/s] 62%|██████▏   | 12552/20300 [1:38:21<45:05,  2.86it/s] 62%|██████▏   | 12564/20300 [1:38:25<44:56,  2.87it/s] 62%|██████▏   | 12576/20300 [1:38:30<44:53,  2.87it/s] 62%|██████▏   | 12588/20300 [1:38:34<44:47,  2.87it/s] 62%|██████▏   | 12600/20300 [1:38:38<44:37,  2.88it/s] 62%|██████▏   | 12612/20300 [1:38:42<44:34,  2.87it/s] 62%|██████▏   | 12624/20300 [1:38:46<44:32,  2.87it/s] 62%|██████▏   | 12636/20300 [1:38:50<44:26,  2.87it/s] 62%|██████▏   | 12648/20300 [1:38:55<44:13,  2.88it/s] 62%|██████▏   | 12660/20300 [1:38:59<44:10,  2.88it/s] 62%|██████▏   | 12672/20300 [1:39:03<44:01,  2.89it/s] 62%|██████▏   | 12684/20300 [1:39:07<43:54,  2.89it/s] 63%|██████▎   | 12696/20300 [1:39:11<43:57,  2.88it/s] 63%|██████▎   | 12708/20300 [1:39:15<44:03,  2.87it/s] 63%|██████▎   | 12720/20300 [1:39:20<43:58,  2.87it/s] 63%|██████▎   | 12732/20300 [1:39:24<44:11,  2.85it/s] 63%|██████▎   | 12744/20300 [1:39:28<44:25,  2.83it/s] 63%|██████▎   | 12756/20300 [1:39:32<44:26,  2.83it/s] 63%|██████▎   | 12768/20300 [1:39:37<44:37,  2.81it/s] 63%|██████▎   | 12780/20300 [1:39:41<44:44,  2.80it/s] 63%|██████▎   | 12792/20300 [1:39:45<44:39,  2.80it/s] 63%|██████▎   | 12804/20300 [1:39:50<44:43,  2.79it/s] 63%|██████▎   | 12816/20300 [1:39:54<44:29,  2.80it/s] 63%|██████▎   | 12828/20300 [1:39:58<43:52,  2.84it/s] 63%|██████▎   | 12840/20300 [1:40:02<43:27,  2.86it/s] 63%|██████▎   | 12852/20300 [1:40:06<43:00,  2.89it/s] 63%|██████▎   | 12864/20300 [1:40:10<42:33,  2.91it/s] 63%|██████▎   | 12876/20300 [1:40:14<42:31,  2.91it/s] 63%|██████▎   | 12888/20300 [1:40:18<42:24,  2.91it/s] 64%|██████▎   | 12900/20300 [1:40:23<42:16,  2.92it/s] 64%|██████▎   | 12912/20300 [1:40:27<42:13,  2.92it/s] 64%|██████▎   | 12924/20300 [1:40:31<42:12,  2.91it/s] 64%|██████▎   | 12936/20300 [1:40:35<42:09,  2.91it/s] 64%|██████▍   | 12948/20300 [1:40:39<42:04,  2.91it/s] 64%|██████▍   | 12960/20300 [1:40:43<42:02,  2.91it/s] 64%|██████▍   | 12972/20300 [1:40:47<41:54,  2.91it/s] 64%|██████▍   | 12984/20300 [1:40:51<41:52,  2.91it/s] 64%|██████▍   | 12996/20300 [1:40:56<41:51,  2.91it/s] 64%|██████▍   | 13008/20300 [1:41:00<41:46,  2.91it/s] 64%|██████▍   | 13020/20300 [1:41:04<41:47,  2.90it/s] 64%|██████▍   | 13032/20300 [1:41:08<41:54,  2.89it/s] 64%|██████▍   | 13044/20300 [1:41:12<41:55,  2.88it/s] 64%|██████▍   | 13056/20300 [1:41:16<41:46,  2.89it/s] 64%|██████▍   | 13068/20300 [1:41:20<41:37,  2.90it/s] 64%|██████▍   | 13080/20300 [1:41:25<41:30,  2.90it/s] 64%|██████▍   | 13092/20300 [1:41:29<41:24,  2.90it/s] 65%|██████▍   | 13104/20300 [1:41:33<41:16,  2.91it/s] 65%|██████▍   | 13116/20300 [1:41:37<41:09,  2.91it/s] 65%|██████▍   | 13128/20300 [1:41:41<41:07,  2.91it/s] 65%|██████▍   | 13140/20300 [1:41:45<41:10,  2.90it/s] 65%|██████▍   | 13152/20300 [1:41:49<41:20,  2.88it/s] 65%|██████▍   | 13164/20300 [1:41:54<41:24,  2.87it/s] 65%|██████▍   | 13176/20300 [1:41:58<41:19,  2.87it/s] 65%|██████▍   | 13188/20300 [1:42:02<40:54,  2.90it/s] 65%|██████▌   | 13200/20300 [1:42:06<40:16,  2.94it/s] 65%|██████▌   | 13212/20300 [1:42:10<40:00,  2.95it/s] 65%|██████▌   | 13224/20300 [1:42:14<39:45,  2.97it/s] 65%|██████▌   | 13236/20300 [1:42:18<39:33,  2.98it/s] 65%|██████▌   | 13248/20300 [1:42:22<39:27,  2.98it/s] 65%|██████▌   | 13260/20300 [1:42:26<39:22,  2.98it/s] 65%|██████▌   | 13272/20300 [1:42:30<39:15,  2.98it/s] 65%|██████▌   | 13284/20300 [1:42:34<39:11,  2.98it/s] 65%|██████▌   | 13296/20300 [1:42:38<39:07,  2.98it/s] 66%|██████▌   | 13308/20300 [1:42:42<39:07,  2.98it/s] 66%|██████▌   | 13320/20300 [1:42:46<39:14,  2.96it/s] 66%|██████▌   | 13332/20300 [1:42:50<39:17,  2.96it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 66%|██████▌   | 13344/20300 [1:42:54<39:11,  2.96it/s] 66%|██████▌   | 13356/20300 [1:42:58<39:07,  2.96it/s] 66%|██████▌   | 13368/20300 [1:43:02<39:02,  2.96it/s] 66%|██████▌   | 13380/20300 [1:43:06<38:55,  2.96it/s] 66%|██████▌   | 13392/20300 [1:43:10<38:46,  2.97it/s] 66%|██████▌   | 13404/20300 [1:43:14<38:42,  2.97it/s] 66%|██████▌   | 13416/20300 [1:43:19<38:34,  2.97it/s] 66%|██████▌   | 13428/20300 [1:43:23<38:27,  2.98it/s] 66%|██████▌   | 13440/20300 [1:43:27<38:22,  2.98it/s] 66%|██████▋   | 13452/20300 [1:43:31<38:15,  2.98it/s] 66%|██████▋   | 13464/20300 [1:43:35<38:20,  2.97it/s] 66%|██████▋   | 13476/20300 [1:43:39<38:21,  2.96it/s] 66%|██████▋   | 13488/20300 [1:43:43<38:19,  2.96it/s] 67%|██████▋   | 13500/20300 [1:43:47<38:18,  2.96it/s] 67%|██████▋   | 13512/20300 [1:43:51<38:21,  2.95it/s] 67%|██████▋   | 13524/20300 [1:43:55<38:21,  2.94it/s] 67%|██████▋   | 13536/20300 [1:43:59<38:18,  2.94it/s] 67%|██████▋   | 13548/20300 [1:44:03<38:05,  2.95it/s] 67%|██████▋   | 13560/20300 [1:44:07<37:57,  2.96it/s] 67%|██████▋   | 13572/20300 [1:44:11<37:54,  2.96it/s] 67%|██████▋   | 13584/20300 [1:44:15<37:53,  2.95it/s] 67%|██████▋   | 13596/20300 [1:44:19<37:47,  2.96it/s] 67%|██████▋   | 13608/20300 [1:44:23<37:34,  2.97it/s] 67%|██████▋   | 13620/20300 [1:44:27<37:27,  2.97it/s] 67%|██████▋   | 13632/20300 [1:44:31<37:19,  2.98it/s] 67%|██████▋   | 13644/20300 [1:44:35<37:12,  2.98it/s] 67%|██████▋   | 13656/20300 [1:44:39<37:08,  2.98it/s] 67%|██████▋   | 13668/20300 [1:44:43<37:00,  2.99it/s] 67%|██████▋   | 13680/20300 [1:44:47<36:55,  2.99it/s] 67%|██████▋   | 13692/20300 [1:44:51<36:49,  2.99it/s] 68%|██████▊   | 13704/20300 [1:44:55<36:36,  3.00it/s] 68%|██████▊   | 13716/20300 [1:44:59<36:19,  3.02it/s] 68%|██████▊   | 13728/20300 [1:45:03<36:00,  3.04it/s] 68%|██████▊   | 13740/20300 [1:45:07<35:47,  3.05it/s] 68%|██████▊   | 13752/20300 [1:45:11<35:28,  3.08it/s] 68%|██████▊   | 13764/20300 [1:45:15<35:19,  3.08it/s] 68%|██████▊   | 13776/20300 [1:45:19<35:17,  3.08it/s] 68%|██████▊   | 13788/20300 [1:45:23<34:58,  3.10it/s] 68%|██████▊   | 13800/20300 [1:45:26<34:42,  3.12it/s] 68%|██████▊   | 13812/20300 [1:45:30<34:42,  3.12it/s] 68%|██████▊   | 13824/20300 [1:45:34<34:30,  3.13it/s] 68%|██████▊   | 13836/20300 [1:45:38<34:29,  3.12it/s] 68%|██████▊   | 13848/20300 [1:45:42<34:40,  3.10it/s] 68%|██████▊   | 13860/20300 [1:45:46<34:49,  3.08it/s] 68%|██████▊   | 13872/20300 [1:45:50<34:57,  3.06it/s] 68%|██████▊   | 13884/20300 [1:45:54<35:04,  3.05it/s] 68%|██████▊   | 13896/20300 [1:45:58<35:00,  3.05it/s] 69%|██████▊   | 13908/20300 [1:46:02<35:03,  3.04it/s] 69%|██████▊   | 13920/20300 [1:46:05<34:51,  3.05it/s] 69%|██████▊   | 13932/20300 [1:46:09<34:14,  3.10it/s] 69%|██████▊   | 13944/20300 [1:46:13<33:44,  3.14it/s] 69%|██████▊   | 13956/20300 [1:46:17<33:42,  3.14it/s] 69%|██████▉   | 13968/20300 [1:46:21<33:30,  3.15it/s] 69%|██████▉   | 13980/20300 [1:46:24<33:07,  3.18it/s] 69%|██████▉   | 13992/20300 [1:46:28<33:03,  3.18it/s] 69%|██████▉   | 14004/20300 [1:46:32<33:02,  3.18it/s] 69%|██████▉   | 14016/20300 [1:46:36<33:02,  3.17it/s] 69%|██████▉   | 14028/20300 [1:46:39<32:59,  3.17it/s] 69%|██████▉   | 14040/20300 [1:46:43<32:52,  3.17it/s] 69%|██████▉   | 14052/20300 [1:46:47<32:45,  3.18it/s] 69%|██████▉   | 14064/20300 [1:46:51<32:36,  3.19it/s] 69%|██████▉   | 14076/20300 [1:46:54<32:32,  3.19it/s] 69%|██████▉   | 14088/20300 [1:46:58<32:31,  3.18it/s] 69%|██████▉   | 14100/20300 [1:47:02<32:09,  3.21it/s] 70%|██████▉   | 14112/20300 [1:47:05<31:36,  3.26it/s] 70%|██████▉   | 14124/20300 [1:47:09<31:15,  3.29it/s] 70%|██████▉   | 14136/20300 [1:47:13<31:07,  3.30it/s] 70%|██████▉   | 14148/20300 [1:47:16<31:03,  3.30it/s] 70%|██████▉   | 14160/20300 [1:47:20<30:58,  3.30it/s] 70%|██████▉   | 14172/20300 [1:47:23<30:53,  3.31it/s] 70%|██████▉   | 14184/20300 [1:47:27<30:36,  3.33it/s] 70%|██████▉   | 14196/20300 [1:47:31<30:30,  3.33it/s] 70%|██████▉   | 14208/20300 [1:47:34<30:21,  3.34it/s] 70%|███████   | 14220/20300 [1:47:38<29:50,  3.40it/s] 70%|███████   | 14232/20300 [1:47:41<29:21,  3.45it/s] 70%|███████   | 14244/20300 [1:47:44<29:23,  3.43it/s] 70%|███████   | 14256/20300 [1:47:48<29:22,  3.43it/s] 70%|███████   | 14268/20300 [1:47:51<29:18,  3.43it/s] 70%|███████   | 14280/20300 [1:47:55<29:09,  3.44it/s] 70%|███████   | 14292/20300 [1:47:58<29:13,  3.43it/s] 70%|███████   | 14304/20300 [1:48:02<29:01,  3.44it/s] 71%|███████   | 14316/20300 [1:48:05<28:21,  3.52it/s] 71%|███████   | 14328/20300 [1:48:09<28:14,  3.52it/s] 71%|███████   | 14340/20300 [1:48:12<28:17,  3.51it/s] 71%|███████   | 14352/20300 [1:48:15<28:04,  3.53it/s] 71%|███████   | 14364/20300 [1:48:19<27:55,  3.54it/s] 71%|███████   | 14376/20300 [1:48:22<27:57,  3.53it/s] 71%|███████   | 14388/20300 [1:48:25<27:42,  3.56it/s] 71%|███████   | 14400/20300 [1:48:29<27:25,  3.59it/s] 71%|███████   | 14412/20300 [1:48:32<27:21,  3.59it/s] 71%|███████   | 14424/20300 [1:48:35<27:15,  3.59it/s] 71%|███████   | 14436/20300 [1:48:39<26:55,  3.63it/s] 71%|███████   | 14448/20300 [1:48:42<26:46,  3.64it/s] 71%|███████   | 14460/20300 [1:48:45<26:42,  3.64it/s] 71%|███████▏  | 14472/20300 [1:48:48<26:45,  3.63it/s] 71%|███████▏  | 14484/20300 [1:48:52<26:30,  3.66it/s] 71%|███████▏  | 14496/20300 [1:48:55<26:10,  3.70it/s] 71%|███████▏  | 14508/20300 [1:48:58<25:42,  3.75it/s] 72%|███████▏  | 14520/20300 [1:49:01<25:42,  3.75it/s] 72%|███████▏  | 14532/20300 [1:49:04<25:49,  3.72it/s] 72%|███████▏  | 14544/20300 [1:49:08<25:39,  3.74it/s] 72%|███████▏  | 14556/20300 [1:49:11<25:30,  3.75it/s] 72%|███████▏  | 14568/20300 [1:49:14<25:12,  3.79it/s] 72%|███████▏  | 14580/20300 [1:49:17<24:39,  3.87it/s] 72%|███████▏  | 14592/20300 [1:49:20<24:46,  3.84it/s] 72%|███████▏  | 14604/20300 [1:49:23<24:51,  3.82it/s] 72%|███████▏  | 14616/20300 [1:49:26<24:33,  3.86it/s] 72%|███████▏  | 14628/20300 [1:49:29<24:27,  3.87it/s] 72%|███████▏  | 14640/20300 [1:49:32<24:03,  3.92it/s] 72%|███████▏  | 14652/20300 [1:49:35<24:04,  3.91it/s] 72%|███████▏  | 14664/20300 [1:49:38<24:07,  3.89it/s] 72%|███████▏  | 14676/20300 [1:49:41<23:27,  4.00it/s] 72%|███████▏  | 14688/20300 [1:49:44<23:11,  4.03it/s] 72%|███████▏  | 14700/20300 [1:49:47<23:12,  4.02it/s] 72%|███████▏  | 14712/20300 [1:49:50<23:16,  4.00it/s] 73%|███████▎  | 14724/20300 [1:49:53<23:18,  3.99it/s] 73%|███████▎  | 14736/20300 [1:49:56<22:39,  4.09it/s] 73%|███████▎  | 14748/20300 [1:49:59<22:25,  4.13it/s] 73%|███████▎  | 14760/20300 [1:50:02<22:29,  4.10it/s] 73%|███████▎  | 14772/20300 [1:50:05<22:39,  4.07it/s] 73%|███████▎  | 14784/20300 [1:50:08<22:42,  4.05it/s] 73%|███████▎  | 14796/20300 [1:50:11<22:07,  4.15it/s] 73%|███████▎  | 14808/20300 [1:50:13<21:51,  4.19it/s] 73%|███████▎  | 14820/20300 [1:50:16<21:50,  4.18it/s] 73%|███████▎  | 14832/20300 [1:50:19<21:55,  4.16it/s] 73%|███████▎  | 14844/20300 [1:50:22<21:46,  4.17it/s] 73%|███████▎  | 14856/20300 [1:50:25<21:13,  4.27it/s] 73%|███████▎  | 14868/20300 [1:50:27<21:10,  4.28it/s] 73%|███████▎  | 14880/20300 [1:50:30<21:09,  4.27it/s] 73%|███████▎  | 14892/20300 [1:50:33<21:14,  4.24it/s] 73%|███████▎  | 14904/20300 [1:50:36<21:02,  4.27it/s] 73%|███████▎  | 14916/20300 [1:50:38<20:16,  4.43it/s] 74%|███████▎  | 14928/20300 [1:50:41<20:22,  4.39it/s] 74%|███████▎  | 14940/20300 [1:50:44<20:35,  4.34it/s] 74%|███████▎  | 14952/20300 [1:50:47<20:35,  4.33it/s] 74%|███████▎  | 14964/20300 [1:50:50<20:28,  4.34it/s] 74%|███████▍  | 14976/20300 [1:50:52<19:56,  4.45it/s] 74%|███████▍  | 14988/20300 [1:50:55<19:53,  4.45it/s] 74%|███████▍  | 15000/20300 [1:50:58<20:04,  4.40it/s] 74%|███████▍  | 15012/20300 [1:51:00<20:04,  4.39it/s] 74%|███████▍  | 15024/20300 [1:51:03<19:49,  4.44it/s] 74%|███████▍  | 15036/20300 [1:51:06<19:28,  4.50it/s] 74%|███████▍  | 15048/20300 [1:51:08<19:29,  4.49it/s] 74%|███████▍  | 15060/20300 [1:51:11<19:45,  4.42it/s] 74%|███████▍  | 15072/20300 [1:51:14<19:51,  4.39it/s] 74%|███████▍  | 15084/20300 [1:51:16<19:29,  4.46it/s] 74%|███████▍  | 15096/20300 [1:51:19<19:11,  4.52it/s] 74%|███████▍  | 15108/20300 [1:51:22<19:13,  4.50it/s] 74%|███████▍  | 15120/20300 [1:51:24<19:23,  4.45it/s] 75%|███████▍  | 15132/20300 [1:51:27<19:25,  4.43it/s] 75%|███████▍  | 15144/20300 [1:51:30<19:06,  4.50it/s] 75%|███████▍  | 15156/20300 [1:51:32<18:48,  4.56it/s] 75%|███████▍  | 15168/20300 [1:51:35<18:52,  4.53it/s] 75%|███████▍  | 15180/20300 [1:51:38<18:56,  4.51it/s] 75%|███████▍  | 15192/20300 [1:51:40<19:06,  4.46it/s] 75%|███████▍  | 15204/20300 [1:51:43<19:06,  4.45it/s] 75%|███████▍  | 15216/20300 [1:51:46<18:34,  4.56it/s] 75%|███████▌  | 15228/20300 [1:51:48<18:35,  4.55it/s] 75%|███████▌  | 15240/20300 [1:51:51<18:40,  4.52it/s] 75%|███████▌  | 15252/20300 [1:51:54<18:30,  4.55it/s] 75%|███████▌  | 15264/20300 [1:51:56<18:39,  4.50it/s] 75%|███████▌  | 15276/20300 [1:51:59<18:26,  4.54it/s] 75%|███████▌  | 15288/20300 [1:52:01<17:55,  4.66it/s] 75%|███████▌  | 15300/20300 [1:52:04<18:01,  4.62it/s] 75%|███████▌  | 15312/20300 [1:52:07<18:06,  4.59it/s] 75%|███████▌  | 15324/20300 [1:52:09<18:03,  4.59it/s] 76%|███████▌  | 15336/20300 [1:52:12<18:15,  4.53it/s] 76%|███████▌  | 15348/20300 [1:52:15<18:13,  4.53it/s] 76%|███████▌  | 15360/20300 [1:52:17<17:53,  4.60it/s] 76%|███████▌  | 15372/20300 [1:52:20<17:40,  4.65it/s] 76%|███████▌  | 15384/20300 [1:52:22<17:44,  4.62it/s] 76%|███████▌  | 15396/20300 [1:52:25<17:44,  4.61it/s] 76%|███████▌  | 15408/20300 [1:52:28<17:41,  4.61it/s] 76%|███████▌  | 15420/20300 [1:52:30<17:43,  4.59it/s] 76%|███████▌  | 15432/20300 [1:52:33<17:49,  4.55it/s] 76%|███████▌  | 15444/20300 [1:52:35<17:37,  4.59it/s] 76%|███████▌  | 15456/20300 [1:52:38<17:07,  4.72it/s] 76%|███████▌  | 15468/20300 [1:52:40<17:13,  4.68it/s] 76%|███████▋  | 15480/20300 [1:52:43<17:17,  4.65it/s] 76%|███████▋  | 15492/20300 [1:52:46<17:09,  4.67it/s] 76%|███████▋  | 15504/20300 [1:52:48<17:15,  4.63it/s] 76%|███████▋  | 15516/20300 [1:52:51<17:15,  4.62it/s] 76%|███████▋  | 15528/20300 [1:52:54<17:21,  4.58it/s] 77%|███████▋  | 15540/20300 [1:52:56<17:15,  4.60it/s] 77%|███████▋  | 15552/20300 [1:52:58<16:47,  4.71it/s] 77%|███████▋  | 15564/20300 [1:53:01<16:49,  4.69it/s] 77%|███████▋  | 15576/20300 [1:53:04<16:53,  4.66it/s] 77%|███████▋  | 15588/20300 [1:53:06<16:51,  4.66it/s] 77%|███████▋  | 15600/20300 [1:53:09<16:57,  4.62it/s] 77%|███████▋  | 15612/20300 [1:53:12<17:04,  4.58it/s] 77%|███████▋  | 15624/20300 [1:53:14<16:58,  4.59it/s] 77%|███████▋  | 15636/20300 [1:53:17<16:58,  4.58it/s] 77%|███████▋  | 15648/20300 [1:53:20<17:02,  4.55it/s] 77%|███████▋  | 15660/20300 [1:53:22<17:00,  4.55it/s] 77%|███████▋  | 15672/20300 [1:53:25<17:07,  4.50it/s] 77%|███████▋  | 15684/20300 [1:53:27<16:59,  4.53it/s] 77%|███████▋  | 15696/20300 [1:53:30<16:50,  4.56it/s] 77%|███████▋  | 15708/20300 [1:53:33<16:44,  4.57it/s] 77%|███████▋  | 15720/20300 [1:53:35<16:39,  4.58it/s] 77%|███████▋  | 15732/20300 [1:53:38<16:30,  4.61it/s] 78%|███████▊  | 15744/20300 [1:53:40<16:26,  4.62it/s] 78%|███████▊  | 15756/20300 [1:53:43<16:19,  4.64it/s] 78%|███████▊  | 15768/20300 [1:53:46<16:12,  4.66it/s] 78%|███████▊  | 15780/20300 [1:53:48<16:09,  4.66it/s] 78%|███████▊  | 15792/20300 [1:53:51<16:07,  4.66it/s] 78%|███████▊  | 15804/20300 [1:53:53<16:00,  4.68it/s] 78%|███████▊  | 15816/20300 [1:53:56<15:53,  4.70it/s] 78%|███████▊  | 15828/20300 [1:53:58<15:50,  4.70it/s] 78%|███████▊  | 15840/20300 [1:54:01<15:49,  4.70it/s] 78%|███████▊  | 15852/20300 [1:54:03<15:49,  4.68it/s] 78%|███████▊  | 15864/20300 [1:54:06<15:47,  4.68it/s] 78%|███████▊  | 15876/20300 [1:54:09<15:52,  4.64it/s] 78%|███████▊  | 15888/20300 [1:54:11<16:00,  4.59it/s] 78%|███████▊  | 15900/20300 [1:54:14<16:02,  4.57it/s] 78%|███████▊  | 15912/20300 [1:54:17<16:00,  4.57it/s] 78%|███████▊  | 15924/20300 [1:54:19<16:01,  4.55it/s] 79%|███████▊  | 15936/20300 [1:54:22<15:54,  4.57it/s] 79%|███████▊  | 15948/20300 [1:54:24<15:47,  4.59it/s] 79%|███████▊  | 15960/20300 [1:54:27<15:43,  4.60it/s] 79%|███████▊  | 15972/20300 [1:54:30<15:27,  4.67it/s] 79%|███████▊  | 15984/20300 [1:54:32<15:03,  4.78it/s] 79%|███████▉  | 15996/20300 [1:54:34<14:56,  4.80it/s] 79%|███████▉  | 16008/20300 [1:54:37<14:50,  4.82it/s] 79%|███████▉  | 16020/20300 [1:54:39<14:38,  4.87it/s] 79%|███████▉  | 16032/20300 [1:54:42<14:31,  4.90it/s] 79%|███████▉  | 16044/20300 [1:54:44<14:37,  4.85it/s] 79%|███████▉  | 16056/20300 [1:54:47<14:45,  4.79it/s] 79%|███████▉  | 16068/20300 [1:54:49<14:54,  4.73it/s] 79%|███████▉  | 16080/20300 [1:54:52<15:00,  4.69it/s] 79%|███████▉  | 16092/20300 [1:54:55<15:01,  4.67it/s] 79%|███████▉  | 16104/20300 [1:54:57<14:56,  4.68it/s] 79%|███████▉  | 16116/20300 [1:55:00<14:42,  4.74it/s] 79%|███████▉  | 16128/20300 [1:55:02<14:23,  4.83it/s] 80%|███████▉  | 16140/20300 [1:55:04<14:20,  4.84it/s] 80%|███████▉  | 16152/20300 [1:55:07<14:15,  4.85it/s] 80%|███████▉  | 16164/20300 [1:55:09<14:00,  4.92it/s] 80%|███████▉  | 16176/20300 [1:55:12<13:56,  4.93it/s] 80%|███████▉  | 16188/20300 [1:55:14<13:59,  4.90it/s] 80%|███████▉  | 16200/20300 [1:55:17<13:59,  4.88it/s] 80%|███████▉  | 16212/20300 [1:55:19<14:01,  4.86it/s] 80%|███████▉  | 16224/20300 [1:55:22<14:08,  4.80it/s] 80%|███████▉  | 16236/20300 [1:55:24<14:11,  4.77it/s] 80%|████████  | 16248/20300 [1:55:27<14:08,  4.77it/s] 80%|████████  | 16260/20300 [1:55:29<13:58,  4.82it/s] 80%|████████  | 16272/20300 [1:55:32<13:41,  4.91it/s] 80%|████████  | 16284/20300 [1:55:34<13:36,  4.92it/s] 80%|████████  | 16296/20300 [1:55:36<13:36,  4.91it/s] 80%|████████  | 16308/20300 [1:55:39<13:25,  4.96it/s] 80%|████████  | 16320/20300 [1:55:41<13:29,  4.91it/s] 80%|████████  | 16332/20300 [1:55:44<13:35,  4.86it/s] 81%|████████  | 16344/20300 [1:55:46<13:32,  4.87it/s] 81%|████████  | 16356/20300 [1:55:49<13:31,  4.86it/s] 81%|████████  | 16368/20300 [1:55:51<13:34,  4.83it/s] 81%|████████  | 16380/20300 [1:55:54<13:37,  4.79it/s] 81%|████████  | 16392/20300 [1:55:56<13:41,  4.76it/s] 81%|████████  | 16404/20300 [1:55:59<13:29,  4.81it/s] 81%|████████  | 16416/20300 [1:56:01<13:09,  4.92it/s] 81%|████████  | 16428/20300 [1:56:04<13:03,  4.94it/s] 81%|████████  | 16440/20300 [1:56:06<13:00,  4.95it/s] 81%|████████  | 16452/20300 [1:56:08<12:54,  4.97it/s] 81%|████████  | 16464/20300 [1:56:11<12:56,  4.94it/s] 81%|████████  | 16476/20300 [1:56:13<13:00,  4.90it/s] 81%|████████  | 16488/20300 [1:56:16<12:57,  4.90it/s] 81%|████████▏ | 16500/20300 [1:56:18<12:59,  4.88it/s] 81%|████████▏ | 16512/20300 [1:56:21<12:59,  4.86it/s] 81%|████████▏ | 16524/20300 [1:56:23<12:55,  4.87it/s] 81%|████████▏ | 16536/20300 [1:56:26<12:55,  4.86it/s] 82%|████████▏ | 16548/20300 [1:56:28<12:54,  4.85it/s] 82%|████████▏ | 16560/20300 [1:56:31<12:51,  4.85it/s] 82%|████████▏ | 16572/20300 [1:56:33<12:50,  4.84it/s] 82%|████████▏ | 16584/20300 [1:56:36<12:41,  4.88it/s] 82%|████████▏ | 16596/20300 [1:56:38<12:37,  4.89it/s] 82%|████████▏ | 16608/20300 [1:56:40<12:34,  4.89it/s] 82%|████████▏ | 16620/20300 [1:56:43<12:27,  4.92it/s] 82%|████████▏ | 16632/20300 [1:56:45<12:24,  4.92it/s] 82%|████████▏ | 16644/20300 [1:56:48<12:24,  4.91it/s] 82%|████████▏ | 16656/20300 [1:56:50<12:18,  4.93it/s] 82%|████████▏ | 16668/20300 [1:56:53<12:15,  4.94it/s] 82%|████████▏ | 16680/20300 [1:56:55<12:12,  4.94it/s] 82%|████████▏ | 16692/20300 [1:56:57<12:07,  4.96it/s] 82%|████████▏ | 16704/20300 [1:57:00<12:04,  4.96it/s] 82%|████████▏ | 16716/20300 [1:57:02<12:03,  4.96it/s] 82%|████████▏ | 16728/20300 [1:57:05<11:58,  4.97it/s] 82%|████████▏ | 16740/20300 [1:57:07<12:03,  4.92it/s] 83%|████████▎ | 16752/20300 [1:57:10<12:06,  4.88it/s] 83%|████████▎ | 16764/20300 [1:57:12<12:05,  4.88it/s] 83%|████████▎ | 16776/20300 [1:57:15<12:03,  4.87it/s] 83%|████████▎ | 16788/20300 [1:57:17<12:03,  4.86it/s] 83%|████████▎ | 16800/20300 [1:57:20<12:01,  4.85it/s] 83%|████████▎ | 16812/20300 [1:57:22<11:56,  4.87it/s] 83%|████████▎ | 16824/20300 [1:57:24<11:43,  4.94it/s] 83%|████████▎ | 16836/20300 [1:57:27<11:28,  5.03it/s] 83%|████████▎ | 16848/20300 [1:57:29<11:15,  5.11it/s] 83%|████████▎ | 16860/20300 [1:57:31<11:07,  5.15it/s] 83%|████████▎ | 16872/20300 [1:57:33<11:00,  5.19it/s] 83%|████████▎ | 16884/20300 [1:57:36<11:05,  5.13it/s] 83%|████████▎ | 16896/20300 [1:57:38<11:13,  5.05it/s] 83%|████████▎ | 16908/20300 [1:57:41<11:14,  5.03it/s] 83%|████████▎ | 16920/20300 [1:57:43<11:16,  5.00it/s] 83%|████████▎ | 16932/20300 [1:57:46<11:12,  5.00it/s] 83%|████████▎ | 16944/20300 [1:57:48<10:49,  5.17it/s] 84%|████████▎ | 16956/20300 [1:57:50<10:44,  5.19it/s] 84%|████████▎ | 16968/20300 [1:57:52<10:49,  5.13it/s] 84%|████████▎ | 16980/20300 [1:57:55<10:35,  5.22it/s] 84%|████████▎ | 16992/20300 [1:57:57<10:33,  5.22it/s] 84%|████████▍ | 17004/20300 [1:57:59<10:41,  5.14it/s] 84%|████████▍ | 17016/20300 [1:58:02<10:44,  5.10it/s] 84%|████████▍ | 17028/20300 [1:58:04<10:48,  5.04it/s] 84%|████████▍ | 17040/20300 [1:58:07<10:53,  4.99it/s] 84%|████████▍ | 17052/20300 [1:58:09<10:40,  5.07it/s] 84%|████████▍ | 17064/20300 [1:58:11<10:32,  5.12it/s] 84%|████████▍ | 17076/20300 [1:58:13<10:27,  5.14it/s] 84%|████████▍ | 17088/20300 [1:58:16<10:20,  5.18it/s] 84%|████████▍ | 17100/20300 [1:58:18<10:19,  5.16it/s] 84%|████████▍ | 17112/20300 [1:58:20<10:24,  5.11it/s] 84%|████████▍ | 17124/20300 [1:58:23<10:23,  5.09it/s] 84%|████████▍ | 17136/20300 [1:58:25<10:21,  5.09it/s] 84%|████████▍ | 17148/20300 [1:58:28<10:19,  5.09it/s] 85%|████████▍ | 17160/20300 [1:58:30<10:17,  5.08it/s] 85%|████████▍ | 17172/20300 [1:58:32<10:17,  5.07it/s] 85%|████████▍ | 17184/20300 [1:58:35<10:18,  5.04it/s] 85%|████████▍ | 17196/20300 [1:58:37<10:17,  5.03it/s] 85%|████████▍ | 17208/20300 [1:58:40<10:17,  5.01it/s] 85%|████████▍ | 17220/20300 [1:58:42<10:10,  5.04it/s] 85%|████████▍ | 17232/20300 [1:58:44<10:04,  5.08it/s] 85%|████████▍ | 17244/20300 [1:58:47<09:56,  5.12it/s] 85%|████████▌ | 17256/20300 [1:58:49<09:54,  5.12it/s] 85%|████████▌ | 17268/20300 [1:58:51<09:54,  5.10it/s] 85%|████████▌ | 17280/20300 [1:58:54<09:53,  5.09it/s] 85%|████████▌ | 17292/20300 [1:58:56<09:51,  5.09it/s] 85%|████████▌ | 17304/20300 [1:58:58<09:47,  5.10it/s] 85%|████████▌ | 17316/20300 [1:59:01<09:46,  5.08it/s] 85%|████████▌ | 17328/20300 [1:59:03<09:41,  5.11it/s] 85%|████████▌ | 17340/20300 [1:59:05<09:34,  5.15it/s] 85%|████████▌ | 17352/20300 [1:59:08<09:30,  5.17it/s] 86%|████████▌ | 17364/20300 [1:59:10<09:26,  5.18it/s] 86%|████████▌ | 17376/20300 [1:59:12<09:23,  5.19it/s] 86%|████████▌ | 17388/20300 [1:59:15<09:26,  5.14it/s] 86%|████████▌ | 17400/20300 [1:59:17<09:31,  5.07it/s] 86%|████████▌ | 17412/20300 [1:59:19<09:30,  5.06it/s] 86%|████████▌ | 17424/20300 [1:59:22<09:30,  5.05it/s] 86%|████████▌ | 17436/20300 [1:59:24<09:29,  5.03it/s] 86%|████████▌ | 17448/20300 [1:59:27<09:20,  5.09it/s] 86%|████████▌ | 17460/20300 [1:59:29<09:03,  5.22it/s] 86%|████████▌ | 17472/20300 [1:59:31<08:54,  5.29it/s] 86%|████████▌ | 17484/20300 [1:59:33<08:51,  5.30it/s] 86%|████████▌ | 17496/20300 [1:59:35<08:42,  5.37it/s] 86%|████████▌ | 17508/20300 [1:59:37<08:35,  5.41it/s] 86%|████████▋ | 17520/20300 [1:59:40<08:41,  5.33it/s] 86%|████████▋ | 17532/20300 [1:59:42<08:45,  5.27it/s] 86%|████████▋ | 17544/20300 [1:59:44<08:48,  5.21it/s] 86%|████████▋ | 17556/20300 [1:59:47<08:52,  5.15it/s] 87%|████████▋ | 17568/20300 [1:59:49<08:45,  5.20it/s] 87%|████████▋ | 17580/20300 [1:59:51<08:32,  5.31it/s] 87%|████████▋ | 17592/20300 [1:59:54<08:26,  5.34it/s] 87%|████████▋ | 17604/20300 [1:59:56<08:23,  5.35it/s] 87%|████████▋ | 17616/20300 [1:59:58<08:16,  5.41it/s] 87%|████████▋ | 17628/20300 [2:00:00<08:17,  5.38it/s] 87%|████████▋ | 17640/20300 [2:00:02<08:20,  5.31it/s] 87%|████████▋ | 17652/20300 [2:00:05<08:19,  5.30it/s] 87%|████████▋ | 17664/20300 [2:00:07<08:19,  5.28it/s] 87%|████████▋ | 17676/20300 [2:00:09<08:22,  5.22it/s] 87%|████████▋ | 17688/20300 [2:00:12<08:23,  5.18it/s] 87%|████████▋ | 17700/20300 [2:00:14<08:22,  5.17it/s] 87%|████████▋ | 17712/20300 [2:00:16<08:11,  5.27it/s] 87%|████████▋ | 17724/20300 [2:00:19<08:06,  5.30it/s] 87%|████████▋ | 17736/20300 [2:00:21<08:04,  5.30it/s] 87%|████████▋ | 17748/20300 [2:00:23<08:02,  5.29it/s] 87%|████████▋ | 17760/20300 [2:00:25<08:02,  5.27it/s] 88%|████████▊ | 17772/20300 [2:00:28<08:03,  5.23it/s] 88%|████████▊ | 17784/20300 [2:00:30<08:00,  5.24it/s] 88%|████████▊ | 17796/20300 [2:00:32<07:56,  5.26it/s] 88%|████████▊ | 17808/20300 [2:00:35<07:57,  5.22it/s] 88%|████████▊ | 17820/20300 [2:00:37<07:52,  5.25it/s] 88%|████████▊ | 17832/20300 [2:00:39<07:48,  5.27it/s] 88%|████████▊ | 17844/20300 [2:00:41<07:49,  5.23it/s] 88%|████████▊ | 17856/20300 [2:00:44<07:44,  5.26it/s] 88%|████████▊ | 17868/20300 [2:00:46<07:40,  5.28it/s] 88%|████████▊ | 17880/20300 [2:00:48<07:41,  5.25it/s] 88%|████████▊ | 17892/20300 [2:00:51<07:39,  5.25it/s] 88%|████████▊ | 17904/20300 [2:00:53<07:36,  5.24it/s] 88%|████████▊ | 17916/20300 [2:00:55<07:38,  5.20it/s] 88%|████████▊ | 17928/20300 [2:00:58<07:38,  5.17it/s] 88%|████████▊ | 17940/20300 [2:01:00<07:36,  5.17it/s] 88%|████████▊ | 17952/20300 [2:01:02<07:34,  5.16it/s] 88%|████████▊ | 17964/20300 [2:01:04<07:28,  5.21it/s] 89%|████████▊ | 17976/20300 [2:01:07<07:16,  5.32it/s] 89%|████████▊ | 17988/20300 [2:01:09<07:09,  5.38it/s] 89%|████████▊ | 18000/20300 [2:01:11<07:03,  5.43it/s] 89%|████████▊ | 18012/20300 [2:01:13<06:59,  5.45it/s] 89%|████████▉ | 18024/20300 [2:01:15<06:54,  5.49it/s] 89%|████████▉ | 18036/20300 [2:01:17<06:54,  5.47it/s] 89%|████████▉ | 18048/20300 [2:01:20<06:59,  5.37it/s] 89%|████████▉ | 18060/20300 [2:01:22<07:02,  5.30it/s] 89%|████████▉ | 18072/20300 [2:01:24<07:03,  5.26it/s] 89%|████████▉ | 18084/20300 [2:01:27<07:00,  5.27it/s] 89%|████████▉ | 18096/20300 [2:01:29<06:50,  5.37it/s] 89%|████████▉ | 18108/20300 [2:01:31<06:43,  5.43it/s] 89%|████████▉ | 18120/20300 [2:01:33<06:40,  5.45it/s] 89%|████████▉ | 18132/20300 [2:01:35<06:33,  5.51it/s] 89%|████████▉ | 18144/20300 [2:01:38<06:33,  5.49it/s] 89%|████████▉ | 18156/20300 [2:01:40<06:35,  5.42it/s] 89%|████████▉ | 18168/20300 [2:01:42<06:33,  5.42it/s] 90%|████████▉ | 18180/20300 [2:01:44<06:31,  5.42it/s] 90%|████████▉ | 18192/20300 [2:01:47<06:32,  5.37it/s] 90%|████████▉ | 18204/20300 [2:01:49<06:32,  5.34it/s] 90%|████████▉ | 18216/20300 [2:01:51<06:31,  5.33it/s] 90%|████████▉ | 18228/20300 [2:01:53<06:31,  5.29it/s] 90%|████████▉ | 18240/20300 [2:01:56<06:30,  5.27it/s] 90%|████████▉ | 18252/20300 [2:01:58<06:27,  5.28it/s] 90%|████████▉ | 18264/20300 [2:02:00<06:23,  5.30it/s] 90%|█████████ | 18276/20300 [2:02:02<06:20,  5.31it/s] 90%|█████████ | 18288/20300 [2:02:05<06:16,  5.35it/s] 90%|█████████ | 18300/20300 [2:02:07<06:09,  5.41it/s] 90%|█████████ | 18312/20300 [2:02:09<06:04,  5.45it/s] 90%|█████████ | 18324/20300 [2:02:11<06:03,  5.44it/s] 90%|█████████ | 18336/20300 [2:02:13<06:01,  5.44it/s] 90%|█████████ | 18348/20300 [2:02:16<06:00,  5.42it/s] 90%|█████████ | 18360/20300 [2:02:18<05:58,  5.41it/s] 91%|█████████ | 18372/20300 [2:02:20<05:56,  5.41it/s] 91%|█████████ | 18384/20300 [2:02:22<05:54,  5.40it/s] 91%|█████████ | 18396/20300 [2:02:24<05:52,  5.40it/s] 91%|█████████ | 18408/20300 [2:02:27<05:49,  5.41it/s] 91%|█████████ | 18420/20300 [2:02:29<05:47,  5.41it/s] 91%|█████████ | 18432/20300 [2:02:31<05:44,  5.42it/s] 91%|█████████ | 18444/20300 [2:02:33<05:43,  5.41it/s] 91%|█████████ | 18456/20300 [2:02:36<05:43,  5.36it/s] 91%|█████████ | 18468/20300 [2:02:38<05:43,  5.33it/s] 91%|█████████ | 18480/20300 [2:02:40<05:41,  5.33it/s] 91%|█████████ | 18492/20300 [2:02:42<05:40,  5.31it/s] 91%|█████████ | 18504/20300 [2:02:45<05:38,  5.30it/s] 91%|█████████ | 18516/20300 [2:02:47<05:30,  5.40it/s] 91%|█████████▏| 18528/20300 [2:02:49<05:19,  5.55it/s] 91%|█████████▏| 18540/20300 [2:02:51<05:11,  5.64it/s] 91%|█████████▏| 18552/20300 [2:02:53<05:07,  5.68it/s] 91%|█████████▏| 18564/20300 [2:02:55<05:01,  5.76it/s] 92%|█████████▏| 18576/20300 [2:02:57<05:03,  5.69it/s] 92%|█████████▏| 18588/20300 [2:02:59<05:05,  5.60it/s] 92%|█████████▏| 18600/20300 [2:03:02<05:05,  5.57it/s] 92%|█████████▏| 18612/20300 [2:03:04<05:05,  5.52it/s] 92%|█████████▏| 18624/20300 [2:03:06<05:01,  5.55it/s] 92%|█████████▏| 18636/20300 [2:03:08<04:49,  5.75it/s] 92%|█████████▏| 18648/20300 [2:03:10<04:47,  5.74it/s] 92%|█████████▏| 18660/20300 [2:03:12<04:48,  5.68it/s] 92%|█████████▏| 18672/20300 [2:03:14<04:39,  5.83it/s] 92%|█████████▏| 18684/20300 [2:03:16<04:39,  5.79it/s] 92%|█████████▏| 18696/20300 [2:03:18<04:43,  5.67it/s] 92%|█████████▏| 18708/20300 [2:03:21<04:42,  5.63it/s] 92%|█████████▏| 18720/20300 [2:03:23<04:43,  5.58it/s] 92%|█████████▏| 18732/20300 [2:03:25<04:44,  5.50it/s] 92%|█████████▏| 18744/20300 [2:03:27<04:35,  5.66it/s] 92%|█████████▏| 18756/20300 [2:03:29<04:27,  5.78it/s] 92%|█████████▏| 18768/20300 [2:03:31<04:28,  5.71it/s] 93%|█████████▎| 18780/20300 [2:03:33<04:24,  5.75it/s] 93%|█████████▎| 18792/20300 [2:03:35<04:18,  5.84it/s] 93%|█████████▎| 18804/20300 [2:03:37<04:20,  5.74it/s] 93%|█████████▎| 18816/20300 [2:03:40<04:22,  5.65it/s] 93%|█████████▎| 18828/20300 [2:03:42<04:22,  5.61it/s] 93%|█████████▎| 18840/20300 [2:03:44<04:23,  5.54it/s] 93%|█████████▎| 18852/20300 [2:03:46<04:19,  5.58it/s] 93%|█████████▎| 18864/20300 [2:03:48<04:07,  5.79it/s] 93%|█████████▎| 18876/20300 [2:03:50<04:08,  5.74it/s] 93%|█████████▎| 18888/20300 [2:03:52<04:07,  5.70it/s] 93%|█████████▎| 18900/20300 [2:03:54<03:59,  5.84it/s] 93%|█████████▎| 18912/20300 [2:03:56<04:00,  5.77it/s] 93%|█████████▎| 18924/20300 [2:03:58<04:03,  5.65it/s] 93%|█████████▎| 18936/20300 [2:04:01<04:04,  5.59it/s] 93%|█████████▎| 18948/20300 [2:04:03<04:05,  5.52it/s] 93%|█████████▎| 18960/20300 [2:04:05<04:02,  5.52it/s] 93%|█████████▎| 18972/20300 [2:04:07<03:52,  5.72it/s] 94%|█████████▎| 18984/20300 [2:04:09<03:51,  5.68it/s] 94%|█████████▎| 18996/20300 [2:04:11<03:51,  5.64it/s] 94%|█████████▎| 19008/20300 [2:04:13<03:46,  5.69it/s] 94%|█████████▎| 19020/20300 [2:04:16<03:46,  5.65it/s] 94%|█████████▍| 19032/20300 [2:04:18<03:47,  5.58it/s] 94%|█████████▍| 19044/20300 [2:04:20<03:43,  5.63it/s] 94%|█████████▍| 19056/20300 [2:04:22<03:40,  5.64it/s] 94%|█████████▍| 19068/20300 [2:04:24<03:39,  5.61it/s] 94%|█████████▍| 19080/20300 [2:04:26<03:36,  5.64it/s] 94%|█████████▍| 19092/20300 [2:04:28<03:34,  5.62it/s] 94%|█████████▍| 19104/20300 [2:04:31<03:33,  5.60it/s] 94%|█████████▍| 19116/20300 [2:04:33<03:30,  5.62it/s] 94%|█████████▍| 19128/20300 [2:04:35<03:29,  5.60it/s] 94%|█████████▍| 19140/20300 [2:04:37<03:28,  5.57it/s] 94%|█████████▍| 19152/20300 [2:04:39<03:25,  5.58it/s] 94%|█████████▍| 19164/20300 [2:04:41<03:24,  5.54it/s] 94%|█████████▍| 19176/20300 [2:04:44<03:23,  5.51it/s] 95%|█████████▍| 19188/20300 [2:04:46<03:21,  5.52it/s] 95%|█████████▍| 19200/20300 [2:04:48<03:18,  5.54it/s] 95%|█████████▍| 19212/20300 [2:04:50<03:16,  5.53it/s] 95%|█████████▍| 19224/20300 [2:04:52<03:13,  5.57it/s] 95%|█████████▍| 19236/20300 [2:04:54<03:06,  5.71it/s] 95%|█████████▍| 19248/20300 [2:04:56<03:02,  5.78it/s] 95%|█████████▍| 19260/20300 [2:04:58<02:57,  5.86it/s] 95%|█████████▍| 19272/20300 [2:05:00<02:54,  5.89it/s] 95%|█████████▍| 19284/20300 [2:05:02<02:51,  5.91it/s] 95%|█████████▌| 19296/20300 [2:05:04<02:52,  5.81it/s] 95%|█████████▌| 19308/20300 [2:05:07<02:54,  5.69it/s] 95%|█████████▌| 19320/20300 [2:05:09<02:53,  5.64it/s] 95%|█████████▌| 19332/20300 [2:05:11<02:52,  5.61it/s] 95%|█████████▌| 19344/20300 [2:05:13<02:51,  5.58it/s] 95%|█████████▌| 19356/20300 [2:05:15<02:45,  5.70it/s] 95%|█████████▌| 19368/20300 [2:05:17<02:39,  5.85it/s] 95%|█████████▌| 19380/20300 [2:05:19<02:37,  5.82it/s] 96%|█████████▌| 19392/20300 [2:05:21<02:34,  5.86it/s] 96%|█████████▌| 19404/20300 [2:05:23<02:30,  5.96it/s] 96%|█████████▌| 19416/20300 [2:05:25<02:29,  5.91it/s] 96%|█████████▌| 19428/20300 [2:05:27<02:29,  5.81it/s] 96%|█████████▌| 19440/20300 [2:05:29<02:29,  5.75it/s] 96%|█████████▌| 19452/20300 [2:05:32<02:29,  5.65it/s] 96%|█████████▌| 19464/20300 [2:05:34<02:29,  5.60it/s] 96%|█████████▌| 19476/20300 [2:05:36<02:25,  5.66it/s] 96%|█████████▌| 19488/20300 [2:05:38<02:20,  5.76it/s] 96%|█████████▌| 19500/20300 [2:05:40<02:17,  5.82it/s] 96%|█████████▌| 19512/20300 [2:05:42<02:14,  5.85it/s] 96%|█████████▌| 19524/20300 [2:05:44<02:11,  5.90it/s] 96%|█████████▌| 19536/20300 [2:05:46<02:09,  5.89it/s] 96%|█████████▋| 19548/20300 [2:05:48<02:08,  5.86it/s] 96%|█████████▋| 19560/20300 [2:05:50<02:06,  5.86it/s] 96%|█████████▋| 19572/20300 [2:05:52<02:04,  5.86it/s] 96%|█████████▋| 19584/20300 [2:05:54<02:02,  5.85it/s] 97%|█████████▋| 19596/20300 [2:05:56<02:01,  5.81it/s] 97%|█████████▋| 19608/20300 [2:05:58<02:00,  5.75it/s] 97%|█████████▋| 19620/20300 [2:06:01<01:59,  5.71it/s] 97%|█████████▋| 19632/20300 [2:06:03<01:55,  5.78it/s] 97%|█████████▋| 19644/20300 [2:06:04<01:51,  5.88it/s] 97%|█████████▋| 19656/20300 [2:06:06<01:49,  5.90it/s] 97%|█████████▋| 19668/20300 [2:06:08<01:45,  5.98it/s] 97%|█████████▋| 19680/20300 [2:06:10<01:43,  6.00it/s] 97%|█████████▋| 19692/20300 [2:06:12<01:42,  5.93it/s] 97%|█████████▋| 19704/20300 [2:06:15<01:40,  5.91it/s] 97%|█████████▋| 19716/20300 [2:06:17<01:38,  5.90it/s] 97%|█████████▋| 19728/20300 [2:06:19<01:37,  5.88it/s] 97%|█████████▋| 19740/20300 [2:06:21<01:35,  5.85it/s] 97%|█████████▋| 19752/20300 [2:06:23<01:34,  5.80it/s] 97%|█████████▋| 19764/20300 [2:06:25<01:33,  5.73it/s] 97%|█████████▋| 19776/20300 [2:06:27<01:31,  5.72it/s] 97%|█████████▋| 19788/20300 [2:06:29<01:29,  5.74it/s] 98%|█████████▊| 19800/20300 [2:06:31<01:26,  5.76it/s] 98%|█████████▊| 19812/20300 [2:06:33<01:24,  5.75it/s] 98%|█████████▊| 19824/20300 [2:06:35<01:22,  5.76it/s] 98%|█████████▊| 19836/20300 [2:06:37<01:20,  5.78it/s] 98%|█████████▊| 19848/20300 [2:06:40<01:18,  5.79it/s] 98%|█████████▊| 19860/20300 [2:06:42<01:15,  5.80it/s] 98%|█████████▊| 19872/20300 [2:06:44<01:13,  5.81it/s] 98%|█████████▊| 19884/20300 [2:06:46<01:11,  5.82it/s] 98%|█████████▊| 19896/20300 [2:06:48<01:09,  5.83it/s] 98%|█████████▊| 19908/20300 [2:06:50<01:06,  5.90it/s] 98%|█████████▊| 19920/20300 [2:06:52<01:04,  5.89it/s] 98%|█████████▊| 19932/20300 [2:06:54<01:02,  5.87it/s] 98%|█████████▊| 19944/20300 [2:06:56<01:01,  5.79it/s] 98%|█████████▊| 19956/20300 [2:06:58<01:00,  5.72it/s] 98%|█████████▊| 19968/20300 [2:07:00<00:58,  5.70it/s] 98%|█████████▊| 19980/20300 [2:07:02<00:56,  5.70it/s] 98%|█████████▊| 19992/20300 [2:07:05<00:54,  5.65it/s] 99%|█████████▊| 20004/20300 [2:07:07<00:51,  5.74it/s] 99%|█████████▊| 20016/20300 [2:07:08<00:48,  5.91it/s] 99%|█████████▊| 20028/20300 [2:07:10<00:45,  5.95it/s] 99%|█████████▊| 20040/20300 [2:07:12<00:43,  5.98it/s] 99%|█████████▉| 20052/20300 [2:07:14<00:40,  6.07it/s] 99%|█████████▉| 20064/20300 [2:07:16<00:38,  6.08it/s] 99%|█████████▉| 20076/20300 [2:07:18<00:37,  6.01it/s] 99%|█████████▉| 20088/20300 [2:07:20<00:35,  5.92it/s] 99%|█████████▉| 20100/20300 [2:07:23<00:34,  5.85it/s] 99%|█████████▉| 20112/20300 [2:07:25<00:32,  5.76it/s] 99%|█████████▉| 20124/20300 [2:07:27<00:30,  5.82it/s] 99%|█████████▉| 20136/20300 [2:07:29<00:27,  5.96it/s] 99%|█████████▉| 20148/20300 [2:07:31<00:25,  6.02it/s] 99%|█████████▉| 20160/20300 [2:07:33<00:23,  6.00it/s] 99%|█████████▉| 20172/20300 [2:07:35<00:21,  5.98it/s] 99%|█████████▉| 20184/20300 [2:07:37<00:19,  5.94it/s] 99%|█████████▉| 20196/20300 [2:07:39<00:17,  5.88it/s]100%|█████████▉| 20208/20300 [2:07:41<00:15,  5.87it/s]100%|█████████▉| 20220/20300 [2:07:43<00:13,  5.85it/s]100%|█████████▉| 20232/20300 [2:07:45<00:11,  5.84it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
100%|█████████▉| 20244/20300 [2:07:47<00:09,  5.88it/s]100%|█████████▉| 20256/20300 [2:07:49<00:07,  5.99it/s]100%|█████████▉| 20268/20300 [2:07:51<00:05,  5.95it/s]100%|█████████▉| 20280/20300 [2:07:53<00:03,  5.97it/s]100%|█████████▉| 20292/20300 [2:07:55<00:01,  6.04it/s]100%|██████████| 20300/20300 [2:07:55<00:00,  2.64it/s]
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
fatal: not a git repository (or any of the parent directories): .git
{'m_mmlu_el': {'alias': 'm_mmlu_el', 'acc,none': 0.47671271898589945, 'acc_stderr,none': 0.004215018056875214}, 'm_mmlu_hu': {'alias': 'm_mmlu_hu', 'acc,none': 0.5052979115479116, 'acc_stderr,none': 0.00438116998049635}, 'm_mmlu_tr': {'alias': 'm_mmlu_tr', 'acc,none': 0.48720603461026474, 'acc_stderr,none': 0.004298563789314996}}
