W1007 02:17:08.910728 140197951792064 torch/distributed/run.py:757] 
W1007 02:17:08.910728 140197951792064 torch/distributed/run.py:757] *****************************************
W1007 02:17:08.910728 140197951792064 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1007 02:17:08.910728 140197951792064 torch/distributed/run.py:757] *****************************************
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
using world size: 8, data-parallel size: 8, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0
WARNING: overriding default arguments for no_load_rng:True                        with no_load_rng:True
WARNING: overriding default arguments for no_load_optim:True                        with no_load_optim:True
WARNING: overriding default arguments for micro_batch_size:1                        with micro_batch_size:4
WARNING: overriding default arguments for exit_on_missing_checkpoint:True                        with exit_on_missing_checkpoint:False
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adaptive_seq_len ................................ True
  add_bias_linear ................................. False
  add_position_embedding .......................... False
  add_qkv_bias .................................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... False
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.0
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ False
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  bsz ............................................. 12
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/root/work/huangxin/nanda/Megatron-LM/llamamoe/data/data-bin/elhutr_qwen2.5_30b_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... True
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 1000000
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  enable_shared_expert ............................ True
  encoder_num_layers .............................. 36
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 2048
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1000
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 8
  ffn_hidden_size ................................. 11008
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 1024
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... True
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.0
  hidden_size ..................................... 2048
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp24-TP1PP1EP8
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 5e-05
  lr_decay_iters .................................. 5000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 300
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 32768
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.001
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_ffn_hidden_size ............................. 1376
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_lpr_loss_coeff .............................. 0.001
  moe_lpr_stage ................................... 1
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 8
  moe_token_dispatcher_type ....................... alltoall
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  moelpr_train_embeddings ......................... False
  nccl_communicator_config_path ................... None
  no_load_optim ................................... True
  no_load_rng ..................................... True
  no_persist_layer_norm ........................... False
  no_save_optim ................................... True
  no_save_rng ..................................... True
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... RMSNorm
  num_attention_heads ............................. 16
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... 24
  num_fewshot ..................................... 5
  num_layers ...................................... 36
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 2
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. True
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ True
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... rope
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  results_path .................................... /root/work/huangxin/nanda/Megatron-LM/llamamoe/eval/results/mcore_qwen2.5-3B-instruct-share-24exp-mmlu_expanded.json
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 1000000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp24-TP1PP1EP8
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 99990,8,2
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... True
  swin_backbone_type .............................. tiny
  task_list ....................................... m_mmlu_el,m_mmlu_hu,m_mmlu_tr
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. /root/work/huangxin/nanda/models/Qwen/Qwen2.5-3B-Instruct
  tokenizer_type .................................. HuggingFaceTokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 5000
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. True
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... None
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
  zero_expert_down_proj ........................... False
-------------------- end of arguments ---------------------
> building HuggingFaceTokenizer tokenizer ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
 > padded vocab (size: 151936) with 0 dummy tokens (new size: 151936)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.024 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.008 seconds
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
building GPT model ...
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[Rank 1] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
GPTModel(
  (embedding): LanguageModelEmbedding(
    (word_embeddings): VocabParallelEmbedding()
    (embedding_dropout): Dropout(p=0.0, inplace=False)
  )
  (rotary_pos_emb): RotaryEmbedding()
  (decoder): TransformerBlock(
    (layers): ModuleList(
      (0-35): 36 x TransformerLayer(
        (input_layernorm): IdentityOp()
        (self_attention): SelfAttention(
          (core_attention): TEDotProductAttention(
            (flash_attention): FlashAttention()
            (fused_attention): FusedAttention()
            (unfused_attention): UnfusedDotProductAttention(
              (scale_mask_softmax): FusedScaleMaskSoftmax()
              (attention_dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (linear_proj): TERowParallelLinear()
          (linear_qkv): TELayerNormColumnParallelLinear()
          (q_layernorm): IdentityOp()
          (k_layernorm): IdentityOp()
        )
        (pre_cross_attn_layernorm): IdentityOp()
        (cross_attention): IdentityOp()
        (cross_attn_bda): IdentityFuncOp()
        (pre_mlp_layernorm): RMSNorm()
        (mlp): MoELayer(
          (router): TopKRouter()
          (shared_expert_gate): LanguageRouter()
          (shared_expert): MLP(
            (linear_fc1): ColumnParallelLinear()
            (linear_fc2): RowParallelLinear()
          )
          (experts): SequentialMLP(
            (local_experts): ModuleList(
              (0-2): 3 x MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
            )
          )
        )
      )
    )
    (final_layernorm): RMSNorm()
  )
  (output_layer): ColumnParallelLinear()
)
Fine-tuning method: MoE-LPR stage 1
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[Rank 4] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[Rank 3] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[Rank 0] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 4000903168
[Rank 7] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[Rank 5] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[Rank 2] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
[Rank 6] trainable params: 0 || all params: 4,000,903,168 || trainable%: 0.0000
 loading checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp24-TP1PP1EP8 at iteration 12000
 checkpoint version 3.0
  successfully loaded checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp24-TP1PP1EP8 [ t 0, p 0 ] at iteration 12000
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_tr from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
  0%|          | 0/20300 [00:00<?, ?it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  0%|          | 12/20300 [00:13<6:26:14,  1.14s/it]  0%|          | 24/20300 [00:22<5:09:30,  1.09it/s]  0%|          | 36/20300 [00:29<4:18:40,  1.31it/s]  0%|          | 48/20300 [00:38<4:17:11,  1.31it/s]  0%|          | 60/20300 [00:45<3:55:41,  1.43it/s]  0%|          | 72/20300 [00:55<4:02:03,  1.39it/s]  0%|          | 84/20300 [01:02<3:47:34,  1.48it/s]  0%|          | 96/20300 [01:11<3:56:12,  1.43it/s]  1%|          | 108/20300 [01:18<3:44:15,  1.50it/s]  1%|          | 120/20300 [01:27<3:53:33,  1.44it/s]  1%|          | 132/20300 [01:34<3:42:40,  1.51it/s]  1%|          | 144/20300 [01:43<3:52:10,  1.45it/s]  1%|          | 156/20300 [01:50<3:41:23,  1.52it/s]  1%|          | 168/20300 [01:59<3:51:26,  1.45it/s]  1%|          | 180/20300 [02:06<3:41:18,  1.52it/s]  1%|          | 192/20300 [02:15<3:51:27,  1.45it/s]  1%|          | 204/20300 [02:22<3:40:55,  1.52it/s]  1%|          | 216/20300 [02:32<3:50:44,  1.45it/s]  1%|          | 228/20300 [02:39<3:40:21,  1.52it/s]  1%|          | 240/20300 [02:48<3:50:26,  1.45it/s]  1%|          | 252/20300 [02:55<3:40:07,  1.52it/s]  1%|▏         | 264/20300 [03:04<3:50:11,  1.45it/s]  1%|▏         | 276/20300 [03:11<3:39:50,  1.52it/s]  1%|▏         | 288/20300 [03:20<3:49:46,  1.45it/s]  1%|▏         | 300/20300 [03:27<3:39:41,  1.52it/s]  2%|▏         | 312/20300 [03:36<3:49:38,  1.45it/s]  2%|▏         | 324/20300 [03:43<3:39:32,  1.52it/s]  2%|▏         | 336/20300 [03:52<3:49:22,  1.45it/s]  2%|▏         | 348/20300 [03:59<3:39:12,  1.52it/s]  2%|▏         | 360/20300 [04:09<3:49:20,  1.45it/s]  2%|▏         | 372/20300 [04:16<3:39:00,  1.52it/s]  2%|▏         | 384/20300 [04:25<3:48:57,  1.45it/s]  2%|▏         | 396/20300 [04:32<3:38:48,  1.52it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 408/20300 [04:41<3:52:05,  1.43it/s]  2%|▏         | 420/20300 [04:48<3:40:57,  1.50it/s]  2%|▏         | 432/20300 [04:58<3:49:51,  1.44it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 444/20300 [05:05<3:43:21,  1.48it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 456/20300 [05:15<3:55:55,  1.40it/s]  2%|▏         | 468/20300 [05:22<3:42:51,  1.48it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  2%|▏         | 480/20300 [05:31<3:53:33,  1.41it/s]  2%|▏         | 492/20300 [05:38<3:40:25,  1.50it/s]  2%|▏         | 504/20300 [05:47<3:46:55,  1.45it/s]  3%|▎         | 516/20300 [05:54<3:35:17,  1.53it/s]  3%|▎         | 528/20300 [06:02<3:42:18,  1.48it/s]  3%|▎         | 540/20300 [06:09<3:31:21,  1.56it/s]  3%|▎         | 552/20300 [06:18<3:38:43,  1.50it/s]  3%|▎         | 564/20300 [06:25<3:28:11,  1.58it/s]  3%|▎         | 576/20300 [06:33<3:35:21,  1.53it/s]  3%|▎         | 588/20300 [06:40<3:25:15,  1.60it/s]  3%|▎         | 600/20300 [06:48<3:32:07,  1.55it/s]  3%|▎         | 612/20300 [06:55<3:22:12,  1.62it/s]  3%|▎         | 624/20300 [07:03<3:29:02,  1.57it/s]  3%|▎         | 636/20300 [07:09<3:19:45,  1.64it/s]  3%|▎         | 648/20300 [07:18<3:26:30,  1.59it/s]  3%|▎         | 660/20300 [07:24<3:17:17,  1.66it/s]  3%|▎         | 672/20300 [07:32<3:23:54,  1.60it/s]  3%|▎         | 684/20300 [07:38<3:15:00,  1.68it/s]  3%|▎         | 696/20300 [07:46<3:21:04,  1.62it/s]  3%|▎         | 708/20300 [07:53<3:11:56,  1.70it/s]  4%|▎         | 720/20300 [08:00<3:18:01,  1.65it/s]  4%|▎         | 732/20300 [08:07<3:09:18,  1.72it/s]  4%|▎         | 744/20300 [08:14<3:15:11,  1.67it/s]  4%|▎         | 756/20300 [08:21<3:06:56,  1.74it/s]  4%|▍         | 768/20300 [08:28<3:12:51,  1.69it/s]  4%|▍         | 780/20300 [08:34<3:04:46,  1.76it/s]  4%|▍         | 792/20300 [08:42<3:10:35,  1.71it/s]  4%|▍         | 804/20300 [08:48<3:02:36,  1.78it/s]  4%|▍         | 816/20300 [08:55<3:08:20,  1.72it/s]  4%|▍         | 828/20300 [09:01<3:00:31,  1.80it/s]  4%|▍         | 840/20300 [09:09<3:06:21,  1.74it/s]  4%|▍         | 852/20300 [09:15<2:58:51,  1.81it/s]  4%|▍         | 864/20300 [09:22<3:04:30,  1.76it/s]  4%|▍         | 876/20300 [09:28<2:57:02,  1.83it/s]  4%|▍         | 888/20300 [09:35<3:02:29,  1.77it/s]  4%|▍         | 900/20300 [09:41<2:55:23,  1.84it/s]  4%|▍         | 912/20300 [09:48<3:00:48,  1.79it/s]  5%|▍         | 924/20300 [09:54<2:53:44,  1.86it/s]  5%|▍         | 936/20300 [10:01<2:58:52,  1.80it/s]  5%|▍         | 948/20300 [10:07<2:51:56,  1.88it/s]  5%|▍         | 960/20300 [10:14<2:56:39,  1.82it/s]  5%|▍         | 972/20300 [10:20<2:49:42,  1.90it/s]  5%|▍         | 984/20300 [10:27<2:54:19,  1.85it/s]  5%|▍         | 996/20300 [10:33<2:47:43,  1.92it/s]  5%|▍         | 1008/20300 [10:39<2:52:28,  1.86it/s]  5%|▌         | 1020/20300 [10:45<2:46:03,  1.94it/s]  5%|▌         | 1032/20300 [10:52<2:50:33,  1.88it/s]  5%|▌         | 1044/20300 [10:57<2:44:23,  1.95it/s]  5%|▌         | 1056/20300 [11:04<2:48:53,  1.90it/s]  5%|▌         | 1068/20300 [11:10<2:42:48,  1.97it/s]  5%|▌         | 1080/20300 [11:16<2:46:59,  1.92it/s]  5%|▌         | 1092/20300 [11:22<2:41:02,  1.99it/s]  5%|▌         | 1104/20300 [11:28<2:45:05,  1.94it/s]  5%|▌         | 1116/20300 [11:34<2:39:17,  2.01it/s]  6%|▌         | 1128/20300 [11:40<2:43:07,  1.96it/s]  6%|▌         | 1140/20300 [11:46<2:37:18,  2.03it/s]  6%|▌         | 1152/20300 [11:52<2:41:06,  1.98it/s]  6%|▌         | 1164/20300 [11:58<2:35:38,  2.05it/s]  6%|▌         | 1176/20300 [12:04<2:39:16,  2.00it/s]  6%|▌         | 1188/20300 [12:09<2:34:04,  2.07it/s]  6%|▌         | 1200/20300 [12:16<2:37:39,  2.02it/s]  6%|▌         | 1212/20300 [12:21<2:32:33,  2.09it/s]  6%|▌         | 1224/20300 [12:27<2:35:58,  2.04it/s]  6%|▌         | 1236/20300 [12:32<2:31:00,  2.10it/s]  6%|▌         | 1248/20300 [12:38<2:34:13,  2.06it/s]  6%|▌         | 1260/20300 [12:44<2:29:31,  2.12it/s]  6%|▋         | 1272/20300 [12:50<2:32:36,  2.08it/s]  6%|▋         | 1284/20300 [12:55<2:28:07,  2.14it/s]  6%|▋         | 1296/20300 [13:01<2:31:00,  2.10it/s]  6%|▋         | 1308/20300 [13:06<2:26:42,  2.16it/s]  7%|▋         | 1320/20300 [13:12<2:29:30,  2.12it/s]  7%|▋         | 1332/20300 [13:17<2:25:10,  2.18it/s]  7%|▋         | 1344/20300 [13:23<2:28:02,  2.13it/s]  7%|▋         | 1356/20300 [13:28<2:23:49,  2.20it/s]  7%|▋         | 1368/20300 [13:34<2:26:28,  2.15it/s]  7%|▋         | 1380/20300 [13:39<2:22:20,  2.22it/s]  7%|▋         | 1392/20300 [13:45<2:24:44,  2.18it/s]  7%|▋         | 1404/20300 [13:50<2:21:01,  2.23it/s]  7%|▋         | 1416/20300 [13:56<2:23:38,  2.19it/s]  7%|▋         | 1428/20300 [14:01<2:19:58,  2.25it/s]  7%|▋         | 1440/20300 [14:06<2:22:15,  2.21it/s]  7%|▋         | 1452/20300 [14:11<2:18:36,  2.27it/s]  7%|▋         | 1464/20300 [14:17<2:20:50,  2.23it/s]  7%|▋         | 1476/20300 [14:22<2:17:16,  2.29it/s]  7%|▋         | 1488/20300 [14:27<2:19:27,  2.25it/s]  7%|▋         | 1500/20300 [14:32<2:16:00,  2.30it/s]  7%|▋         | 1512/20300 [14:38<2:18:09,  2.27it/s]  8%|▊         | 1524/20300 [14:43<2:14:54,  2.32it/s]  8%|▊         | 1536/20300 [14:48<2:17:02,  2.28it/s]  8%|▊         | 1548/20300 [14:53<2:13:54,  2.33it/s]  8%|▊         | 1560/20300 [14:58<2:15:41,  2.30it/s]  8%|▊         | 1572/20300 [15:03<2:12:44,  2.35it/s]  8%|▊         | 1584/20300 [15:08<2:14:47,  2.31it/s]  8%|▊         | 1596/20300 [15:13<2:11:51,  2.36it/s]  8%|▊         | 1608/20300 [15:19<2:13:36,  2.33it/s]  8%|▊         | 1620/20300 [15:23<2:10:41,  2.38it/s]  8%|▊         | 1632/20300 [15:29<2:12:27,  2.35it/s]  8%|▊         | 1644/20300 [15:33<2:09:49,  2.40it/s]  8%|▊         | 1656/20300 [15:39<2:11:30,  2.36it/s]  8%|▊         | 1668/20300 [15:43<2:08:52,  2.41it/s]  8%|▊         | 1680/20300 [15:49<2:10:31,  2.38it/s]  8%|▊         | 1692/20300 [15:53<2:08:02,  2.42it/s]  8%|▊         | 1704/20300 [15:59<2:09:38,  2.39it/s]  8%|▊         | 1716/20300 [16:03<2:07:15,  2.43it/s]  9%|▊         | 1728/20300 [16:08<2:08:46,  2.40it/s]  9%|▊         | 1740/20300 [16:13<2:06:13,  2.45it/s]  9%|▊         | 1752/20300 [16:18<2:07:11,  2.43it/s]  9%|▊         | 1764/20300 [16:23<2:04:56,  2.47it/s]  9%|▊         | 1776/20300 [16:28<2:06:10,  2.45it/s]  9%|▉         | 1788/20300 [16:32<2:03:52,  2.49it/s]  9%|▉         | 1800/20300 [16:37<2:05:21,  2.46it/s]  9%|▉         | 1812/20300 [16:42<2:03:13,  2.50it/s]  9%|▉         | 1824/20300 [16:47<2:04:10,  2.48it/s]  9%|▉         | 1836/20300 [16:52<2:02:11,  2.52it/s]  9%|▉         | 1848/20300 [16:57<2:03:30,  2.49it/s]  9%|▉         | 1860/20300 [17:01<2:01:23,  2.53it/s]  9%|▉         | 1872/20300 [17:06<2:02:29,  2.51it/s]  9%|▉         | 1884/20300 [17:10<2:00:20,  2.55it/s]  9%|▉         | 1896/20300 [17:15<2:01:32,  2.52it/s]  9%|▉         | 1908/20300 [17:20<1:59:33,  2.56it/s]  9%|▉         | 1920/20300 [17:25<2:00:29,  2.54it/s] 10%|▉         | 1932/20300 [17:29<1:58:33,  2.58it/s] 10%|▉         | 1944/20300 [17:34<1:59:35,  2.56it/s] 10%|▉         | 1956/20300 [17:38<1:57:55,  2.59it/s] 10%|▉         | 1968/20300 [17:43<1:58:49,  2.57it/s] 10%|▉         | 1980/20300 [17:48<1:56:58,  2.61it/s] 10%|▉         | 1992/20300 [17:52<1:57:47,  2.59it/s] 10%|▉         | 2004/20300 [17:57<1:56:17,  2.62it/s] 10%|▉         | 2016/20300 [18:01<1:56:58,  2.61it/s] 10%|▉         | 2028/20300 [18:06<1:55:24,  2.64it/s] 10%|█         | 2040/20300 [18:11<1:56:09,  2.62it/s] 10%|█         | 2052/20300 [18:15<1:54:53,  2.65it/s] 10%|█         | 2064/20300 [18:20<1:55:27,  2.63it/s] 10%|█         | 2076/20300 [18:24<1:54:06,  2.66it/s] 10%|█         | 2088/20300 [18:29<1:54:37,  2.65it/s] 10%|█         | 2100/20300 [18:33<1:53:07,  2.68it/s] 10%|█         | 2112/20300 [18:37<1:53:37,  2.67it/s] 10%|█         | 2124/20300 [18:42<1:52:20,  2.70it/s] 11%|█         | 2136/20300 [18:46<1:52:45,  2.68it/s] 11%|█         | 2148/20300 [18:51<1:51:40,  2.71it/s] 11%|█         | 2160/20300 [18:55<1:51:47,  2.70it/s] 11%|█         | 2172/20300 [18:59<1:50:45,  2.73it/s] 11%|█         | 2184/20300 [19:04<1:51:13,  2.71it/s] 11%|█         | 2196/20300 [19:08<1:50:09,  2.74it/s] 11%|█         | 2208/20300 [19:13<1:50:09,  2.74it/s] 11%|█         | 2220/20300 [19:17<1:49:25,  2.75it/s] 11%|█         | 2232/20300 [19:21<1:49:31,  2.75it/s] 11%|█         | 2244/20300 [19:25<1:48:42,  2.77it/s] 11%|█         | 2256/20300 [19:30<1:48:51,  2.76it/s] 11%|█         | 2268/20300 [19:34<1:47:59,  2.78it/s] 11%|█         | 2280/20300 [19:38<1:47:57,  2.78it/s] 11%|█▏        | 2292/20300 [19:43<1:47:09,  2.80it/s] 11%|█▏        | 2304/20300 [19:47<1:46:57,  2.80it/s] 11%|█▏        | 2316/20300 [19:51<1:46:15,  2.82it/s] 11%|█▏        | 2328/20300 [19:55<1:46:11,  2.82it/s] 12%|█▏        | 2340/20300 [20:00<1:45:47,  2.83it/s] 12%|█▏        | 2352/20300 [20:04<1:45:47,  2.83it/s] 12%|█▏        | 2364/20300 [20:08<1:45:03,  2.85it/s] 12%|█▏        | 2376/20300 [20:12<1:44:50,  2.85it/s] 12%|█▏        | 2388/20300 [20:16<1:44:28,  2.86it/s] 12%|█▏        | 2400/20300 [20:21<1:44:24,  2.86it/s] 12%|█▏        | 2412/20300 [20:25<1:43:55,  2.87it/s] 12%|█▏        | 2424/20300 [20:29<1:43:46,  2.87it/s] 12%|█▏        | 2436/20300 [20:33<1:43:19,  2.88it/s] 12%|█▏        | 2448/20300 [20:37<1:42:47,  2.89it/s] 12%|█▏        | 2460/20300 [20:41<1:42:23,  2.90it/s] 12%|█▏        | 2472/20300 [20:45<1:42:13,  2.91it/s] 12%|█▏        | 2484/20300 [20:49<1:41:55,  2.91it/s] 12%|█▏        | 2496/20300 [20:53<1:41:39,  2.92it/s] 12%|█▏        | 2508/20300 [20:58<1:41:11,  2.93it/s] 12%|█▏        | 2520/20300 [21:02<1:41:01,  2.93it/s] 12%|█▏        | 2532/20300 [21:06<1:40:55,  2.93it/s] 13%|█▎        | 2544/20300 [21:10<1:40:46,  2.94it/s] 13%|█▎        | 2556/20300 [21:14<1:40:23,  2.95it/s] 13%|█▎        | 2568/20300 [21:18<1:40:18,  2.95it/s] 13%|█▎        | 2580/20300 [21:22<1:40:03,  2.95it/s] 13%|█▎        | 2592/20300 [21:26<1:40:14,  2.94it/s] 13%|█▎        | 2604/20300 [21:30<1:39:55,  2.95it/s] 13%|█▎        | 2616/20300 [21:34<1:39:47,  2.95it/s] 13%|█▎        | 2628/20300 [21:38<1:39:36,  2.96it/s] 13%|█▎        | 2640/20300 [21:42<1:39:25,  2.96it/s] 13%|█▎        | 2652/20300 [21:46<1:39:13,  2.96it/s] 13%|█▎        | 2664/20300 [21:50<1:38:54,  2.97it/s] 13%|█▎        | 2676/20300 [21:54<1:38:49,  2.97it/s] 13%|█▎        | 2688/20300 [21:58<1:38:38,  2.98it/s] 13%|█▎        | 2700/20300 [22:02<1:38:29,  2.98it/s] 13%|█▎        | 2712/20300 [22:06<1:38:28,  2.98it/s] 13%|█▎        | 2724/20300 [22:10<1:38:12,  2.98it/s] 13%|█▎        | 2736/20300 [22:14<1:38:01,  2.99it/s] 14%|█▎        | 2748/20300 [22:18<1:37:49,  2.99it/s] 14%|█▎        | 2760/20300 [22:22<1:37:37,  2.99it/s] 14%|█▎        | 2772/20300 [22:26<1:37:26,  3.00it/s] 14%|█▎        | 2784/20300 [22:30<1:37:16,  3.00it/s] 14%|█▍        | 2796/20300 [22:34<1:37:03,  3.01it/s] 14%|█▍        | 2808/20300 [22:38<1:36:59,  3.01it/s] 14%|█▍        | 2820/20300 [22:42<1:36:52,  3.01it/s] 14%|█▍        | 2832/20300 [22:46<1:36:49,  3.01it/s] 14%|█▍        | 2844/20300 [22:50<1:36:37,  3.01it/s] 14%|█▍        | 2856/20300 [22:54<1:36:37,  3.01it/s] 14%|█▍        | 2868/20300 [22:58<1:36:27,  3.01it/s] 14%|█▍        | 2880/20300 [23:02<1:36:24,  3.01it/s] 14%|█▍        | 2892/20300 [23:06<1:36:16,  3.01it/s] 14%|█▍        | 2904/20300 [23:10<1:35:57,  3.02it/s] 14%|█▍        | 2916/20300 [23:14<1:35:32,  3.03it/s] 14%|█▍        | 2928/20300 [23:18<1:35:10,  3.04it/s] 14%|█▍        | 2940/20300 [23:22<1:35:01,  3.05it/s] 15%|█▍        | 2952/20300 [23:26<1:35:08,  3.04it/s] 15%|█▍        | 2964/20300 [23:30<1:35:02,  3.04it/s] 15%|█▍        | 2976/20300 [23:34<1:35:01,  3.04it/s] 15%|█▍        | 2988/20300 [23:38<1:34:46,  3.04it/s] 15%|█▍        | 3000/20300 [23:42<1:34:38,  3.05it/s] 15%|█▍        | 3012/20300 [23:46<1:34:33,  3.05it/s] 15%|█▍        | 3024/20300 [23:50<1:34:29,  3.05it/s] 15%|█▍        | 3036/20300 [23:53<1:34:22,  3.05it/s] 15%|█▌        | 3048/20300 [23:57<1:34:16,  3.05it/s] 15%|█▌        | 3060/20300 [24:01<1:34:08,  3.05it/s] 15%|█▌        | 3072/20300 [24:05<1:33:50,  3.06it/s] 15%|█▌        | 3084/20300 [24:09<1:33:49,  3.06it/s] 15%|█▌        | 3096/20300 [24:13<1:33:48,  3.06it/s] 15%|█▌        | 3108/20300 [24:17<1:33:37,  3.06it/s] 15%|█▌        | 3120/20300 [24:21<1:33:34,  3.06it/s] 15%|█▌        | 3132/20300 [24:25<1:33:25,  3.06it/s] 15%|█▌        | 3144/20300 [24:29<1:33:23,  3.06it/s] 16%|█▌        | 3156/20300 [24:33<1:33:13,  3.07it/s] 16%|█▌        | 3168/20300 [24:37<1:32:59,  3.07it/s] 16%|█▌        | 3180/20300 [24:40<1:32:55,  3.07it/s] 16%|█▌        | 3192/20300 [24:44<1:32:32,  3.08it/s] 16%|█▌        | 3204/20300 [24:48<1:32:32,  3.08it/s] 16%|█▌        | 3216/20300 [24:52<1:32:25,  3.08it/s] 16%|█▌        | 3228/20300 [24:56<1:32:12,  3.09it/s] 16%|█▌        | 3240/20300 [25:00<1:32:08,  3.09it/s] 16%|█▌        | 3252/20300 [25:04<1:32:03,  3.09it/s] 16%|█▌        | 3264/20300 [25:08<1:31:56,  3.09it/s] 16%|█▌        | 3276/20300 [25:12<1:31:50,  3.09it/s] 16%|█▌        | 3288/20300 [25:15<1:31:53,  3.09it/s] 16%|█▋        | 3300/20300 [25:19<1:31:44,  3.09it/s] 16%|█▋        | 3312/20300 [25:23<1:31:43,  3.09it/s] 16%|█▋        | 3324/20300 [25:27<1:31:39,  3.09it/s] 16%|█▋        | 3336/20300 [25:31<1:31:28,  3.09it/s] 16%|█▋        | 3348/20300 [25:35<1:31:17,  3.09it/s] 17%|█▋        | 3360/20300 [25:39<1:31:06,  3.10it/s] 17%|█▋        | 3372/20300 [25:43<1:30:57,  3.10it/s] 17%|█▋        | 3384/20300 [25:46<1:30:55,  3.10it/s] 17%|█▋        | 3396/20300 [25:50<1:30:49,  3.10it/s] 17%|█▋        | 3408/20300 [25:54<1:30:44,  3.10it/s] 17%|█▋        | 3420/20300 [25:58<1:30:31,  3.11it/s] 17%|█▋        | 3432/20300 [26:02<1:30:28,  3.11it/s] 17%|█▋        | 3444/20300 [26:06<1:30:30,  3.10it/s] 17%|█▋        | 3456/20300 [26:10<1:30:21,  3.11it/s] 17%|█▋        | 3468/20300 [26:13<1:30:16,  3.11it/s] 17%|█▋        | 3480/20300 [26:17<1:30:08,  3.11it/s] 17%|█▋        | 3492/20300 [26:21<1:30:05,  3.11it/s] 17%|█▋        | 3504/20300 [26:25<1:29:58,  3.11it/s] 17%|█▋        | 3516/20300 [26:29<1:29:49,  3.11it/s] 17%|█▋        | 3528/20300 [26:33<1:29:41,  3.12it/s] 17%|█▋        | 3540/20300 [26:37<1:29:38,  3.12it/s] 17%|█▋        | 3552/20300 [26:40<1:29:37,  3.11it/s] 18%|█▊        | 3564/20300 [26:44<1:29:26,  3.12it/s] 18%|█▊        | 3576/20300 [26:48<1:29:26,  3.12it/s] 18%|█▊        | 3588/20300 [26:52<1:29:17,  3.12it/s] 18%|█▊        | 3600/20300 [26:56<1:29:16,  3.12it/s] 18%|█▊        | 3612/20300 [27:00<1:29:08,  3.12it/s] 18%|█▊        | 3624/20300 [27:03<1:29:02,  3.12it/s] 18%|█▊        | 3636/20300 [27:07<1:28:58,  3.12it/s] 18%|█▊        | 3648/20300 [27:11<1:28:50,  3.12it/s] 18%|█▊        | 3660/20300 [27:15<1:28:49,  3.12it/s] 18%|█▊        | 3672/20300 [27:19<1:28:40,  3.13it/s] 18%|█▊        | 3684/20300 [27:23<1:28:30,  3.13it/s] 18%|█▊        | 3696/20300 [27:26<1:28:26,  3.13it/s] 18%|█▊        | 3708/20300 [27:30<1:28:20,  3.13it/s] 18%|█▊        | 3720/20300 [27:34<1:28:20,  3.13it/s] 18%|█▊        | 3732/20300 [27:38<1:28:09,  3.13it/s] 18%|█▊        | 3744/20300 [27:42<1:28:09,  3.13it/s] 19%|█▊        | 3756/20300 [27:46<1:28:03,  3.13it/s] 19%|█▊        | 3768/20300 [27:49<1:27:56,  3.13it/s] 19%|█▊        | 3780/20300 [27:53<1:27:48,  3.14it/s] 19%|█▊        | 3792/20300 [27:57<1:27:49,  3.13it/s] 19%|█▊        | 3804/20300 [28:01<1:27:43,  3.13it/s] 19%|█▉        | 3816/20300 [28:05<1:27:35,  3.14it/s] 19%|█▉        | 3828/20300 [28:09<1:27:24,  3.14it/s] 19%|█▉        | 3840/20300 [28:12<1:27:18,  3.14it/s] 19%|█▉        | 3852/20300 [28:16<1:27:18,  3.14it/s] 19%|█▉        | 3864/20300 [28:20<1:27:15,  3.14it/s] 19%|█▉        | 3876/20300 [28:24<1:27:14,  3.14it/s] 19%|█▉        | 3888/20300 [28:28<1:27:08,  3.14it/s] 19%|█▉        | 3900/20300 [28:32<1:26:59,  3.14it/s] 19%|█▉        | 3912/20300 [28:35<1:26:38,  3.15it/s] 19%|█▉        | 3924/20300 [28:39<1:26:30,  3.16it/s] 19%|█▉        | 3936/20300 [28:43<1:26:24,  3.16it/s] 19%|█▉        | 3948/20300 [28:47<1:26:18,  3.16it/s] 20%|█▉        | 3960/20300 [28:50<1:26:19,  3.15it/s] 20%|█▉        | 3972/20300 [28:54<1:26:13,  3.16it/s] 20%|█▉        | 3984/20300 [28:58<1:26:01,  3.16it/s] 20%|█▉        | 3996/20300 [29:02<1:25:56,  3.16it/s] 20%|█▉        | 4008/20300 [29:06<1:25:54,  3.16it/s] 20%|█▉        | 4020/20300 [29:09<1:25:49,  3.16it/s] 20%|█▉        | 4032/20300 [29:13<1:25:46,  3.16it/s] 20%|█▉        | 4044/20300 [29:17<1:25:37,  3.16it/s] 20%|█▉        | 4056/20300 [29:21<1:25:38,  3.16it/s] 20%|██        | 4068/20300 [29:25<1:25:26,  3.17it/s] 20%|██        | 4080/20300 [29:28<1:25:18,  3.17it/s] 20%|██        | 4092/20300 [29:32<1:25:15,  3.17it/s] 20%|██        | 4104/20300 [29:36<1:25:12,  3.17it/s] 20%|██        | 4116/20300 [29:40<1:25:05,  3.17it/s] 20%|██        | 4128/20300 [29:44<1:25:00,  3.17it/s] 20%|██        | 4140/20300 [29:47<1:24:58,  3.17it/s] 20%|██        | 4152/20300 [29:51<1:24:56,  3.17it/s] 21%|██        | 4164/20300 [29:55<1:24:52,  3.17it/s] 21%|██        | 4176/20300 [29:59<1:24:31,  3.18it/s] 21%|██        | 4188/20300 [30:02<1:24:28,  3.18it/s] 21%|██        | 4200/20300 [30:06<1:24:18,  3.18it/s] 21%|██        | 4212/20300 [30:10<1:24:16,  3.18it/s] 21%|██        | 4224/20300 [30:14<1:24:08,  3.18it/s] 21%|██        | 4236/20300 [30:17<1:24:04,  3.18it/s] 21%|██        | 4248/20300 [30:21<1:23:56,  3.19it/s] 21%|██        | 4260/20300 [30:25<1:23:53,  3.19it/s] 21%|██        | 4272/20300 [30:29<1:23:40,  3.19it/s] 21%|██        | 4284/20300 [30:33<1:23:40,  3.19it/s] 21%|██        | 4296/20300 [30:36<1:23:34,  3.19it/s] 21%|██        | 4308/20300 [30:40<1:23:28,  3.19it/s] 21%|██▏       | 4320/20300 [30:44<1:23:30,  3.19it/s] 21%|██▏       | 4332/20300 [30:48<1:23:28,  3.19it/s] 21%|██▏       | 4344/20300 [30:51<1:23:22,  3.19it/s] 21%|██▏       | 4356/20300 [30:55<1:23:16,  3.19it/s] 22%|██▏       | 4368/20300 [30:59<1:23:15,  3.19it/s] 22%|██▏       | 4380/20300 [31:03<1:23:11,  3.19it/s] 22%|██▏       | 4392/20300 [31:06<1:23:09,  3.19it/s] 22%|██▏       | 4404/20300 [31:10<1:23:09,  3.19it/s] 22%|██▏       | 4416/20300 [31:14<1:22:57,  3.19it/s] 22%|██▏       | 4428/20300 [31:18<1:22:44,  3.20it/s] 22%|██▏       | 4440/20300 [31:21<1:22:36,  3.20it/s] 22%|██▏       | 4452/20300 [31:25<1:22:22,  3.21it/s] 22%|██▏       | 4464/20300 [31:29<1:22:20,  3.21it/s] 22%|██▏       | 4476/20300 [31:33<1:22:08,  3.21it/s] 22%|██▏       | 4488/20300 [31:36<1:21:58,  3.21it/s] 22%|██▏       | 4500/20300 [31:40<1:21:53,  3.22it/s] 22%|██▏       | 4512/20300 [31:44<1:21:49,  3.22it/s] 22%|██▏       | 4524/20300 [31:47<1:21:42,  3.22it/s] 22%|██▏       | 4536/20300 [31:51<1:21:36,  3.22it/s] 22%|██▏       | 4548/20300 [31:55<1:21:35,  3.22it/s] 22%|██▏       | 4560/20300 [31:59<1:21:28,  3.22it/s] 23%|██▎       | 4572/20300 [32:02<1:21:26,  3.22it/s] 23%|██▎       | 4584/20300 [32:06<1:21:25,  3.22it/s] 23%|██▎       | 4596/20300 [32:10<1:21:18,  3.22it/s] 23%|██▎       | 4608/20300 [32:14<1:21:11,  3.22it/s] 23%|██▎       | 4620/20300 [32:17<1:20:50,  3.23it/s] 23%|██▎       | 4632/20300 [32:21<1:20:40,  3.24it/s] 23%|██▎       | 4644/20300 [32:25<1:20:26,  3.24it/s] 23%|██▎       | 4656/20300 [32:28<1:20:13,  3.25it/s] 23%|██▎       | 4668/20300 [32:32<1:19:59,  3.26it/s] 23%|██▎       | 4680/20300 [32:36<1:19:52,  3.26it/s] 23%|██▎       | 4692/20300 [32:39<1:19:54,  3.26it/s] 23%|██▎       | 4704/20300 [32:43<1:19:45,  3.26it/s] 23%|██▎       | 4716/20300 [32:47<1:19:52,  3.25it/s] 23%|██▎       | 4728/20300 [32:50<1:19:39,  3.26it/s] 23%|██▎       | 4740/20300 [32:54<1:19:40,  3.26it/s] 23%|██▎       | 4752/20300 [32:58<1:19:34,  3.26it/s] 23%|██▎       | 4764/20300 [33:01<1:19:31,  3.26it/s] 24%|██▎       | 4776/20300 [33:05<1:19:30,  3.25it/s] 24%|██▎       | 4788/20300 [33:09<1:19:22,  3.26it/s] 24%|██▎       | 4800/20300 [33:12<1:19:16,  3.26it/s] 24%|██▎       | 4812/20300 [33:16<1:19:15,  3.26it/s] 24%|██▍       | 4824/20300 [33:20<1:18:55,  3.27it/s] 24%|██▍       | 4836/20300 [33:24<1:19:00,  3.26it/s] 24%|██▍       | 4848/20300 [33:27<1:18:41,  3.27it/s] 24%|██▍       | 4860/20300 [33:31<1:18:44,  3.27it/s] 24%|██▍       | 4872/20300 [33:35<1:18:35,  3.27it/s] 24%|██▍       | 4884/20300 [33:38<1:18:38,  3.27it/s] 24%|██▍       | 4896/20300 [33:42<1:18:32,  3.27it/s] 24%|██▍       | 4908/20300 [33:46<1:18:22,  3.27it/s] 24%|██▍       | 4920/20300 [33:49<1:18:17,  3.27it/s] 24%|██▍       | 4932/20300 [33:53<1:18:11,  3.28it/s] 24%|██▍       | 4944/20300 [33:56<1:18:07,  3.28it/s] 24%|██▍       | 4956/20300 [34:00<1:18:04,  3.28it/s] 24%|██▍       | 4968/20300 [34:04<1:17:58,  3.28it/s] 25%|██▍       | 4980/20300 [34:07<1:17:59,  3.27it/s] 25%|██▍       | 4992/20300 [34:11<1:17:50,  3.28it/s] 25%|██▍       | 5004/20300 [34:15<1:17:47,  3.28it/s] 25%|██▍       | 5016/20300 [34:18<1:17:43,  3.28it/s] 25%|██▍       | 5028/20300 [34:22<1:17:34,  3.28it/s] 25%|██▍       | 5040/20300 [34:26<1:17:35,  3.28it/s] 25%|██▍       | 5052/20300 [34:29<1:17:25,  3.28it/s] 25%|██▍       | 5064/20300 [34:33<1:17:23,  3.28it/s] 25%|██▌       | 5076/20300 [34:37<1:17:20,  3.28it/s] 25%|██▌       | 5088/20300 [34:40<1:17:13,  3.28it/s] 25%|██▌       | 5100/20300 [34:44<1:17:04,  3.29it/s] 25%|██▌       | 5112/20300 [34:48<1:16:57,  3.29it/s] 25%|██▌       | 5124/20300 [34:51<1:16:50,  3.29it/s] 25%|██▌       | 5136/20300 [34:55<1:16:44,  3.29it/s] 25%|██▌       | 5148/20300 [34:59<1:16:40,  3.29it/s] 25%|██▌       | 5160/20300 [35:02<1:16:31,  3.30it/s] 25%|██▌       | 5172/20300 [35:06<1:16:28,  3.30it/s] 26%|██▌       | 5184/20300 [35:09<1:16:20,  3.30it/s] 26%|██▌       | 5196/20300 [35:13<1:16:20,  3.30it/s] 26%|██▌       | 5208/20300 [35:17<1:16:16,  3.30it/s] 26%|██▌       | 5220/20300 [35:20<1:16:14,  3.30it/s] 26%|██▌       | 5232/20300 [35:24<1:16:07,  3.30it/s] 26%|██▌       | 5244/20300 [35:28<1:16:02,  3.30it/s] 26%|██▌       | 5256/20300 [35:31<1:15:53,  3.30it/s] 26%|██▌       | 5268/20300 [35:35<1:15:48,  3.30it/s] 26%|██▌       | 5280/20300 [35:39<1:15:42,  3.31it/s] 26%|██▌       | 5292/20300 [35:42<1:15:43,  3.30it/s] 26%|██▌       | 5304/20300 [35:46<1:15:38,  3.30it/s] 26%|██▌       | 5316/20300 [35:49<1:15:32,  3.31it/s] 26%|██▌       | 5328/20300 [35:53<1:15:28,  3.31it/s] 26%|██▋       | 5340/20300 [35:57<1:15:29,  3.30it/s] 26%|██▋       | 5352/20300 [36:00<1:15:22,  3.31it/s] 26%|██▋       | 5364/20300 [36:04<1:15:13,  3.31it/s] 26%|██▋       | 5376/20300 [36:08<1:15:03,  3.31it/s] 27%|██▋       | 5388/20300 [36:11<1:14:59,  3.31it/s] 27%|██▋       | 5400/20300 [36:15<1:14:47,  3.32it/s] 27%|██▋       | 5412/20300 [36:18<1:14:53,  3.31it/s] 27%|██▋       | 5424/20300 [36:22<1:14:52,  3.31it/s] 27%|██▋       | 5436/20300 [36:26<1:14:56,  3.31it/s] 27%|██▋       | 5448/20300 [36:29<1:14:53,  3.31it/s] 27%|██▋       | 5460/20300 [36:33<1:14:47,  3.31it/s] 27%|██▋       | 5472/20300 [36:37<1:14:40,  3.31it/s] 27%|██▋       | 5484/20300 [36:40<1:14:36,  3.31it/s] 27%|██▋       | 5496/20300 [36:44<1:14:20,  3.32it/s] 27%|██▋       | 5508/20300 [36:47<1:14:14,  3.32it/s] 27%|██▋       | 5520/20300 [36:51<1:14:10,  3.32it/s] 27%|██▋       | 5532/20300 [36:55<1:14:15,  3.31it/s] 27%|██▋       | 5544/20300 [36:58<1:14:07,  3.32it/s] 27%|██▋       | 5556/20300 [37:02<1:14:11,  3.31it/s] 27%|██▋       | 5568/20300 [37:06<1:14:06,  3.31it/s] 27%|██▋       | 5580/20300 [37:09<1:14:01,  3.31it/s] 28%|██▊       | 5592/20300 [37:13<1:13:57,  3.31it/s] 28%|██▊       | 5604/20300 [37:16<1:13:49,  3.32it/s] 28%|██▊       | 5616/20300 [37:20<1:13:41,  3.32it/s] 28%|██▊       | 5628/20300 [37:24<1:13:33,  3.32it/s] 28%|██▊       | 5640/20300 [37:27<1:13:35,  3.32it/s] 28%|██▊       | 5652/20300 [37:31<1:13:42,  3.31it/s] 28%|██▊       | 5664/20300 [37:35<1:13:51,  3.30it/s] 28%|██▊       | 5676/20300 [37:38<1:13:55,  3.30it/s] 28%|██▊       | 5688/20300 [37:42<1:13:46,  3.30it/s] 28%|██▊       | 5700/20300 [37:45<1:13:39,  3.30it/s] 28%|██▊       | 5712/20300 [37:49<1:13:28,  3.31it/s] 28%|██▊       | 5724/20300 [37:53<1:13:19,  3.31it/s] 28%|██▊       | 5736/20300 [37:56<1:13:16,  3.31it/s] 28%|██▊       | 5748/20300 [38:00<1:13:13,  3.31it/s] 28%|██▊       | 5760/20300 [38:04<1:13:13,  3.31it/s] 28%|██▊       | 5772/20300 [38:07<1:13:11,  3.31it/s] 28%|██▊       | 5784/20300 [38:11<1:13:04,  3.31it/s] 29%|██▊       | 5796/20300 [38:14<1:13:03,  3.31it/s] 29%|██▊       | 5808/20300 [38:18<1:12:55,  3.31it/s] 29%|██▊       | 5820/20300 [38:22<1:12:49,  3.31it/s] 29%|██▊       | 5832/20300 [38:25<1:12:43,  3.32it/s] 29%|██▉       | 5844/20300 [38:29<1:12:44,  3.31it/s] 29%|██▉       | 5856/20300 [38:32<1:12:35,  3.32it/s] 29%|██▉       | 5868/20300 [38:36<1:12:25,  3.32it/s] 29%|██▉       | 5880/20300 [38:40<1:12:19,  3.32it/s] 29%|██▉       | 5892/20300 [38:43<1:12:14,  3.32it/s] 29%|██▉       | 5904/20300 [38:47<1:12:02,  3.33it/s] 29%|██▉       | 5916/20300 [38:50<1:11:58,  3.33it/s] 29%|██▉       | 5928/20300 [38:54<1:11:51,  3.33it/s] 29%|██▉       | 5940/20300 [38:58<1:11:54,  3.33it/s] 29%|██▉       | 5952/20300 [39:01<1:11:51,  3.33it/s] 29%|██▉       | 5964/20300 [39:05<1:11:43,  3.33it/s] 29%|██▉       | 5976/20300 [39:08<1:11:37,  3.33it/s] 29%|██▉       | 5988/20300 [39:12<1:11:30,  3.34it/s] 30%|██▉       | 6000/20300 [39:16<1:11:27,  3.34it/s] 30%|██▉       | 6012/20300 [39:19<1:11:21,  3.34it/s] 30%|██▉       | 6024/20300 [39:23<1:11:12,  3.34it/s] 30%|██▉       | 6036/20300 [39:26<1:11:08,  3.34it/s] 30%|██▉       | 6048/20300 [39:30<1:11:01,  3.34it/s] 30%|██▉       | 6060/20300 [39:34<1:10:56,  3.35it/s] 30%|██▉       | 6072/20300 [39:37<1:10:51,  3.35it/s] 30%|██▉       | 6084/20300 [39:41<1:10:48,  3.35it/s] 30%|███       | 6096/20300 [39:44<1:10:45,  3.35it/s] 30%|███       | 6108/20300 [39:48<1:10:43,  3.34it/s] 30%|███       | 6120/20300 [39:52<1:10:41,  3.34it/s] 30%|███       | 6132/20300 [39:55<1:10:33,  3.35it/s] 30%|███       | 6144/20300 [39:59<1:10:24,  3.35it/s] 30%|███       | 6156/20300 [40:02<1:10:13,  3.36it/s] 30%|███       | 6168/20300 [40:06<1:10:09,  3.36it/s] 30%|███       | 6180/20300 [40:09<1:10:00,  3.36it/s] 31%|███       | 6192/20300 [40:13<1:09:57,  3.36it/s] 31%|███       | 6204/20300 [40:17<1:09:54,  3.36it/s] 31%|███       | 6216/20300 [40:20<1:09:48,  3.36it/s] 31%|███       | 6228/20300 [40:24<1:09:37,  3.37it/s] 31%|███       | 6240/20300 [40:27<1:09:36,  3.37it/s] 31%|███       | 6252/20300 [40:31<1:09:31,  3.37it/s] 31%|███       | 6264/20300 [40:34<1:09:28,  3.37it/s] 31%|███       | 6276/20300 [40:38<1:09:21,  3.37it/s] 31%|███       | 6288/20300 [40:41<1:09:17,  3.37it/s] 31%|███       | 6300/20300 [40:45<1:09:12,  3.37it/s] 31%|███       | 6312/20300 [40:49<1:09:10,  3.37it/s] 31%|███       | 6324/20300 [40:52<1:09:03,  3.37it/s] 31%|███       | 6336/20300 [40:56<1:09:01,  3.37it/s] 31%|███▏      | 6348/20300 [40:59<1:08:52,  3.38it/s] 31%|███▏      | 6360/20300 [41:03<1:08:53,  3.37it/s] 31%|███▏      | 6372/20300 [41:06<1:08:46,  3.38it/s] 31%|███▏      | 6384/20300 [41:10<1:08:45,  3.37it/s] 32%|███▏      | 6396/20300 [41:13<1:08:41,  3.37it/s] 32%|███▏      | 6408/20300 [41:17<1:09:06,  3.35it/s] 32%|███▏      | 6420/20300 [41:21<1:08:46,  3.36it/s] 32%|███▏      | 6432/20300 [41:24<1:08:36,  3.37it/s] 32%|███▏      | 6444/20300 [41:28<1:08:25,  3.38it/s] 32%|███▏      | 6456/20300 [41:31<1:08:17,  3.38it/s] 32%|███▏      | 6468/20300 [41:35<1:08:10,  3.38it/s] 32%|███▏      | 6480/20300 [41:38<1:08:07,  3.38it/s] 32%|███▏      | 6492/20300 [41:42<1:08:00,  3.38it/s] 32%|███▏      | 6504/20300 [41:45<1:07:52,  3.39it/s] 32%|███▏      | 6516/20300 [41:49<1:07:48,  3.39it/s] 32%|███▏      | 6528/20300 [41:53<1:07:42,  3.39it/s] 32%|███▏      | 6540/20300 [41:56<1:07:41,  3.39it/s] 32%|███▏      | 6552/20300 [42:00<1:07:38,  3.39it/s] 32%|███▏      | 6564/20300 [42:03<1:07:37,  3.39it/s] 32%|███▏      | 6576/20300 [42:07<1:07:34,  3.38it/s] 32%|███▏      | 6588/20300 [42:10<1:07:32,  3.38it/s] 33%|███▎      | 6600/20300 [42:14<1:07:30,  3.38it/s] 33%|███▎      | 6612/20300 [42:17<1:07:28,  3.38it/s] 33%|███▎      | 6624/20300 [42:21<1:07:22,  3.38it/s] 33%|███▎      | 6636/20300 [42:24<1:07:16,  3.39it/s] 33%|███▎      | 6648/20300 [42:28<1:07:09,  3.39it/s] 33%|███▎      | 6660/20300 [42:32<1:07:07,  3.39it/s] 33%|███▎      | 6672/20300 [42:35<1:07:02,  3.39it/s] 33%|███▎      | 6684/20300 [42:39<1:06:54,  3.39it/s] 33%|███▎      | 6696/20300 [42:42<1:06:52,  3.39it/s] 33%|███▎      | 6708/20300 [42:46<1:06:48,  3.39it/s] 33%|███▎      | 6720/20300 [42:49<1:06:42,  3.39it/s] 33%|███▎      | 6732/20300 [42:53<1:06:40,  3.39it/s] 33%|███▎      | 6744/20300 [42:56<1:06:39,  3.39it/s] 33%|███▎      | 6756/20300 [43:00<1:06:32,  3.39it/s] 33%|███▎      | 6768/20300 [43:03<1:06:17,  3.40it/s] 33%|███▎      | 6780/20300 [43:07<1:06:16,  3.40it/s] 33%|███▎      | 6792/20300 [43:10<1:06:07,  3.40it/s] 34%|███▎      | 6804/20300 [43:14<1:05:58,  3.41it/s] 34%|███▎      | 6816/20300 [43:17<1:05:46,  3.42it/s] 34%|███▎      | 6828/20300 [43:21<1:05:43,  3.42it/s] 34%|███▎      | 6840/20300 [43:24<1:05:37,  3.42it/s] 34%|███▍      | 6852/20300 [43:28<1:05:33,  3.42it/s] 34%|███▍      | 6864/20300 [43:31<1:05:27,  3.42it/s] 34%|███▍      | 6876/20300 [43:35<1:05:20,  3.42it/s] 34%|███▍      | 6888/20300 [43:38<1:05:17,  3.42it/s] 34%|███▍      | 6900/20300 [43:42<1:05:13,  3.42it/s] 34%|███▍      | 6912/20300 [43:45<1:05:13,  3.42it/s] 34%|███▍      | 6924/20300 [43:49<1:05:15,  3.42it/s] 34%|███▍      | 6936/20300 [43:52<1:05:10,  3.42it/s] 34%|███▍      | 6948/20300 [43:56<1:05:08,  3.42it/s] 34%|███▍      | 6960/20300 [43:59<1:05:00,  3.42it/s] 34%|███▍      | 6972/20300 [44:03<1:04:50,  3.43it/s] 34%|███▍      | 6984/20300 [44:06<1:04:51,  3.42it/s] 34%|███▍      | 6996/20300 [44:10<1:04:49,  3.42it/s] 35%|███▍      | 7008/20300 [44:14<1:04:46,  3.42it/s] 35%|███▍      | 7020/20300 [44:17<1:04:41,  3.42it/s] 35%|███▍      | 7032/20300 [44:21<1:04:40,  3.42it/s] 35%|███▍      | 7044/20300 [44:24<1:04:31,  3.42it/s] 35%|███▍      | 7056/20300 [44:28<1:04:28,  3.42it/s] 35%|███▍      | 7068/20300 [44:31<1:04:15,  3.43it/s] 35%|███▍      | 7080/20300 [44:34<1:04:09,  3.43it/s] 35%|███▍      | 7092/20300 [44:38<1:04:09,  3.43it/s] 35%|███▍      | 7104/20300 [44:41<1:04:05,  3.43it/s] 35%|███▌      | 7116/20300 [44:45<1:04:02,  3.43it/s] 35%|███▌      | 7128/20300 [44:48<1:03:59,  3.43it/s] 35%|███▌      | 7140/20300 [44:52<1:03:53,  3.43it/s] 35%|███▌      | 7152/20300 [44:55<1:03:50,  3.43it/s] 35%|███▌      | 7164/20300 [44:59<1:03:51,  3.43it/s] 35%|███▌      | 7176/20300 [45:02<1:03:46,  3.43it/s] 35%|███▌      | 7188/20300 [45:06<1:03:45,  3.43it/s] 35%|███▌      | 7200/20300 [45:09<1:03:36,  3.43it/s] 36%|███▌      | 7212/20300 [45:13<1:03:30,  3.43it/s] 36%|███▌      | 7224/20300 [45:16<1:03:28,  3.43it/s] 36%|███▌      | 7236/20300 [45:20<1:03:26,  3.43it/s] 36%|███▌      | 7248/20300 [45:23<1:03:20,  3.43it/s] 36%|███▌      | 7260/20300 [45:27<1:03:13,  3.44it/s] 36%|███▌      | 7272/20300 [45:30<1:03:08,  3.44it/s] 36%|███▌      | 7284/20300 [45:34<1:03:08,  3.44it/s] 36%|███▌      | 7296/20300 [45:37<1:03:05,  3.44it/s] 36%|███▌      | 7308/20300 [45:41<1:02:54,  3.44it/s] 36%|███▌      | 7320/20300 [45:44<1:02:50,  3.44it/s] 36%|███▌      | 7332/20300 [45:48<1:02:47,  3.44it/s] 36%|███▌      | 7344/20300 [45:51<1:02:43,  3.44it/s] 36%|███▌      | 7356/20300 [45:55<1:02:40,  3.44it/s] 36%|███▋      | 7368/20300 [45:58<1:02:42,  3.44it/s] 36%|███▋      | 7380/20300 [46:02<1:02:35,  3.44it/s] 36%|███▋      | 7392/20300 [46:05<1:02:28,  3.44it/s] 36%|███▋      | 7404/20300 [46:09<1:02:26,  3.44it/s] 37%|███▋      | 7416/20300 [46:12<1:02:25,  3.44it/s] 37%|███▋      | 7428/20300 [46:16<1:02:20,  3.44it/s] 37%|███▋      | 7440/20300 [46:19<1:02:14,  3.44it/s] 37%|███▋      | 7452/20300 [46:23<1:02:08,  3.45it/s] 37%|███▋      | 7464/20300 [46:26<1:01:59,  3.45it/s] 37%|███▋      | 7476/20300 [46:30<1:01:54,  3.45it/s] 37%|███▋      | 7488/20300 [46:33<1:01:51,  3.45it/s] 37%|███▋      | 7500/20300 [46:37<1:01:44,  3.45it/s] 37%|███▋      | 7512/20300 [46:40<1:01:38,  3.46it/s] 37%|███▋      | 7524/20300 [46:44<1:01:36,  3.46it/s] 37%|███▋      | 7536/20300 [46:47<1:01:31,  3.46it/s] 37%|███▋      | 7548/20300 [46:50<1:01:27,  3.46it/s] 37%|███▋      | 7560/20300 [46:54<1:01:25,  3.46it/s] 37%|███▋      | 7572/20300 [46:57<1:01:21,  3.46it/s] 37%|███▋      | 7584/20300 [47:01<1:01:17,  3.46it/s] 37%|███▋      | 7596/20300 [47:04<1:01:14,  3.46it/s] 37%|███▋      | 7608/20300 [47:08<1:01:11,  3.46it/s] 38%|███▊      | 7620/20300 [47:11<1:00:55,  3.47it/s] 38%|███▊      | 7632/20300 [47:15<1:00:59,  3.46it/s] 38%|███▊      | 7644/20300 [47:18<1:00:49,  3.47it/s] 38%|███▊      | 7656/20300 [47:22<1:00:53,  3.46it/s] 38%|███▊      | 7668/20300 [47:25<1:00:41,  3.47it/s] 38%|███▊      | 7680/20300 [47:29<1:00:45,  3.46it/s] 38%|███▊      | 7692/20300 [47:32<1:00:31,  3.47it/s] 38%|███▊      | 7704/20300 [47:35<1:00:30,  3.47it/s] 38%|███▊      | 7716/20300 [47:39<1:00:25,  3.47it/s] 38%|███▊      | 7728/20300 [47:42<1:00:23,  3.47it/s] 38%|███▊      | 7740/20300 [47:46<1:00:17,  3.47it/s] 38%|███▊      | 7752/20300 [47:49<1:00:13,  3.47it/s] 38%|███▊      | 7764/20300 [47:53<1:00:03,  3.48it/s] 38%|███▊      | 7776/20300 [47:56<1:00:02,  3.48it/s] 38%|███▊      | 7788/20300 [48:00<59:55,  3.48it/s]   38%|███▊      | 7800/20300 [48:03<1:00:00,  3.47it/s] 38%|███▊      | 7812/20300 [48:07<59:58,  3.47it/s]   39%|███▊      | 7824/20300 [48:10<59:55,  3.47it/s] 39%|███▊      | 7836/20300 [48:13<59:48,  3.47it/s] 39%|███▊      | 7848/20300 [48:17<59:47,  3.47it/s] 39%|███▊      | 7860/20300 [48:20<59:42,  3.47it/s] 39%|███▉      | 7872/20300 [48:24<59:39,  3.47it/s] 39%|███▉      | 7884/20300 [48:27<59:37,  3.47it/s] 39%|███▉      | 7896/20300 [48:31<59:31,  3.47it/s] 39%|███▉      | 7908/20300 [48:34<59:27,  3.47it/s] 39%|███▉      | 7920/20300 [48:38<59:26,  3.47it/s] 39%|███▉      | 7932/20300 [48:41<59:22,  3.47it/s] 39%|███▉      | 7944/20300 [48:45<59:17,  3.47it/s] 39%|███▉      | 7956/20300 [48:48<59:08,  3.48it/s] 39%|███▉      | 7968/20300 [48:51<59:08,  3.48it/s] 39%|███▉      | 7980/20300 [48:55<58:56,  3.48it/s] 39%|███▉      | 7992/20300 [48:58<58:52,  3.48it/s] 39%|███▉      | 8004/20300 [49:02<58:46,  3.49it/s] 39%|███▉      | 8016/20300 [49:05<58:42,  3.49it/s] 40%|███▉      | 8028/20300 [49:09<58:37,  3.49it/s] 40%|███▉      | 8040/20300 [49:12<58:30,  3.49it/s] 40%|███▉      | 8052/20300 [49:16<58:22,  3.50it/s] 40%|███▉      | 8064/20300 [49:19<58:17,  3.50it/s] 40%|███▉      | 8076/20300 [49:22<58:09,  3.50it/s] 40%|███▉      | 8088/20300 [49:26<58:01,  3.51it/s] 40%|███▉      | 8100/20300 [49:29<58:01,  3.50it/s] 40%|███▉      | 8112/20300 [49:33<57:53,  3.51it/s] 40%|████      | 8124/20300 [49:36<57:52,  3.51it/s] 40%|████      | 8136/20300 [49:39<57:47,  3.51it/s] 40%|████      | 8148/20300 [49:43<57:44,  3.51it/s] 40%|████      | 8160/20300 [49:46<57:39,  3.51it/s] 40%|████      | 8172/20300 [49:50<57:36,  3.51it/s] 40%|████      | 8184/20300 [49:53<57:27,  3.51it/s] 40%|████      | 8196/20300 [49:57<57:30,  3.51it/s] 40%|████      | 8208/20300 [50:00<57:23,  3.51it/s] 40%|████      | 8220/20300 [50:03<57:19,  3.51it/s] 41%|████      | 8232/20300 [50:07<57:13,  3.51it/s] 41%|████      | 8244/20300 [50:10<57:09,  3.52it/s] 41%|████      | 8256/20300 [50:14<57:04,  3.52it/s] 41%|████      | 8268/20300 [50:17<57:07,  3.51it/s] 41%|████      | 8280/20300 [50:20<56:58,  3.52it/s] 41%|████      | 8292/20300 [50:24<56:56,  3.52it/s] 41%|████      | 8304/20300 [50:27<56:50,  3.52it/s] 41%|████      | 8316/20300 [50:31<56:49,  3.51it/s] 41%|████      | 8328/20300 [50:34<56:44,  3.52it/s] 41%|████      | 8340/20300 [50:38<56:50,  3.51it/s] 41%|████      | 8352/20300 [50:41<56:44,  3.51it/s] 41%|████      | 8364/20300 [50:44<56:41,  3.51it/s] 41%|████▏     | 8376/20300 [50:48<56:36,  3.51it/s] 41%|████▏     | 8388/20300 [50:51<56:36,  3.51it/s] 41%|████▏     | 8400/20300 [50:55<56:28,  3.51it/s] 41%|████▏     | 8412/20300 [50:58<56:28,  3.51it/s] 41%|████▏     | 8424/20300 [51:01<56:22,  3.51it/s] 42%|████▏     | 8436/20300 [51:05<56:21,  3.51it/s] 42%|████▏     | 8448/20300 [51:08<56:12,  3.51it/s] 42%|████▏     | 8460/20300 [51:12<56:10,  3.51it/s] 42%|████▏     | 8472/20300 [51:15<55:57,  3.52it/s] 42%|████▏     | 8484/20300 [51:18<55:56,  3.52it/s] 42%|████▏     | 8496/20300 [51:22<55:46,  3.53it/s] 42%|████▏     | 8508/20300 [51:25<55:49,  3.52it/s] 42%|████▏     | 8520/20300 [51:29<55:42,  3.52it/s] 42%|████▏     | 8532/20300 [51:32<55:39,  3.52it/s] 42%|████▏     | 8544/20300 [51:36<55:35,  3.52it/s] 42%|████▏     | 8556/20300 [51:39<55:30,  3.53it/s] 42%|████▏     | 8568/20300 [51:42<55:23,  3.53it/s] 42%|████▏     | 8580/20300 [51:46<55:23,  3.53it/s] 42%|████▏     | 8592/20300 [51:49<55:14,  3.53it/s] 42%|████▏     | 8604/20300 [51:52<55:12,  3.53it/s] 42%|████▏     | 8616/20300 [51:56<55:02,  3.54it/s] 43%|████▎     | 8628/20300 [51:59<55:01,  3.54it/s] 43%|████▎     | 8640/20300 [52:03<54:57,  3.54it/s] 43%|████▎     | 8652/20300 [52:06<54:57,  3.53it/s] 43%|████▎     | 8664/20300 [52:09<54:56,  3.53it/s] 43%|████▎     | 8676/20300 [52:13<54:50,  3.53it/s] 43%|████▎     | 8688/20300 [52:16<54:46,  3.53it/s] 43%|████▎     | 8700/20300 [52:20<54:48,  3.53it/s] 43%|████▎     | 8712/20300 [52:23<54:40,  3.53it/s] 43%|████▎     | 8724/20300 [52:26<54:35,  3.53it/s] 43%|████▎     | 8736/20300 [52:30<54:31,  3.54it/s] 43%|████▎     | 8748/20300 [52:33<54:25,  3.54it/s] 43%|████▎     | 8760/20300 [52:37<54:27,  3.53it/s] 43%|████▎     | 8772/20300 [52:40<54:24,  3.53it/s] 43%|████▎     | 8784/20300 [52:43<54:18,  3.53it/s] 43%|████▎     | 8796/20300 [52:47<54:14,  3.53it/s] 43%|████▎     | 8808/20300 [52:50<54:14,  3.53it/s] 43%|████▎     | 8820/20300 [52:54<54:08,  3.53it/s] 44%|████▎     | 8832/20300 [52:57<54:07,  3.53it/s] 44%|████▎     | 8844/20300 [53:00<54:04,  3.53it/s] 44%|████▎     | 8856/20300 [53:04<53:59,  3.53it/s] 44%|████▎     | 8868/20300 [53:07<53:56,  3.53it/s] 44%|████▎     | 8880/20300 [53:11<53:49,  3.54it/s] 44%|████▍     | 8892/20300 [53:14<53:44,  3.54it/s] 44%|████▍     | 8904/20300 [53:17<53:41,  3.54it/s] 44%|████▍     | 8916/20300 [53:21<53:31,  3.54it/s] 44%|████▍     | 8928/20300 [53:24<53:26,  3.55it/s] 44%|████▍     | 8940/20300 [53:27<53:18,  3.55it/s] 44%|████▍     | 8952/20300 [53:31<53:12,  3.55it/s] 44%|████▍     | 8964/20300 [53:34<53:07,  3.56it/s] 44%|████▍     | 8976/20300 [53:38<53:08,  3.55it/s] 44%|████▍     | 8988/20300 [53:41<53:01,  3.56it/s] 44%|████▍     | 9000/20300 [53:44<52:53,  3.56it/s] 44%|████▍     | 9012/20300 [53:48<52:52,  3.56it/s] 44%|████▍     | 9024/20300 [53:51<52:53,  3.55it/s] 45%|████▍     | 9036/20300 [53:54<52:44,  3.56it/s] 45%|████▍     | 9048/20300 [53:58<52:39,  3.56it/s] 45%|████▍     | 9060/20300 [54:01<52:34,  3.56it/s] 45%|████▍     | 9072/20300 [54:05<52:37,  3.56it/s] 45%|████▍     | 9084/20300 [54:08<52:33,  3.56it/s] 45%|████▍     | 9096/20300 [54:11<52:25,  3.56it/s] 45%|████▍     | 9108/20300 [54:15<52:22,  3.56it/s] 45%|████▍     | 9120/20300 [54:18<52:23,  3.56it/s] 45%|████▍     | 9132/20300 [54:21<52:18,  3.56it/s] 45%|████▌     | 9144/20300 [54:25<52:12,  3.56it/s] 45%|████▌     | 9156/20300 [54:28<52:11,  3.56it/s] 45%|████▌     | 9168/20300 [54:32<52:08,  3.56it/s] 45%|████▌     | 9180/20300 [54:35<52:03,  3.56it/s] 45%|████▌     | 9192/20300 [54:38<51:59,  3.56it/s] 45%|████▌     | 9204/20300 [54:42<51:56,  3.56it/s] 45%|████▌     | 9216/20300 [54:45<51:52,  3.56it/s] 45%|████▌     | 9228/20300 [54:48<51:49,  3.56it/s] 46%|████▌     | 9240/20300 [54:52<51:46,  3.56it/s] 46%|████▌     | 9252/20300 [54:55<51:42,  3.56it/s] 46%|████▌     | 9264/20300 [54:59<51:38,  3.56it/s] 46%|████▌     | 9276/20300 [55:02<51:32,  3.56it/s] 46%|████▌     | 9288/20300 [55:05<51:32,  3.56it/s] 46%|████▌     | 9300/20300 [55:09<51:30,  3.56it/s] 46%|████▌     | 9312/20300 [55:12<51:20,  3.57it/s] 46%|████▌     | 9324/20300 [55:15<51:19,  3.56it/s] 46%|████▌     | 9336/20300 [55:19<51:12,  3.57it/s] 46%|████▌     | 9348/20300 [55:22<51:12,  3.56it/s] 46%|████▌     | 9360/20300 [55:25<50:58,  3.58it/s] 46%|████▌     | 9372/20300 [55:29<50:57,  3.57it/s] 46%|████▌     | 9384/20300 [55:32<50:48,  3.58it/s] 46%|████▋     | 9396/20300 [55:35<50:47,  3.58it/s] 46%|████▋     | 9408/20300 [55:39<50:40,  3.58it/s] 46%|████▋     | 9420/20300 [55:42<50:40,  3.58it/s] 46%|████▋     | 9432/20300 [55:45<50:30,  3.59it/s] 47%|████▋     | 9444/20300 [55:49<50:29,  3.58it/s] 47%|████▋     | 9456/20300 [55:52<50:22,  3.59it/s] 47%|████▋     | 9468/20300 [55:56<50:24,  3.58it/s] 47%|████▋     | 9480/20300 [55:59<50:16,  3.59it/s] 47%|████▋     | 9492/20300 [56:02<50:14,  3.59it/s] 47%|████▋     | 9504/20300 [56:06<50:12,  3.58it/s] 47%|████▋     | 9516/20300 [56:09<50:12,  3.58it/s] 47%|████▋     | 9528/20300 [56:12<50:08,  3.58it/s] 47%|████▋     | 9540/20300 [56:16<50:05,  3.58it/s] 47%|████▋     | 9552/20300 [56:19<49:56,  3.59it/s] 47%|████▋     | 9564/20300 [56:22<49:56,  3.58it/s] 47%|████▋     | 9576/20300 [56:26<49:49,  3.59it/s] 47%|████▋     | 9588/20300 [56:29<49:46,  3.59it/s] 47%|████▋     | 9600/20300 [56:32<49:43,  3.59it/s] 47%|████▋     | 9612/20300 [56:36<49:41,  3.58it/s] 47%|████▋     | 9624/20300 [56:39<49:32,  3.59it/s] 47%|████▋     | 9636/20300 [56:42<49:34,  3.58it/s] 48%|████▊     | 9648/20300 [56:46<49:29,  3.59it/s] 48%|████▊     | 9660/20300 [56:49<49:28,  3.58it/s] 48%|████▊     | 9672/20300 [56:52<49:23,  3.59it/s] 48%|████▊     | 9684/20300 [56:56<49:19,  3.59it/s] 48%|████▊     | 9696/20300 [56:59<49:18,  3.58it/s] 48%|████▊     | 9708/20300 [57:02<49:15,  3.58it/s] 48%|████▊     | 9720/20300 [57:06<49:10,  3.59it/s] 48%|████▊     | 9732/20300 [57:09<49:07,  3.59it/s] 48%|████▊     | 9744/20300 [57:13<48:57,  3.59it/s] 48%|████▊     | 9756/20300 [57:16<49:01,  3.58it/s] 48%|████▊     | 9768/20300 [57:19<48:54,  3.59it/s] 48%|████▊     | 9780/20300 [57:23<48:55,  3.58it/s] 48%|████▊     | 9792/20300 [57:26<48:50,  3.59it/s] 48%|████▊     | 9804/20300 [57:29<48:49,  3.58it/s] 48%|████▊     | 9816/20300 [57:33<48:40,  3.59it/s] 48%|████▊     | 9828/20300 [57:36<48:38,  3.59it/s] 48%|████▊     | 9840/20300 [57:39<48:29,  3.59it/s] 49%|████▊     | 9852/20300 [57:43<48:24,  3.60it/s] 49%|████▊     | 9864/20300 [57:46<48:18,  3.60it/s] 49%|████▊     | 9876/20300 [57:49<48:14,  3.60it/s] 49%|████▊     | 9888/20300 [57:53<48:12,  3.60it/s] 49%|████▉     | 9900/20300 [57:56<48:06,  3.60it/s] 49%|████▉     | 9912/20300 [57:59<48:04,  3.60it/s] 49%|████▉     | 9924/20300 [58:03<48:05,  3.60it/s] 49%|████▉     | 9936/20300 [58:06<48:00,  3.60it/s] 49%|████▉     | 9948/20300 [58:09<47:58,  3.60it/s] 49%|████▉     | 9960/20300 [58:13<47:51,  3.60it/s] 49%|████▉     | 9972/20300 [58:16<47:47,  3.60it/s] 49%|████▉     | 9984/20300 [58:19<47:43,  3.60it/s] 49%|████▉     | 9996/20300 [58:23<47:42,  3.60it/s] 49%|████▉     | 10008/20300 [58:26<47:31,  3.61it/s] 49%|████▉     | 10020/20300 [58:29<47:30,  3.61it/s] 49%|████▉     | 10032/20300 [58:33<47:28,  3.60it/s] 49%|████▉     | 10044/20300 [58:36<47:21,  3.61it/s] 50%|████▉     | 10056/20300 [58:39<47:18,  3.61it/s] 50%|████▉     | 10068/20300 [58:43<47:12,  3.61it/s] 50%|████▉     | 10080/20300 [58:46<47:07,  3.61it/s] 50%|████▉     | 10092/20300 [58:49<47:02,  3.62it/s] 50%|████▉     | 10104/20300 [58:52<46:56,  3.62it/s] 50%|████▉     | 10116/20300 [58:56<46:53,  3.62it/s] 50%|████▉     | 10128/20300 [58:59<46:50,  3.62it/s] 50%|████▉     | 10140/20300 [59:02<46:45,  3.62it/s] 50%|█████     | 10152/20300 [59:06<46:42,  3.62it/s] 50%|█████     | 10164/20300 [59:09<46:27,  3.64it/s] 50%|█████     | 10176/20300 [59:12<46:27,  3.63it/s] 50%|█████     | 10188/20300 [59:16<46:28,  3.63it/s] 50%|█████     | 10200/20300 [59:19<46:24,  3.63it/s] 50%|█████     | 10212/20300 [59:22<46:18,  3.63it/s] 50%|█████     | 10224/20300 [59:26<46:14,  3.63it/s] 50%|█████     | 10236/20300 [59:29<46:09,  3.63it/s] 50%|█████     | 10248/20300 [59:32<46:03,  3.64it/s] 51%|█████     | 10260/20300 [59:35<46:01,  3.64it/s] 51%|█████     | 10272/20300 [59:39<45:55,  3.64it/s] 51%|█████     | 10284/20300 [59:42<45:48,  3.64it/s] 51%|█████     | 10296/20300 [59:45<45:43,  3.65it/s] 51%|█████     | 10308/20300 [59:49<45:40,  3.65it/s] 51%|█████     | 10320/20300 [59:52<45:37,  3.65it/s] 51%|█████     | 10332/20300 [59:55<45:34,  3.65it/s] 51%|█████     | 10344/20300 [59:58<45:32,  3.64it/s] 51%|█████     | 10356/20300 [1:00:02<45:25,  3.65it/s] 51%|█████     | 10368/20300 [1:00:05<45:20,  3.65it/s] 51%|█████     | 10380/20300 [1:00:08<45:15,  3.65it/s] 51%|█████     | 10392/20300 [1:00:12<45:09,  3.66it/s] 51%|█████▏    | 10404/20300 [1:00:15<45:04,  3.66it/s] 51%|█████▏    | 10416/20300 [1:00:18<44:59,  3.66it/s] 51%|█████▏    | 10428/20300 [1:00:21<44:58,  3.66it/s] 51%|█████▏    | 10440/20300 [1:00:25<44:53,  3.66it/s] 51%|█████▏    | 10452/20300 [1:00:28<44:46,  3.67it/s] 52%|█████▏    | 10464/20300 [1:00:31<44:41,  3.67it/s] 52%|█████▏    | 10476/20300 [1:00:34<44:33,  3.67it/s] 52%|█████▏    | 10488/20300 [1:00:38<44:24,  3.68it/s] 52%|█████▏    | 10500/20300 [1:00:41<44:14,  3.69it/s] 52%|█████▏    | 10512/20300 [1:00:44<44:03,  3.70it/s] 52%|█████▏    | 10524/20300 [1:00:47<44:00,  3.70it/s] 52%|█████▏    | 10536/20300 [1:00:51<43:53,  3.71it/s] 52%|█████▏    | 10548/20300 [1:00:54<43:48,  3.71it/s] 52%|█████▏    | 10560/20300 [1:00:57<43:45,  3.71it/s] 52%|█████▏    | 10572/20300 [1:01:00<43:41,  3.71it/s] 52%|█████▏    | 10584/20300 [1:01:04<43:37,  3.71it/s] 52%|█████▏    | 10596/20300 [1:01:07<43:30,  3.72it/s] 52%|█████▏    | 10608/20300 [1:01:10<43:25,  3.72it/s] 52%|█████▏    | 10620/20300 [1:01:13<43:16,  3.73it/s] 52%|█████▏    | 10632/20300 [1:01:16<43:09,  3.73it/s] 52%|█████▏    | 10644/20300 [1:01:20<43:04,  3.74it/s] 52%|█████▏    | 10656/20300 [1:01:23<43:00,  3.74it/s] 53%|█████▎    | 10668/20300 [1:01:26<42:56,  3.74it/s] 53%|█████▎    | 10680/20300 [1:01:29<42:53,  3.74it/s] 53%|█████▎    | 10692/20300 [1:01:32<42:51,  3.74it/s] 53%|█████▎    | 10704/20300 [1:01:36<42:43,  3.74it/s] 53%|█████▎    | 10716/20300 [1:01:39<42:39,  3.74it/s] 53%|█████▎    | 10728/20300 [1:01:42<42:28,  3.76it/s] 53%|█████▎    | 10740/20300 [1:01:45<42:25,  3.76it/s] 53%|█████▎    | 10752/20300 [1:01:48<42:19,  3.76it/s] 53%|█████▎    | 10764/20300 [1:01:52<42:16,  3.76it/s] 53%|█████▎    | 10776/20300 [1:01:55<42:09,  3.77it/s] 53%|█████▎    | 10788/20300 [1:01:58<42:06,  3.76it/s] 53%|█████▎    | 10800/20300 [1:02:01<42:01,  3.77it/s] 53%|█████▎    | 10812/20300 [1:02:04<42:00,  3.76it/s] 53%|█████▎    | 10824/20300 [1:02:07<41:58,  3.76it/s] 53%|█████▎    | 10836/20300 [1:02:11<41:46,  3.78it/s] 53%|█████▎    | 10848/20300 [1:02:14<41:44,  3.77it/s] 53%|█████▎    | 10860/20300 [1:02:17<41:36,  3.78it/s] 54%|█████▎    | 10872/20300 [1:02:20<41:31,  3.78it/s] 54%|█████▎    | 10884/20300 [1:02:23<41:24,  3.79it/s] 54%|█████▎    | 10896/20300 [1:02:26<41:19,  3.79it/s] 54%|█████▎    | 10908/20300 [1:02:30<41:14,  3.80it/s] 54%|█████▍    | 10920/20300 [1:02:33<41:11,  3.79it/s] 54%|█████▍    | 10932/20300 [1:02:36<41:06,  3.80it/s] 54%|█████▍    | 10944/20300 [1:02:39<41:03,  3.80it/s] 54%|█████▍    | 10956/20300 [1:02:42<40:57,  3.80it/s] 54%|█████▍    | 10968/20300 [1:02:45<40:51,  3.81it/s] 54%|█████▍    | 10980/20300 [1:02:49<40:45,  3.81it/s] 54%|█████▍    | 10992/20300 [1:02:52<40:42,  3.81it/s] 54%|█████▍    | 11004/20300 [1:02:55<40:36,  3.82it/s] 54%|█████▍    | 11016/20300 [1:02:58<40:33,  3.82it/s] 54%|█████▍    | 11028/20300 [1:03:01<40:27,  3.82it/s] 54%|█████▍    | 11040/20300 [1:03:04<40:22,  3.82it/s] 54%|█████▍    | 11052/20300 [1:03:07<40:20,  3.82it/s] 55%|█████▍    | 11064/20300 [1:03:10<40:08,  3.83it/s] 55%|█████▍    | 11076/20300 [1:03:14<40:06,  3.83it/s] 55%|█████▍    | 11088/20300 [1:03:17<40:01,  3.84it/s] 55%|█████▍    | 11100/20300 [1:03:20<39:58,  3.84it/s] 55%|█████▍    | 11112/20300 [1:03:23<39:55,  3.84it/s] 55%|█████▍    | 11124/20300 [1:03:26<39:50,  3.84it/s] 55%|█████▍    | 11136/20300 [1:03:29<39:46,  3.84it/s] 55%|█████▍    | 11148/20300 [1:03:32<39:41,  3.84it/s] 55%|█████▍    | 11160/20300 [1:03:35<39:34,  3.85it/s] 55%|█████▌    | 11172/20300 [1:03:39<39:31,  3.85it/s] 55%|█████▌    | 11184/20300 [1:03:42<39:22,  3.86it/s] 55%|█████▌    | 11196/20300 [1:03:45<39:19,  3.86it/s] 55%|█████▌    | 11208/20300 [1:03:48<39:09,  3.87it/s] 55%|█████▌    | 11220/20300 [1:03:51<39:06,  3.87it/s] 55%|█████▌    | 11232/20300 [1:03:54<39:03,  3.87it/s] 55%|█████▌    | 11244/20300 [1:03:57<39:01,  3.87it/s] 55%|█████▌    | 11256/20300 [1:04:00<38:55,  3.87it/s] 56%|█████▌    | 11268/20300 [1:04:03<38:52,  3.87it/s] 56%|█████▌    | 11280/20300 [1:04:06<38:51,  3.87it/s] 56%|█████▌    | 11292/20300 [1:04:10<38:47,  3.87it/s] 56%|█████▌    | 11304/20300 [1:04:13<38:40,  3.88it/s] 56%|█████▌    | 11316/20300 [1:04:16<38:34,  3.88it/s] 56%|█████▌    | 11328/20300 [1:04:19<38:28,  3.89it/s] 56%|█████▌    | 11340/20300 [1:04:22<38:26,  3.88it/s] 56%|█████▌    | 11352/20300 [1:04:25<38:21,  3.89it/s] 56%|█████▌    | 11364/20300 [1:04:28<38:09,  3.90it/s] 56%|█████▌    | 11376/20300 [1:04:31<38:06,  3.90it/s] 56%|█████▌    | 11388/20300 [1:04:34<38:02,  3.90it/s] 56%|█████▌    | 11400/20300 [1:04:37<37:57,  3.91it/s] 56%|█████▌    | 11412/20300 [1:04:40<37:54,  3.91it/s] 56%|█████▋    | 11424/20300 [1:04:43<37:54,  3.90it/s] 56%|█████▋    | 11436/20300 [1:04:46<37:51,  3.90it/s] 56%|█████▋    | 11448/20300 [1:04:50<37:42,  3.91it/s] 56%|█████▋    | 11460/20300 [1:04:53<37:38,  3.91it/s] 57%|█████▋    | 11472/20300 [1:04:56<37:35,  3.91it/s] 57%|█████▋    | 11484/20300 [1:04:59<37:29,  3.92it/s] 57%|█████▋    | 11496/20300 [1:05:02<37:25,  3.92it/s] 57%|█████▋    | 11508/20300 [1:05:05<37:18,  3.93it/s] 57%|█████▋    | 11520/20300 [1:05:08<37:10,  3.94it/s] 57%|█████▋    | 11532/20300 [1:05:11<37:05,  3.94it/s] 57%|█████▋    | 11544/20300 [1:05:14<37:04,  3.94it/s] 57%|█████▋    | 11556/20300 [1:05:17<37:00,  3.94it/s] 57%|█████▋    | 11568/20300 [1:05:20<36:58,  3.94it/s] 57%|█████▋    | 11580/20300 [1:05:23<36:56,  3.94it/s] 57%|█████▋    | 11592/20300 [1:05:26<36:52,  3.94it/s] 57%|█████▋    | 11604/20300 [1:05:29<36:46,  3.94it/s] 57%|█████▋    | 11616/20300 [1:05:32<36:46,  3.94it/s] 57%|█████▋    | 11628/20300 [1:05:35<36:40,  3.94it/s] 57%|█████▋    | 11640/20300 [1:05:38<36:39,  3.94it/s] 57%|█████▋    | 11652/20300 [1:05:41<36:35,  3.94it/s] 57%|█████▋    | 11664/20300 [1:05:44<36:30,  3.94it/s] 58%|█████▊    | 11676/20300 [1:05:47<36:24,  3.95it/s] 58%|█████▊    | 11688/20300 [1:05:50<36:15,  3.96it/s] 58%|█████▊    | 11700/20300 [1:05:53<36:15,  3.95it/s] 58%|█████▊    | 11712/20300 [1:05:56<36:08,  3.96it/s] 58%|█████▊    | 11724/20300 [1:06:00<36:06,  3.96it/s] 58%|█████▊    | 11736/20300 [1:06:03<36:02,  3.96it/s] 58%|█████▊    | 11748/20300 [1:06:06<36:01,  3.96it/s] 58%|█████▊    | 11760/20300 [1:06:09<35:57,  3.96it/s] 58%|█████▊    | 11772/20300 [1:06:12<35:53,  3.96it/s] 58%|█████▊    | 11784/20300 [1:06:15<35:45,  3.97it/s] 58%|█████▊    | 11796/20300 [1:06:18<35:43,  3.97it/s] 58%|█████▊    | 11808/20300 [1:06:21<35:41,  3.97it/s] 58%|█████▊    | 11820/20300 [1:06:24<35:35,  3.97it/s] 58%|█████▊    | 11832/20300 [1:06:27<35:31,  3.97it/s] 58%|█████▊    | 11844/20300 [1:06:30<35:23,  3.98it/s] 58%|█████▊    | 11856/20300 [1:06:33<35:20,  3.98it/s] 58%|█████▊    | 11868/20300 [1:06:36<35:17,  3.98it/s] 59%|█████▊    | 11880/20300 [1:06:39<35:06,  4.00it/s] 59%|█████▊    | 11892/20300 [1:06:42<35:03,  4.00it/s] 59%|█████▊    | 11904/20300 [1:06:45<35:00,  4.00it/s] 59%|█████▊    | 11916/20300 [1:06:48<34:56,  4.00it/s] 59%|█████▉    | 11928/20300 [1:06:51<34:51,  4.00it/s] 59%|█████▉    | 11940/20300 [1:06:54<34:51,  4.00it/s] 59%|█████▉    | 11952/20300 [1:06:57<34:47,  4.00it/s] 59%|█████▉    | 11964/20300 [1:07:00<34:47,  3.99it/s] 59%|█████▉    | 11976/20300 [1:07:03<34:40,  4.00it/s] 59%|█████▉    | 11988/20300 [1:07:06<34:33,  4.01it/s] 59%|█████▉    | 12000/20300 [1:07:09<34:29,  4.01it/s] 59%|█████▉    | 12012/20300 [1:07:12<34:20,  4.02it/s] 59%|█████▉    | 12024/20300 [1:07:15<34:15,  4.03it/s] 59%|█████▉    | 12036/20300 [1:07:18<34:13,  4.02it/s] 59%|█████▉    | 12048/20300 [1:07:21<34:10,  4.03it/s] 59%|█████▉    | 12060/20300 [1:07:24<34:03,  4.03it/s] 59%|█████▉    | 12072/20300 [1:07:27<33:58,  4.04it/s] 60%|█████▉    | 12084/20300 [1:07:30<33:56,  4.03it/s] 60%|█████▉    | 12096/20300 [1:07:32<33:52,  4.04it/s] 60%|█████▉    | 12108/20300 [1:07:35<33:48,  4.04it/s] 60%|█████▉    | 12120/20300 [1:07:38<33:44,  4.04it/s] 60%|█████▉    | 12132/20300 [1:07:41<33:43,  4.04it/s] 60%|█████▉    | 12144/20300 [1:07:44<33:38,  4.04it/s] 60%|█████▉    | 12156/20300 [1:07:47<33:34,  4.04it/s] 60%|█████▉    | 12168/20300 [1:07:50<33:29,  4.05it/s] 60%|██████    | 12180/20300 [1:07:53<33:24,  4.05it/s] 60%|██████    | 12192/20300 [1:07:56<33:20,  4.05it/s] 60%|██████    | 12204/20300 [1:07:59<33:14,  4.06it/s] 60%|██████    | 12216/20300 [1:08:02<33:09,  4.06it/s] 60%|██████    | 12228/20300 [1:08:05<33:03,  4.07it/s] 60%|██████    | 12240/20300 [1:08:08<33:01,  4.07it/s] 60%|██████    | 12252/20300 [1:08:11<32:59,  4.07it/s] 60%|██████    | 12264/20300 [1:08:14<32:54,  4.07it/s] 60%|██████    | 12276/20300 [1:08:17<32:50,  4.07it/s] 61%|██████    | 12288/20300 [1:08:20<32:47,  4.07it/s] 61%|██████    | 12300/20300 [1:08:23<32:44,  4.07it/s] 61%|██████    | 12312/20300 [1:08:26<32:39,  4.08it/s] 61%|██████    | 12324/20300 [1:08:29<32:32,  4.09it/s] 61%|██████    | 12336/20300 [1:08:32<32:28,  4.09it/s] 61%|██████    | 12348/20300 [1:08:34<32:22,  4.09it/s] 61%|██████    | 12360/20300 [1:08:37<32:18,  4.10it/s] 61%|██████    | 12372/20300 [1:08:40<32:15,  4.10it/s] 61%|██████    | 12384/20300 [1:08:43<32:10,  4.10it/s] 61%|██████    | 12396/20300 [1:08:46<32:08,  4.10it/s] 61%|██████    | 12408/20300 [1:08:49<32:01,  4.11it/s] 61%|██████    | 12420/20300 [1:08:52<31:59,  4.11it/s] 61%|██████    | 12432/20300 [1:08:55<31:53,  4.11it/s] 61%|██████▏   | 12444/20300 [1:08:58<31:47,  4.12it/s] 61%|██████▏   | 12456/20300 [1:09:01<31:46,  4.11it/s] 61%|██████▏   | 12468/20300 [1:09:04<31:41,  4.12it/s] 61%|██████▏   | 12480/20300 [1:09:07<31:41,  4.11it/s] 62%|██████▏   | 12492/20300 [1:09:09<31:35,  4.12it/s] 62%|██████▏   | 12504/20300 [1:09:12<31:28,  4.13it/s] 62%|██████▏   | 12516/20300 [1:09:15<31:21,  4.14it/s] 62%|██████▏   | 12528/20300 [1:09:18<31:15,  4.14it/s] 62%|██████▏   | 12540/20300 [1:09:21<31:14,  4.14it/s] 62%|██████▏   | 12552/20300 [1:09:24<31:10,  4.14it/s] 62%|██████▏   | 12564/20300 [1:09:27<31:06,  4.15it/s] 62%|██████▏   | 12576/20300 [1:09:30<31:01,  4.15it/s] 62%|██████▏   | 12588/20300 [1:09:33<30:56,  4.15it/s] 62%|██████▏   | 12600/20300 [1:09:35<30:56,  4.15it/s] 62%|██████▏   | 12612/20300 [1:09:38<30:48,  4.16it/s] 62%|██████▏   | 12624/20300 [1:09:41<30:48,  4.15it/s] 62%|██████▏   | 12636/20300 [1:09:44<30:45,  4.15it/s] 62%|██████▏   | 12648/20300 [1:09:47<30:35,  4.17it/s] 62%|██████▏   | 12660/20300 [1:09:50<30:31,  4.17it/s] 62%|██████▏   | 12672/20300 [1:09:53<30:27,  4.17it/s] 62%|██████▏   | 12684/20300 [1:09:56<30:25,  4.17it/s] 63%|██████▎   | 12696/20300 [1:09:58<30:19,  4.18it/s] 63%|██████▎   | 12708/20300 [1:10:01<30:17,  4.18it/s] 63%|██████▎   | 12720/20300 [1:10:04<30:14,  4.18it/s] 63%|██████▎   | 12732/20300 [1:10:07<30:14,  4.17it/s] 63%|██████▎   | 12744/20300 [1:10:10<30:08,  4.18it/s] 63%|██████▎   | 12756/20300 [1:10:13<30:06,  4.18it/s] 63%|██████▎   | 12768/20300 [1:10:16<30:04,  4.17it/s] 63%|██████▎   | 12780/20300 [1:10:19<30:01,  4.17it/s] 63%|██████▎   | 12792/20300 [1:10:21<29:55,  4.18it/s] 63%|██████▎   | 12804/20300 [1:10:24<29:53,  4.18it/s] 63%|██████▎   | 12816/20300 [1:10:27<29:48,  4.19it/s] 63%|██████▎   | 12828/20300 [1:10:30<29:43,  4.19it/s] 63%|██████▎   | 12840/20300 [1:10:33<29:32,  4.21it/s] 63%|██████▎   | 12852/20300 [1:10:36<29:27,  4.21it/s] 63%|██████▎   | 12864/20300 [1:10:39<29:25,  4.21it/s] 63%|██████▎   | 12876/20300 [1:10:41<29:25,  4.20it/s] 63%|██████▎   | 12888/20300 [1:10:44<29:24,  4.20it/s] 64%|██████▎   | 12900/20300 [1:10:47<29:18,  4.21it/s] 64%|██████▎   | 12912/20300 [1:10:50<29:15,  4.21it/s] 64%|██████▎   | 12924/20300 [1:10:53<29:09,  4.22it/s] 64%|██████▎   | 12936/20300 [1:10:56<29:05,  4.22it/s] 64%|██████▍   | 12948/20300 [1:10:58<28:57,  4.23it/s] 64%|██████▍   | 12960/20300 [1:11:01<28:56,  4.23it/s] 64%|██████▍   | 12972/20300 [1:11:04<28:56,  4.22it/s] 64%|██████▍   | 12984/20300 [1:11:07<28:52,  4.22it/s] 64%|██████▍   | 12996/20300 [1:11:10<28:49,  4.22it/s] 64%|██████▍   | 13008/20300 [1:11:13<28:43,  4.23it/s] 64%|██████▍   | 13020/20300 [1:11:15<28:34,  4.25it/s] 64%|██████▍   | 13032/20300 [1:11:18<28:30,  4.25it/s] 64%|██████▍   | 13044/20300 [1:11:21<28:26,  4.25it/s] 64%|██████▍   | 13056/20300 [1:11:24<28:20,  4.26it/s] 64%|██████▍   | 13068/20300 [1:11:27<28:17,  4.26it/s] 64%|██████▍   | 13080/20300 [1:11:30<28:16,  4.26it/s] 64%|██████▍   | 13092/20300 [1:11:32<28:11,  4.26it/s] 65%|██████▍   | 13104/20300 [1:11:35<28:09,  4.26it/s] 65%|██████▍   | 13116/20300 [1:11:38<28:08,  4.26it/s] 65%|██████▍   | 13128/20300 [1:11:41<28:05,  4.25it/s] 65%|██████▍   | 13140/20300 [1:11:44<28:01,  4.26it/s] 65%|██████▍   | 13152/20300 [1:11:46<27:55,  4.27it/s] 65%|██████▍   | 13164/20300 [1:11:49<27:49,  4.28it/s] 65%|██████▍   | 13176/20300 [1:11:52<27:44,  4.28it/s] 65%|██████▍   | 13188/20300 [1:11:55<27:40,  4.28it/s] 65%|██████▌   | 13200/20300 [1:11:58<27:31,  4.30it/s] 65%|██████▌   | 13212/20300 [1:12:00<27:26,  4.30it/s] 65%|██████▌   | 13224/20300 [1:12:03<27:21,  4.31it/s] 65%|██████▌   | 13236/20300 [1:12:06<27:20,  4.31it/s] 65%|██████▌   | 13248/20300 [1:12:09<27:13,  4.32it/s] 65%|██████▌   | 13260/20300 [1:12:11<27:12,  4.31it/s] 65%|██████▌   | 13272/20300 [1:12:14<27:08,  4.31it/s] 65%|██████▌   | 13284/20300 [1:12:17<27:05,  4.32it/s] 65%|██████▌   | 13296/20300 [1:12:20<27:01,  4.32it/s] 66%|██████▌   | 13308/20300 [1:12:23<26:58,  4.32it/s] 66%|██████▌   | 13320/20300 [1:12:25<26:54,  4.32it/s] 66%|██████▌   | 13332/20300 [1:12:28<26:50,  4.33it/s] 66%|██████▌   | 13344/20300 [1:12:31<26:44,  4.33it/s] 66%|██████▌   | 13356/20300 [1:12:34<26:38,  4.34it/s] 66%|██████▌   | 13368/20300 [1:12:36<26:37,  4.34it/s] 66%|██████▌   | 13380/20300 [1:12:39<26:33,  4.34it/s] 66%|██████▌   | 13392/20300 [1:12:42<26:29,  4.35it/s] 66%|██████▌   | 13404/20300 [1:12:45<26:25,  4.35it/s] 66%|██████▌   | 13416/20300 [1:12:47<26:23,  4.35it/s] 66%|██████▌   | 13428/20300 [1:12:50<26:17,  4.36it/s] 66%|██████▌   | 13440/20300 [1:12:53<26:11,  4.36it/s] 66%|██████▋   | 13452/20300 [1:12:56<26:10,  4.36it/s] 66%|██████▋   | 13464/20300 [1:12:58<26:08,  4.36it/s] 66%|██████▋   | 13476/20300 [1:13:01<26:07,  4.35it/s] 66%|██████▋   | 13488/20300 [1:13:04<26:01,  4.36it/s] 67%|██████▋   | 13500/20300 [1:13:07<26:00,  4.36it/s] 67%|██████▋   | 13512/20300 [1:13:09<25:54,  4.37it/s] 67%|██████▋   | 13524/20300 [1:13:12<25:52,  4.36it/s] 67%|██████▋   | 13536/20300 [1:13:15<25:46,  4.37it/s] 67%|██████▋   | 13548/20300 [1:13:18<25:45,  4.37it/s] 67%|██████▋   | 13560/20300 [1:13:20<25:38,  4.38it/s] 67%|██████▋   | 13572/20300 [1:13:23<25:30,  4.39it/s] 67%|██████▋   | 13584/20300 [1:13:26<25:24,  4.40it/s] 67%|██████▋   | 13596/20300 [1:13:29<25:20,  4.41it/s] 67%|██████▋   | 13608/20300 [1:13:31<25:12,  4.43it/s] 67%|██████▋   | 13620/20300 [1:13:34<25:11,  4.42it/s] 67%|██████▋   | 13632/20300 [1:13:37<25:06,  4.43it/s] 67%|██████▋   | 13644/20300 [1:13:39<25:04,  4.43it/s] 67%|██████▋   | 13656/20300 [1:13:42<25:00,  4.43it/s] 67%|██████▋   | 13668/20300 [1:13:45<24:56,  4.43it/s] 67%|██████▋   | 13680/20300 [1:13:47<24:50,  4.44it/s] 67%|██████▋   | 13692/20300 [1:13:50<24:46,  4.44it/s] 68%|██████▊   | 13704/20300 [1:13:53<24:40,  4.46it/s] 68%|██████▊   | 13716/20300 [1:13:56<24:36,  4.46it/s] 68%|██████▊   | 13728/20300 [1:13:58<24:33,  4.46it/s] 68%|██████▊   | 13740/20300 [1:14:01<24:30,  4.46it/s] 68%|██████▊   | 13752/20300 [1:14:04<24:25,  4.47it/s] 68%|██████▊   | 13764/20300 [1:14:06<24:25,  4.46it/s] 68%|██████▊   | 13776/20300 [1:14:09<24:20,  4.47it/s] 68%|██████▊   | 13788/20300 [1:14:12<24:14,  4.48it/s] 68%|██████▊   | 13800/20300 [1:14:14<24:12,  4.48it/s] 68%|██████▊   | 13812/20300 [1:14:17<24:05,  4.49it/s] 68%|██████▊   | 13824/20300 [1:14:20<24:01,  4.49it/s] 68%|██████▊   | 13836/20300 [1:14:22<23:56,  4.50it/s] 68%|██████▊   | 13848/20300 [1:14:25<23:52,  4.50it/s] 68%|██████▊   | 13860/20300 [1:14:28<23:47,  4.51it/s] 68%|██████▊   | 13872/20300 [1:14:30<23:43,  4.52it/s] 68%|██████▊   | 13884/20300 [1:14:33<23:41,  4.51it/s] 68%|██████▊   | 13896/20300 [1:14:36<23:34,  4.53it/s] 69%|██████▊   | 13908/20300 [1:14:38<23:28,  4.54it/s] 69%|██████▊   | 13920/20300 [1:14:41<23:21,  4.55it/s] 69%|██████▊   | 13932/20300 [1:14:43<23:20,  4.55it/s] 69%|██████▊   | 13944/20300 [1:14:46<23:14,  4.56it/s] 69%|██████▊   | 13956/20300 [1:14:49<23:19,  4.53it/s] 69%|██████▉   | 13968/20300 [1:14:51<23:12,  4.55it/s] 69%|██████▉   | 13980/20300 [1:14:54<23:01,  4.57it/s] 69%|██████▉   | 13992/20300 [1:14:57<22:57,  4.58it/s] 69%|██████▉   | 14004/20300 [1:14:59<22:50,  4.59it/s] 69%|██████▉   | 14016/20300 [1:15:02<22:46,  4.60it/s] 69%|██████▉   | 14028/20300 [1:15:04<22:38,  4.62it/s] 69%|██████▉   | 14040/20300 [1:15:07<22:33,  4.62it/s] 69%|██████▉   | 14052/20300 [1:15:09<22:28,  4.63it/s] 69%|██████▉   | 14064/20300 [1:15:12<22:22,  4.64it/s] 69%|██████▉   | 14076/20300 [1:15:15<22:18,  4.65it/s] 69%|██████▉   | 14088/20300 [1:15:17<22:10,  4.67it/s] 69%|██████▉   | 14100/20300 [1:15:20<22:01,  4.69it/s] 70%|██████▉   | 14112/20300 [1:15:22<21:55,  4.70it/s] 70%|██████▉   | 14124/20300 [1:15:25<21:48,  4.72it/s] 70%|██████▉   | 14136/20300 [1:15:27<21:44,  4.73it/s] 70%|██████▉   | 14148/20300 [1:15:30<21:36,  4.75it/s] 70%|██████▉   | 14160/20300 [1:15:32<21:28,  4.77it/s] 70%|██████▉   | 14172/20300 [1:15:35<21:20,  4.78it/s] 70%|██████▉   | 14184/20300 [1:15:37<21:12,  4.81it/s] 70%|██████▉   | 14196/20300 [1:15:40<21:02,  4.83it/s] 70%|██████▉   | 14208/20300 [1:15:42<20:55,  4.85it/s] 70%|███████   | 14220/20300 [1:15:45<20:45,  4.88it/s] 70%|███████   | 14232/20300 [1:15:47<20:36,  4.91it/s] 70%|███████   | 14244/20300 [1:15:49<20:29,  4.93it/s] 70%|███████   | 14256/20300 [1:15:52<20:22,  4.94it/s] 70%|███████   | 14268/20300 [1:15:54<20:16,  4.96it/s] 70%|███████   | 14280/20300 [1:15:57<20:04,  5.00it/s] 70%|███████   | 14292/20300 [1:15:59<19:59,  5.01it/s] 70%|███████   | 14304/20300 [1:16:01<19:49,  5.04it/s] 71%|███████   | 14316/20300 [1:16:04<19:42,  5.06it/s] 71%|███████   | 14328/20300 [1:16:06<19:39,  5.06it/s] 71%|███████   | 14340/20300 [1:16:08<19:29,  5.10it/s] 71%|███████   | 14352/20300 [1:16:11<19:24,  5.11it/s] 71%|███████   | 14364/20300 [1:16:13<19:17,  5.13it/s] 71%|███████   | 14376/20300 [1:16:15<19:07,  5.16it/s] 71%|███████   | 14388/20300 [1:16:18<19:00,  5.18it/s] 71%|███████   | 14400/20300 [1:16:20<18:54,  5.20it/s] 71%|███████   | 14412/20300 [1:16:22<18:45,  5.23it/s] 71%|███████   | 14424/20300 [1:16:24<18:37,  5.26it/s] 71%|███████   | 14436/20300 [1:16:27<18:30,  5.28it/s] 71%|███████   | 14448/20300 [1:16:29<18:22,  5.31it/s] 71%|███████   | 14460/20300 [1:16:31<18:14,  5.33it/s] 71%|███████▏  | 14472/20300 [1:16:33<18:08,  5.35it/s] 71%|███████▏  | 14484/20300 [1:16:35<18:02,  5.38it/s] 71%|███████▏  | 14496/20300 [1:16:38<17:54,  5.40it/s] 71%|███████▏  | 14508/20300 [1:16:40<17:47,  5.43it/s] 72%|███████▏  | 14520/20300 [1:16:42<17:40,  5.45it/s] 72%|███████▏  | 14532/20300 [1:16:44<17:35,  5.47it/s] 72%|███████▏  | 14544/20300 [1:16:46<17:28,  5.49it/s] 72%|███████▏  | 14556/20300 [1:16:49<17:21,  5.52it/s] 72%|███████▏  | 14568/20300 [1:16:51<17:15,  5.54it/s] 72%|███████▏  | 14580/20300 [1:16:53<17:09,  5.55it/s] 72%|███████▏  | 14592/20300 [1:16:55<17:01,  5.59it/s] 72%|███████▏  | 14604/20300 [1:16:57<16:54,  5.61it/s] 72%|███████▏  | 14616/20300 [1:16:59<16:50,  5.63it/s] 72%|███████▏  | 14628/20300 [1:17:01<16:44,  5.65it/s] 72%|███████▏  | 14640/20300 [1:17:03<16:37,  5.67it/s] 72%|███████▏  | 14652/20300 [1:17:05<16:30,  5.70it/s] 72%|███████▏  | 14664/20300 [1:17:08<16:23,  5.73it/s] 72%|███████▏  | 14676/20300 [1:17:10<16:16,  5.76it/s] 72%|███████▏  | 14688/20300 [1:17:12<16:12,  5.77it/s] 72%|███████▏  | 14700/20300 [1:17:14<16:06,  5.79it/s] 72%|███████▏  | 14712/20300 [1:17:16<15:58,  5.83it/s] 73%|███████▎  | 14724/20300 [1:17:18<15:55,  5.84it/s] 73%|███████▎  | 14736/20300 [1:17:20<15:51,  5.85it/s] 73%|███████▎  | 14748/20300 [1:17:22<15:43,  5.88it/s] 73%|███████▎  | 14760/20300 [1:17:24<15:38,  5.90it/s] 73%|███████▎  | 14772/20300 [1:17:26<15:35,  5.91it/s] 73%|███████▎  | 14784/20300 [1:17:28<15:30,  5.93it/s] 73%|███████▎  | 14796/20300 [1:17:30<15:24,  5.95it/s] 73%|███████▎  | 14808/20300 [1:17:32<15:20,  5.97it/s] 73%|███████▎  | 14820/20300 [1:17:34<15:16,  5.98it/s] 73%|███████▎  | 14832/20300 [1:17:36<15:09,  6.01it/s] 73%|███████▎  | 14844/20300 [1:17:38<15:06,  6.02it/s] 73%|███████▎  | 14856/20300 [1:17:40<15:01,  6.04it/s] 73%|███████▎  | 14868/20300 [1:17:42<14:56,  6.06it/s] 73%|███████▎  | 14880/20300 [1:17:44<14:49,  6.09it/s] 73%|███████▎  | 14892/20300 [1:17:46<14:46,  6.10it/s] 73%|███████▎  | 14904/20300 [1:17:48<14:41,  6.12it/s] 73%|███████▎  | 14916/20300 [1:17:50<14:36,  6.14it/s] 74%|███████▎  | 14928/20300 [1:17:52<14:33,  6.15it/s] 74%|███████▎  | 14940/20300 [1:17:53<14:31,  6.15it/s] 74%|███████▎  | 14952/20300 [1:17:55<14:28,  6.16it/s] 74%|███████▎  | 14964/20300 [1:17:57<14:25,  6.17it/s] 74%|███████▍  | 14976/20300 [1:17:59<14:18,  6.20it/s] 74%|███████▍  | 14988/20300 [1:18:01<14:14,  6.22it/s] 74%|███████▍  | 15000/20300 [1:18:03<14:09,  6.24it/s] 74%|███████▍  | 15012/20300 [1:18:05<14:07,  6.24it/s] 74%|███████▍  | 15024/20300 [1:18:07<14:01,  6.27it/s] 74%|███████▍  | 15036/20300 [1:18:09<13:59,  6.27it/s] 74%|███████▍  | 15048/20300 [1:18:11<13:55,  6.28it/s] 74%|███████▍  | 15060/20300 [1:18:13<13:52,  6.29it/s] 74%|███████▍  | 15072/20300 [1:18:15<13:47,  6.32it/s] 74%|███████▍  | 15084/20300 [1:18:16<13:41,  6.35it/s] 74%|███████▍  | 15096/20300 [1:18:18<13:38,  6.36it/s] 74%|███████▍  | 15108/20300 [1:18:20<13:35,  6.36it/s] 74%|███████▍  | 15120/20300 [1:18:22<13:34,  6.36it/s] 75%|███████▍  | 15132/20300 [1:18:24<13:31,  6.37it/s] 75%|███████▍  | 15144/20300 [1:18:26<13:29,  6.37it/s] 75%|███████▍  | 15156/20300 [1:18:28<13:25,  6.38it/s] 75%|███████▍  | 15168/20300 [1:18:30<13:25,  6.37it/s] 75%|███████▍  | 15180/20300 [1:18:31<13:21,  6.39it/s] 75%|███████▍  | 15192/20300 [1:18:33<13:17,  6.40it/s] 75%|███████▍  | 15204/20300 [1:18:35<13:15,  6.41it/s] 75%|███████▍  | 15216/20300 [1:18:37<13:11,  6.42it/s] 75%|███████▌  | 15228/20300 [1:18:39<13:09,  6.43it/s] 75%|███████▌  | 15240/20300 [1:18:41<13:05,  6.45it/s] 75%|███████▌  | 15252/20300 [1:18:43<13:03,  6.44it/s] 75%|███████▌  | 15264/20300 [1:18:44<12:58,  6.47it/s] 75%|███████▌  | 15276/20300 [1:18:46<12:55,  6.48it/s] 75%|███████▌  | 15288/20300 [1:18:48<12:51,  6.49it/s] 75%|███████▌  | 15300/20300 [1:18:50<12:49,  6.50it/s] 75%|███████▌  | 15312/20300 [1:18:52<12:46,  6.50it/s] 75%|███████▌  | 15324/20300 [1:18:54<12:44,  6.51it/s] 76%|███████▌  | 15336/20300 [1:18:55<12:41,  6.52it/s] 76%|███████▌  | 15348/20300 [1:18:57<12:39,  6.52it/s] 76%|███████▌  | 15360/20300 [1:18:59<12:37,  6.52it/s] 76%|███████▌  | 15372/20300 [1:19:01<12:36,  6.51it/s] 76%|███████▌  | 15384/20300 [1:19:03<12:34,  6.51it/s] 76%|███████▌  | 15396/20300 [1:19:05<12:33,  6.51it/s] 76%|███████▌  | 15408/20300 [1:19:07<12:31,  6.51it/s] 76%|███████▌  | 15420/20300 [1:19:08<12:28,  6.52it/s] 76%|███████▌  | 15432/20300 [1:19:10<12:24,  6.54it/s] 76%|███████▌  | 15444/20300 [1:19:12<12:22,  6.54it/s] 76%|███████▌  | 15456/20300 [1:19:14<12:19,  6.55it/s] 76%|███████▌  | 15468/20300 [1:19:16<12:15,  6.57it/s] 76%|███████▋  | 15480/20300 [1:19:17<12:11,  6.59it/s] 76%|███████▋  | 15492/20300 [1:19:19<12:08,  6.60it/s] 76%|███████▋  | 15504/20300 [1:19:21<12:06,  6.60it/s] 76%|███████▋  | 15516/20300 [1:19:23<12:03,  6.61it/s] 76%|███████▋  | 15528/20300 [1:19:25<12:02,  6.60it/s] 77%|███████▋  | 15540/20300 [1:19:27<12:00,  6.61it/s] 77%|███████▋  | 15552/20300 [1:19:28<11:58,  6.61it/s] 77%|███████▋  | 15564/20300 [1:19:30<11:55,  6.62it/s] 77%|███████▋  | 15576/20300 [1:19:32<11:53,  6.62it/s] 77%|███████▋  | 15588/20300 [1:19:34<11:50,  6.63it/s] 77%|███████▋  | 15600/20300 [1:19:36<11:49,  6.62it/s] 77%|███████▋  | 15612/20300 [1:19:37<11:47,  6.63it/s] 77%|███████▋  | 15624/20300 [1:19:39<11:45,  6.63it/s] 77%|███████▋  | 15636/20300 [1:19:41<11:44,  6.62it/s] 77%|███████▋  | 15648/20300 [1:19:43<11:42,  6.62it/s] 77%|███████▋  | 15660/20300 [1:19:45<11:39,  6.63it/s] 77%|███████▋  | 15672/20300 [1:19:46<11:37,  6.63it/s] 77%|███████▋  | 15684/20300 [1:19:48<11:33,  6.65it/s] 77%|███████▋  | 15696/20300 [1:19:50<11:32,  6.65it/s] 77%|███████▋  | 15708/20300 [1:19:52<11:29,  6.66it/s] 77%|███████▋  | 15720/20300 [1:19:54<11:27,  6.67it/s] 77%|███████▋  | 15732/20300 [1:19:55<11:24,  6.68it/s] 78%|███████▊  | 15744/20300 [1:19:57<11:22,  6.67it/s] 78%|███████▊  | 15756/20300 [1:19:59<11:19,  6.69it/s] 78%|███████▊  | 15768/20300 [1:20:01<11:17,  6.69it/s] 78%|███████▊  | 15780/20300 [1:20:03<11:14,  6.70it/s] 78%|███████▊  | 15792/20300 [1:20:04<11:12,  6.70it/s] 78%|███████▊  | 15804/20300 [1:20:06<11:11,  6.70it/s] 78%|███████▊  | 15816/20300 [1:20:08<11:08,  6.70it/s] 78%|███████▊  | 15828/20300 [1:20:10<11:07,  6.70it/s] 78%|███████▊  | 15840/20300 [1:20:12<11:05,  6.70it/s] 78%|███████▊  | 15852/20300 [1:20:13<11:03,  6.70it/s] 78%|███████▊  | 15864/20300 [1:20:15<11:01,  6.71it/s] 78%|███████▊  | 15876/20300 [1:20:17<10:59,  6.71it/s] 78%|███████▊  | 15888/20300 [1:20:19<10:57,  6.71it/s] 78%|███████▊  | 15900/20300 [1:20:20<10:56,  6.71it/s] 78%|███████▊  | 15912/20300 [1:20:22<10:54,  6.71it/s] 78%|███████▊  | 15924/20300 [1:20:24<10:52,  6.70it/s] 79%|███████▊  | 15936/20300 [1:20:26<10:48,  6.73it/s] 79%|███████▊  | 15948/20300 [1:20:28<10:46,  6.73it/s] 79%|███████▊  | 15960/20300 [1:20:29<10:43,  6.75it/s] 79%|███████▊  | 15972/20300 [1:20:31<10:40,  6.75it/s] 79%|███████▊  | 15984/20300 [1:20:33<10:38,  6.76it/s] 79%|███████▉  | 15996/20300 [1:20:35<10:35,  6.77it/s] 79%|███████▉  | 16008/20300 [1:20:36<10:32,  6.79it/s] 79%|███████▉  | 16020/20300 [1:20:38<10:30,  6.79it/s] 79%|███████▉  | 16032/20300 [1:20:40<10:27,  6.81it/s] 79%|███████▉  | 16044/20300 [1:20:42<10:25,  6.80it/s] 79%|███████▉  | 16056/20300 [1:20:43<10:22,  6.82it/s] 79%|███████▉  | 16068/20300 [1:20:45<10:20,  6.82it/s] 79%|███████▉  | 16080/20300 [1:20:47<10:18,  6.82it/s] 79%|███████▉  | 16092/20300 [1:20:49<10:16,  6.82it/s] 79%|███████▉  | 16104/20300 [1:20:51<10:14,  6.83it/s] 79%|███████▉  | 16116/20300 [1:20:52<10:12,  6.83it/s] 79%|███████▉  | 16128/20300 [1:20:54<10:10,  6.83it/s] 80%|███████▉  | 16140/20300 [1:20:56<10:08,  6.84it/s] 80%|███████▉  | 16152/20300 [1:20:58<10:04,  6.86it/s] 80%|███████▉  | 16164/20300 [1:20:59<10:03,  6.85it/s] 80%|███████▉  | 16176/20300 [1:21:01<10:01,  6.86it/s] 80%|███████▉  | 16188/20300 [1:21:03<09:59,  6.86it/s] 80%|███████▉  | 16200/20300 [1:21:05<09:56,  6.88it/s] 80%|███████▉  | 16212/20300 [1:21:06<09:53,  6.88it/s] 80%|███████▉  | 16224/20300 [1:21:08<09:51,  6.89it/s] 80%|███████▉  | 16236/20300 [1:21:10<09:49,  6.90it/s] 80%|████████  | 16248/20300 [1:21:11<09:47,  6.90it/s] 80%|████████  | 16260/20300 [1:21:13<09:44,  6.91it/s] 80%|████████  | 16272/20300 [1:21:15<09:42,  6.91it/s] 80%|████████  | 16284/20300 [1:21:17<09:39,  6.93it/s] 80%|████████  | 16296/20300 [1:21:18<09:37,  6.93it/s] 80%|████████  | 16308/20300 [1:21:20<09:36,  6.93it/s] 80%|████████  | 16320/20300 [1:21:22<09:34,  6.92it/s] 80%|████████  | 16332/20300 [1:21:24<09:32,  6.93it/s] 81%|████████  | 16344/20300 [1:21:25<09:28,  6.95it/s] 81%|████████  | 16356/20300 [1:21:27<09:26,  6.96it/s] 81%|████████  | 16368/20300 [1:21:29<09:24,  6.97it/s] 81%|████████  | 16380/20300 [1:21:30<09:20,  6.99it/s] 81%|████████  | 16392/20300 [1:21:32<09:19,  6.99it/s] 81%|████████  | 16404/20300 [1:21:34<09:17,  6.99it/s] 81%|████████  | 16416/20300 [1:21:36<09:14,  7.00it/s] 81%|████████  | 16428/20300 [1:21:37<09:12,  7.00it/s] 81%|████████  | 16440/20300 [1:21:39<09:10,  7.01it/s] 81%|████████  | 16452/20300 [1:21:41<09:09,  7.00it/s] 81%|████████  | 16464/20300 [1:21:42<09:07,  7.00it/s] 81%|████████  | 16476/20300 [1:21:44<09:05,  7.01it/s] 81%|████████  | 16488/20300 [1:21:46<09:02,  7.02it/s] 81%|████████▏ | 16500/20300 [1:21:48<09:01,  7.02it/s] 81%|████████▏ | 16512/20300 [1:21:49<08:59,  7.02it/s] 81%|████████▏ | 16524/20300 [1:21:51<08:57,  7.03it/s] 81%|████████▏ | 16536/20300 [1:21:53<08:55,  7.03it/s] 82%|████████▏ | 16548/20300 [1:21:54<08:52,  7.05it/s] 82%|████████▏ | 16560/20300 [1:21:56<08:50,  7.05it/s] 82%|████████▏ | 16572/20300 [1:21:58<08:47,  7.06it/s] 82%|████████▏ | 16584/20300 [1:21:59<08:45,  7.08it/s] 82%|████████▏ | 16596/20300 [1:22:01<08:43,  7.08it/s] 82%|████████▏ | 16608/20300 [1:22:03<08:41,  7.08it/s] 82%|████████▏ | 16620/20300 [1:22:05<08:38,  7.09it/s] 82%|████████▏ | 16632/20300 [1:22:06<08:39,  7.07it/s] 82%|████████▏ | 16644/20300 [1:22:08<08:38,  7.06it/s] 82%|████████▏ | 16656/20300 [1:22:10<08:35,  7.07it/s] 82%|████████▏ | 16668/20300 [1:22:11<08:33,  7.08it/s] 82%|████████▏ | 16680/20300 [1:22:13<08:30,  7.09it/s] 82%|████████▏ | 16692/20300 [1:22:15<08:29,  7.09it/s] 82%|████████▏ | 16704/20300 [1:22:16<08:26,  7.09it/s] 82%|████████▏ | 16716/20300 [1:22:18<08:25,  7.09it/s] 82%|████████▏ | 16728/20300 [1:22:20<08:23,  7.10it/s] 82%|████████▏ | 16740/20300 [1:22:21<08:21,  7.09it/s] 83%|████████▎ | 16752/20300 [1:22:23<08:20,  7.09it/s] 83%|████████▎ | 16764/20300 [1:22:25<08:18,  7.09it/s] 83%|████████▎ | 16776/20300 [1:22:27<08:17,  7.09it/s] 83%|████████▎ | 16788/20300 [1:22:28<08:14,  7.11it/s] 83%|████████▎ | 16800/20300 [1:22:30<08:12,  7.10it/s] 83%|████████▎ | 16812/20300 [1:22:32<08:10,  7.11it/s] 83%|████████▎ | 16824/20300 [1:22:33<08:09,  7.11it/s] 83%|████████▎ | 16836/20300 [1:22:35<08:06,  7.13it/s] 83%|████████▎ | 16848/20300 [1:22:37<08:03,  7.13it/s] 83%|████████▎ | 16860/20300 [1:22:38<08:01,  7.14it/s] 83%|████████▎ | 16872/20300 [1:22:40<08:01,  7.13it/s] 83%|████████▎ | 16884/20300 [1:22:42<07:58,  7.14it/s] 83%|████████▎ | 16896/20300 [1:22:43<07:55,  7.15it/s] 83%|████████▎ | 16908/20300 [1:22:45<07:53,  7.17it/s] 83%|████████▎ | 16920/20300 [1:22:47<07:51,  7.18it/s] 83%|████████▎ | 16932/20300 [1:22:48<07:49,  7.17it/s] 83%|████████▎ | 16944/20300 [1:22:50<07:47,  7.18it/s] 84%|████████▎ | 16956/20300 [1:22:52<07:45,  7.19it/s] 84%|████████▎ | 16968/20300 [1:22:53<07:43,  7.18it/s] 84%|████████▎ | 16980/20300 [1:22:55<07:41,  7.19it/s] 84%|████████▎ | 16992/20300 [1:22:57<07:40,  7.19it/s] 84%|████████▍ | 17004/20300 [1:22:58<07:38,  7.19it/s] 84%|████████▍ | 17016/20300 [1:23:00<07:37,  7.18it/s] 84%|████████▍ | 17028/20300 [1:23:02<07:34,  7.19it/s] 84%|████████▍ | 17040/20300 [1:23:03<07:32,  7.21it/s] 84%|████████▍ | 17052/20300 [1:23:05<07:31,  7.19it/s] 84%|████████▍ | 17064/20300 [1:23:07<07:29,  7.19it/s] 84%|████████▍ | 17076/20300 [1:23:08<07:28,  7.19it/s] 84%|████████▍ | 17088/20300 [1:23:10<07:25,  7.20it/s] 84%|████████▍ | 17100/20300 [1:23:12<07:24,  7.19it/s] 84%|████████▍ | 17112/20300 [1:23:13<07:22,  7.20it/s] 84%|████████▍ | 17124/20300 [1:23:15<07:19,  7.22it/s] 84%|████████▍ | 17136/20300 [1:23:17<07:18,  7.21it/s] 84%|████████▍ | 17148/20300 [1:23:18<07:16,  7.22it/s] 85%|████████▍ | 17160/20300 [1:23:20<07:14,  7.23it/s] 85%|████████▍ | 17172/20300 [1:23:22<07:12,  7.23it/s] 85%|████████▍ | 17184/20300 [1:23:23<07:09,  7.26it/s] 85%|████████▍ | 17196/20300 [1:23:25<07:06,  7.27it/s] 85%|████████▍ | 17208/20300 [1:23:27<07:04,  7.29it/s] 85%|████████▍ | 17220/20300 [1:23:28<07:01,  7.30it/s] 85%|████████▍ | 17232/20300 [1:23:30<07:00,  7.30it/s] 85%|████████▍ | 17244/20300 [1:23:31<06:58,  7.30it/s] 85%|████████▌ | 17256/20300 [1:23:33<06:56,  7.31it/s] 85%|████████▌ | 17268/20300 [1:23:35<06:54,  7.31it/s] 85%|████████▌ | 17280/20300 [1:23:36<06:52,  7.32it/s] 85%|████████▌ | 17292/20300 [1:23:38<06:51,  7.32it/s] 85%|████████▌ | 17304/20300 [1:23:40<06:49,  7.32it/s] 85%|████████▌ | 17316/20300 [1:23:41<06:47,  7.32it/s] 85%|████████▌ | 17328/20300 [1:23:43<06:45,  7.33it/s] 85%|████████▌ | 17340/20300 [1:23:45<06:43,  7.33it/s] 85%|████████▌ | 17352/20300 [1:23:46<06:41,  7.35it/s] 86%|████████▌ | 17364/20300 [1:23:48<06:40,  7.34it/s] 86%|████████▌ | 17376/20300 [1:23:49<06:38,  7.35it/s] 86%|████████▌ | 17388/20300 [1:23:51<06:37,  7.33it/s] 86%|████████▌ | 17400/20300 [1:23:53<06:35,  7.34it/s] 86%|████████▌ | 17412/20300 [1:23:54<06:33,  7.33it/s] 86%|████████▌ | 17424/20300 [1:23:56<06:31,  7.34it/s] 86%|████████▌ | 17436/20300 [1:23:58<06:29,  7.35it/s] 86%|████████▌ | 17448/20300 [1:23:59<06:27,  7.37it/s] 86%|████████▌ | 17460/20300 [1:24:01<06:25,  7.36it/s] 86%|████████▌ | 17472/20300 [1:24:03<06:24,  7.36it/s] 86%|████████▌ | 17484/20300 [1:24:04<06:22,  7.35it/s] 86%|████████▌ | 17496/20300 [1:24:06<06:20,  7.36it/s] 86%|████████▌ | 17508/20300 [1:24:07<06:19,  7.36it/s] 86%|████████▋ | 17520/20300 [1:24:09<06:17,  7.37it/s] 86%|████████▋ | 17532/20300 [1:24:11<06:16,  7.35it/s] 86%|████████▋ | 17544/20300 [1:24:12<06:13,  7.38it/s] 86%|████████▋ | 17556/20300 [1:24:14<06:11,  7.38it/s] 87%|████████▋ | 17568/20300 [1:24:16<06:09,  7.40it/s] 87%|████████▋ | 17580/20300 [1:24:17<06:07,  7.40it/s] 87%|████████▋ | 17592/20300 [1:24:19<06:05,  7.42it/s] 87%|████████▋ | 17604/20300 [1:24:20<06:03,  7.41it/s] 87%|████████▋ | 17616/20300 [1:24:22<06:02,  7.41it/s] 87%|████████▋ | 17628/20300 [1:24:24<06:00,  7.42it/s] 87%|████████▋ | 17640/20300 [1:24:25<05:58,  7.43it/s] 87%|████████▋ | 17652/20300 [1:24:27<05:56,  7.42it/s] 87%|████████▋ | 17664/20300 [1:24:28<05:55,  7.42it/s] 87%|████████▋ | 17676/20300 [1:24:30<05:53,  7.43it/s] 87%|████████▋ | 17688/20300 [1:24:32<05:51,  7.44it/s] 87%|████████▋ | 17700/20300 [1:24:33<05:50,  7.43it/s] 87%|████████▋ | 17712/20300 [1:24:35<05:48,  7.43it/s] 87%|████████▋ | 17724/20300 [1:24:37<05:46,  7.44it/s] 87%|████████▋ | 17736/20300 [1:24:38<05:44,  7.44it/s] 87%|████████▋ | 17748/20300 [1:24:40<05:42,  7.45it/s] 87%|████████▋ | 17760/20300 [1:24:41<05:40,  7.46it/s] 88%|████████▊ | 17772/20300 [1:24:43<05:38,  7.47it/s] 88%|████████▊ | 17784/20300 [1:24:45<05:37,  7.46it/s] 88%|████████▊ | 17796/20300 [1:24:46<05:35,  7.46it/s] 88%|████████▊ | 17808/20300 [1:24:48<05:34,  7.46it/s] 88%|████████▊ | 17820/20300 [1:24:49<05:32,  7.46it/s] 88%|████████▊ | 17832/20300 [1:24:51<05:30,  7.46it/s] 88%|████████▊ | 17844/20300 [1:24:53<05:29,  7.46it/s] 88%|████████▊ | 17856/20300 [1:24:54<05:26,  7.47it/s] 88%|████████▊ | 17868/20300 [1:24:56<05:24,  7.50it/s] 88%|████████▊ | 17880/20300 [1:24:57<05:22,  7.50it/s] 88%|████████▊ | 17892/20300 [1:24:59<05:20,  7.51it/s] 88%|████████▊ | 17904/20300 [1:25:01<05:19,  7.51it/s] 88%|████████▊ | 17916/20300 [1:25:02<05:17,  7.51it/s] 88%|████████▊ | 17928/20300 [1:25:04<05:15,  7.51it/s] 88%|████████▊ | 17940/20300 [1:25:05<05:14,  7.51it/s] 88%|████████▊ | 17952/20300 [1:25:07<05:12,  7.51it/s] 88%|████████▊ | 17964/20300 [1:25:09<05:10,  7.52it/s] 89%|████████▊ | 17976/20300 [1:25:10<05:09,  7.52it/s] 89%|████████▊ | 17988/20300 [1:25:12<05:07,  7.52it/s] 89%|████████▊ | 18000/20300 [1:25:13<05:06,  7.51it/s] 89%|████████▊ | 18012/20300 [1:25:15<05:04,  7.51it/s] 89%|████████▉ | 18024/20300 [1:25:17<05:02,  7.52it/s] 89%|████████▉ | 18036/20300 [1:25:18<05:00,  7.53it/s] 89%|████████▉ | 18048/20300 [1:25:20<04:59,  7.53it/s] 89%|████████▉ | 18060/20300 [1:25:21<04:57,  7.53it/s] 89%|████████▉ | 18072/20300 [1:25:23<04:55,  7.53it/s] 89%|████████▉ | 18084/20300 [1:25:25<04:54,  7.52it/s] 89%|████████▉ | 18096/20300 [1:25:26<04:53,  7.52it/s] 89%|████████▉ | 18108/20300 [1:25:28<04:51,  7.53it/s] 89%|████████▉ | 18120/20300 [1:25:29<04:48,  7.56it/s] 89%|████████▉ | 18132/20300 [1:25:31<04:47,  7.55it/s] 89%|████████▉ | 18144/20300 [1:25:32<04:45,  7.55it/s] 89%|████████▉ | 18156/20300 [1:25:34<04:43,  7.55it/s] 89%|████████▉ | 18168/20300 [1:25:36<04:41,  7.56it/s] 90%|████████▉ | 18180/20300 [1:25:37<04:40,  7.57it/s] 90%|████████▉ | 18192/20300 [1:25:39<04:38,  7.58it/s] 90%|████████▉ | 18204/20300 [1:25:40<04:36,  7.58it/s] 90%|████████▉ | 18216/20300 [1:25:42<04:33,  7.61it/s] 90%|████████▉ | 18228/20300 [1:25:44<04:31,  7.62it/s] 90%|████████▉ | 18240/20300 [1:25:45<04:29,  7.64it/s] 90%|████████▉ | 18252/20300 [1:25:47<04:28,  7.63it/s] 90%|████████▉ | 18264/20300 [1:25:48<04:26,  7.65it/s] 90%|█████████ | 18276/20300 [1:25:50<04:24,  7.65it/s] 90%|█████████ | 18288/20300 [1:25:51<04:22,  7.66it/s] 90%|█████████ | 18300/20300 [1:25:53<04:21,  7.66it/s] 90%|█████████ | 18312/20300 [1:25:54<04:19,  7.66it/s] 90%|█████████ | 18324/20300 [1:25:56<04:18,  7.66it/s] 90%|█████████ | 18336/20300 [1:25:58<04:16,  7.66it/s] 90%|█████████ | 18348/20300 [1:25:59<04:14,  7.66it/s] 90%|█████████ | 18360/20300 [1:26:01<04:13,  7.66it/s] 91%|█████████ | 18372/20300 [1:26:02<04:11,  7.66it/s] 91%|█████████ | 18384/20300 [1:26:04<04:09,  7.66it/s] 91%|█████████ | 18396/20300 [1:26:05<04:08,  7.65it/s] 91%|█████████ | 18408/20300 [1:26:07<04:07,  7.65it/s] 91%|█████████ | 18420/20300 [1:26:09<04:05,  7.66it/s] 91%|█████████ | 18432/20300 [1:26:10<04:03,  7.66it/s] 91%|█████████ | 18444/20300 [1:26:12<04:02,  7.67it/s] 91%|█████████ | 18456/20300 [1:26:13<04:00,  7.67it/s] 91%|█████████ | 18468/20300 [1:26:15<03:59,  7.66it/s] 91%|█████████ | 18480/20300 [1:26:16<03:57,  7.67it/s] 91%|█████████ | 18492/20300 [1:26:18<03:55,  7.67it/s] 91%|█████████ | 18504/20300 [1:26:20<03:53,  7.68it/s] 91%|█████████ | 18516/20300 [1:26:21<03:52,  7.68it/s] 91%|█████████▏| 18528/20300 [1:26:23<03:50,  7.70it/s] 91%|█████████▏| 18540/20300 [1:26:24<03:48,  7.70it/s] 91%|█████████▏| 18552/20300 [1:26:26<03:47,  7.67it/s] 91%|█████████▏| 18564/20300 [1:26:27<03:45,  7.70it/s] 92%|█████████▏| 18576/20300 [1:26:29<03:44,  7.69it/s] 92%|█████████▏| 18588/20300 [1:26:30<03:42,  7.70it/s] 92%|█████████▏| 18600/20300 [1:26:32<03:41,  7.69it/s] 92%|█████████▏| 18612/20300 [1:26:34<03:39,  7.71it/s] 92%|█████████▏| 18624/20300 [1:26:35<03:37,  7.70it/s] 92%|█████████▏| 18636/20300 [1:26:37<03:35,  7.71it/s] 92%|█████████▏| 18648/20300 [1:26:38<03:33,  7.72it/s] 92%|█████████▏| 18660/20300 [1:26:40<03:31,  7.76it/s] 92%|█████████▏| 18672/20300 [1:26:41<03:30,  7.75it/s] 92%|█████████▏| 18684/20300 [1:26:43<03:28,  7.77it/s] 92%|█████████▏| 18696/20300 [1:26:44<03:26,  7.76it/s] 92%|█████████▏| 18708/20300 [1:26:46<03:24,  7.78it/s] 92%|█████████▏| 18720/20300 [1:26:47<03:23,  7.76it/s] 92%|█████████▏| 18732/20300 [1:26:49<03:21,  7.77it/s] 92%|█████████▏| 18744/20300 [1:26:51<03:20,  7.77it/s] 92%|█████████▏| 18756/20300 [1:26:52<03:18,  7.77it/s] 92%|█████████▏| 18768/20300 [1:26:54<03:17,  7.76it/s] 93%|█████████▎| 18780/20300 [1:26:55<03:15,  7.77it/s] 93%|█████████▎| 18792/20300 [1:26:57<03:14,  7.77it/s] 93%|█████████▎| 18804/20300 [1:26:58<03:12,  7.78it/s] 93%|█████████▎| 18816/20300 [1:27:00<03:11,  7.76it/s] 93%|█████████▎| 18828/20300 [1:27:01<03:09,  7.78it/s] 93%|█████████▎| 18840/20300 [1:27:03<03:08,  7.77it/s] 93%|█████████▎| 18852/20300 [1:27:04<03:06,  7.78it/s] 93%|█████████▎| 18864/20300 [1:27:06<03:04,  7.76it/s] 93%|█████████▎| 18876/20300 [1:27:08<03:03,  7.77it/s] 93%|█████████▎| 18888/20300 [1:27:09<03:01,  7.77it/s] 93%|█████████▎| 18900/20300 [1:27:11<03:00,  7.77it/s] 93%|█████████▎| 18912/20300 [1:27:12<02:58,  7.78it/s] 93%|█████████▎| 18924/20300 [1:27:14<02:56,  7.78it/s] 93%|█████████▎| 18936/20300 [1:27:15<02:55,  7.78it/s] 93%|█████████▎| 18948/20300 [1:27:17<02:53,  7.79it/s] 93%|█████████▎| 18960/20300 [1:27:18<02:52,  7.79it/s] 93%|█████████▎| 18972/20300 [1:27:20<02:50,  7.80it/s] 94%|█████████▎| 18984/20300 [1:27:21<02:48,  7.80it/s] 94%|█████████▎| 18996/20300 [1:27:23<02:47,  7.81it/s] 94%|█████████▎| 19008/20300 [1:27:24<02:45,  7.80it/s] 94%|█████████▎| 19020/20300 [1:27:26<02:43,  7.81it/s] 94%|█████████▍| 19032/20300 [1:27:28<02:42,  7.81it/s] 94%|█████████▍| 19044/20300 [1:27:29<02:40,  7.84it/s] 94%|█████████▍| 19056/20300 [1:27:31<02:38,  7.84it/s] 94%|█████████▍| 19068/20300 [1:27:32<02:37,  7.84it/s] 94%|█████████▍| 19080/20300 [1:27:34<02:35,  7.85it/s] 94%|█████████▍| 19092/20300 [1:27:35<02:33,  7.85it/s] 94%|█████████▍| 19104/20300 [1:27:37<02:32,  7.85it/s] 94%|█████████▍| 19116/20300 [1:27:38<02:30,  7.87it/s] 94%|█████████▍| 19128/20300 [1:27:40<02:28,  7.89it/s] 94%|█████████▍| 19140/20300 [1:27:41<02:26,  7.90it/s] 94%|█████████▍| 19152/20300 [1:27:43<02:25,  7.90it/s] 94%|█████████▍| 19164/20300 [1:27:44<02:23,  7.92it/s] 94%|█████████▍| 19176/20300 [1:27:46<02:21,  7.92it/s] 95%|█████████▍| 19188/20300 [1:27:47<02:20,  7.91it/s] 95%|█████████▍| 19200/20300 [1:27:49<02:18,  7.92it/s] 95%|█████████▍| 19212/20300 [1:27:50<02:17,  7.93it/s] 95%|█████████▍| 19224/20300 [1:27:52<02:15,  7.92it/s] 95%|█████████▍| 19236/20300 [1:27:53<02:14,  7.92it/s] 95%|█████████▍| 19248/20300 [1:27:55<02:12,  7.93it/s] 95%|█████████▍| 19260/20300 [1:27:56<02:11,  7.92it/s] 95%|█████████▍| 19272/20300 [1:27:58<02:09,  7.92it/s] 95%|█████████▍| 19284/20300 [1:27:59<02:08,  7.93it/s] 95%|█████████▌| 19296/20300 [1:28:01<02:06,  7.93it/s] 95%|█████████▌| 19308/20300 [1:28:02<02:05,  7.93it/s] 95%|█████████▌| 19320/20300 [1:28:04<02:03,  7.93it/s] 95%|█████████▌| 19332/20300 [1:28:05<02:02,  7.93it/s] 95%|█████████▌| 19344/20300 [1:28:07<02:00,  7.92it/s] 95%|█████████▌| 19356/20300 [1:28:08<01:59,  7.93it/s] 95%|█████████▌| 19368/20300 [1:28:10<01:57,  7.93it/s] 95%|█████████▌| 19380/20300 [1:28:12<01:56,  7.92it/s] 96%|█████████▌| 19392/20300 [1:28:13<01:54,  7.92it/s] 96%|█████████▌| 19404/20300 [1:28:15<01:53,  7.93it/s] 96%|█████████▌| 19416/20300 [1:28:16<01:51,  7.93it/s] 96%|█████████▌| 19428/20300 [1:28:18<01:50,  7.92it/s] 96%|█████████▌| 19440/20300 [1:28:19<01:48,  7.93it/s] 96%|█████████▌| 19452/20300 [1:28:21<01:47,  7.92it/s] 96%|█████████▌| 19464/20300 [1:28:22<01:45,  7.93it/s] 96%|█████████▌| 19476/20300 [1:28:24<01:43,  7.94it/s] 96%|█████████▌| 19488/20300 [1:28:25<01:42,  7.94it/s] 96%|█████████▌| 19500/20300 [1:28:27<01:40,  7.93it/s] 96%|█████████▌| 19512/20300 [1:28:28<01:39,  7.93it/s] 96%|█████████▌| 19524/20300 [1:28:30<01:37,  7.96it/s] 96%|█████████▌| 19536/20300 [1:28:31<01:35,  7.96it/s] 96%|█████████▋| 19548/20300 [1:28:33<01:34,  7.94it/s] 96%|█████████▋| 19560/20300 [1:28:34<01:32,  7.97it/s] 96%|█████████▋| 19572/20300 [1:28:36<01:31,  7.98it/s] 96%|█████████▋| 19584/20300 [1:28:37<01:29,  8.00it/s] 97%|█████████▋| 19596/20300 [1:28:39<01:27,  8.02it/s] 97%|█████████▋| 19608/20300 [1:28:40<01:26,  8.03it/s] 97%|█████████▋| 19620/20300 [1:28:42<01:24,  8.03it/s] 97%|█████████▋| 19632/20300 [1:28:43<01:22,  8.05it/s] 97%|█████████▋| 19644/20300 [1:28:45<01:21,  8.05it/s] 97%|█████████▋| 19656/20300 [1:28:46<01:19,  8.06it/s] 97%|█████████▋| 19668/20300 [1:28:48<01:18,  8.05it/s] 97%|█████████▋| 19680/20300 [1:28:49<01:16,  8.05it/s] 97%|█████████▋| 19692/20300 [1:28:51<01:15,  8.05it/s] 97%|█████████▋| 19704/20300 [1:28:52<01:13,  8.06it/s] 97%|█████████▋| 19716/20300 [1:28:54<01:12,  8.06it/s] 97%|█████████▋| 19728/20300 [1:28:55<01:11,  8.06it/s] 97%|█████████▋| 19740/20300 [1:28:57<01:09,  8.06it/s] 97%|█████████▋| 19752/20300 [1:28:58<01:07,  8.06it/s] 97%|█████████▋| 19764/20300 [1:29:00<01:06,  8.04it/s] 97%|█████████▋| 19776/20300 [1:29:01<01:05,  8.05it/s] 97%|█████████▋| 19788/20300 [1:29:03<01:03,  8.04it/s] 98%|█████████▊| 19800/20300 [1:29:04<01:02,  8.04it/s] 98%|█████████▊| 19812/20300 [1:29:05<01:00,  8.03it/s] 98%|█████████▊| 19824/20300 [1:29:07<00:59,  8.05it/s] 98%|█████████▊| 19836/20300 [1:29:08<00:57,  8.05it/s] 98%|█████████▊| 19848/20300 [1:29:10<00:56,  8.05it/s] 98%|█████████▊| 19860/20300 [1:29:11<00:54,  8.04it/s] 98%|█████████▊| 19872/20300 [1:29:13<00:53,  8.04it/s] 98%|█████████▊| 19884/20300 [1:29:14<00:51,  8.05it/s] 98%|█████████▊| 19896/20300 [1:29:16<00:50,  8.06it/s] 98%|█████████▊| 19908/20300 [1:29:17<00:48,  8.06it/s] 98%|█████████▊| 19920/20300 [1:29:19<00:47,  8.07it/s] 98%|█████████▊| 19932/20300 [1:29:20<00:45,  8.06it/s] 98%|█████████▊| 19944/20300 [1:29:22<00:44,  8.07it/s] 98%|█████████▊| 19956/20300 [1:29:23<00:42,  8.10it/s] 98%|█████████▊| 19968/20300 [1:29:25<00:40,  8.11it/s] 98%|█████████▊| 19980/20300 [1:29:26<00:39,  8.14it/s] 98%|█████████▊| 19992/20300 [1:29:28<00:37,  8.16it/s] 99%|█████████▊| 20004/20300 [1:29:29<00:36,  8.17it/s] 99%|█████████▊| 20016/20300 [1:29:31<00:34,  8.18it/s] 99%|█████████▊| 20028/20300 [1:29:32<00:33,  8.19it/s] 99%|█████████▊| 20040/20300 [1:29:34<00:31,  8.19it/s] 99%|█████████▉| 20052/20300 [1:29:35<00:30,  8.18it/s] 99%|█████████▉| 20064/20300 [1:29:37<00:28,  8.19it/s] 99%|█████████▉| 20076/20300 [1:29:38<00:27,  8.19it/s] 99%|█████████▉| 20088/20300 [1:29:39<00:25,  8.19it/s] 99%|█████████▉| 20100/20300 [1:29:41<00:24,  8.19it/s] 99%|█████████▉| 20112/20300 [1:29:42<00:22,  8.18it/s] 99%|█████████▉| 20124/20300 [1:29:44<00:21,  8.18it/s] 99%|█████████▉| 20136/20300 [1:29:45<00:20,  8.19it/s] 99%|█████████▉| 20148/20300 [1:29:47<00:18,  8.19it/s] 99%|█████████▉| 20160/20300 [1:29:48<00:17,  8.19it/s] 99%|█████████▉| 20172/20300 [1:29:50<00:15,  8.19it/s] 99%|█████████▉| 20184/20300 [1:29:51<00:14,  8.20it/s] 99%|█████████▉| 20196/20300 [1:29:53<00:12,  8.20it/s]100%|█████████▉| 20208/20300 [1:29:54<00:11,  8.21it/s]100%|█████████▉| 20220/20300 [1:29:56<00:09,  8.22it/s]100%|█████████▉| 20232/20300 [1:29:57<00:08,  8.28it/s]100%|█████████▉| 20244/20300 [1:29:58<00:06,  8.33it/s]100%|█████████▉| 20256/20300 [1:30:00<00:05,  8.35it/s]100%|█████████▉| 20268/20300 [1:30:01<00:03,  8.37it/s]100%|█████████▉| 20280/20300 [1:30:03<00:02,  8.38it/s]100%|█████████▉| 20292/20300 [1:30:04<00:00,  8.38it/s]100%|██████████| 20300/20300 [1:30:04<00:00,  3.76it/s]
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
fatal: not a git repository (or any of the parent directories): .git
{'m_mmlu_el': {'alias': 'm_mmlu_el', 'acc,none': 0.4804871100982766, 'acc_stderr,none': 0.004216382623159282}, 'm_mmlu_hu': {'alias': 'm_mmlu_hu', 'acc,none': 0.5073710073710074, 'acc_stderr,none': 0.004380939815539918}, 'm_mmlu_tr': {'alias': 'm_mmlu_tr', 'acc,none': 0.48691022038160037, 'acc_stderr,none': 0.004298497919367168}}
