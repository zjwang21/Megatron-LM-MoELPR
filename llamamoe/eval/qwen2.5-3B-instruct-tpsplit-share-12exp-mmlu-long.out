W1020 02:57:53.960407 139805104157632 torch/distributed/run.py:757] 
W1020 02:57:53.960407 139805104157632 torch/distributed/run.py:757] *****************************************
W1020 02:57:53.960407 139805104157632 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1020 02:57:53.960407 139805104157632 torch/distributed/run.py:757] *****************************************
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
using world size: 8, data-parallel size: 8, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0
WARNING: overriding default arguments for no_load_rng:True                        with no_load_rng:True
WARNING: overriding default arguments for no_load_optim:True                        with no_load_optim:True
WARNING: overriding default arguments for micro_batch_size:1                        with micro_batch_size:4
WARNING: overriding default arguments for exit_on_missing_checkpoint:True                        with exit_on_missing_checkpoint:False
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adaptive_seq_len ................................ True
  add_bias_linear ................................. False
  add_position_embedding .......................... False
  add_qkv_bias .................................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... False
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.0
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ False
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  bsz ............................................. 12
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/root/work/huangxin/nanda/Megatron-LM/llamamoe/data/data-bin/elhutr_qwen2.5_30b_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... True
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 1000000
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  enable_shared_expert ............................ True
  encoder_num_layers .............................. 36
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 2048
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1000
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 4
  ffn_hidden_size ................................. 11008
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 1024
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... True
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.0
  hidden_size ..................................... 2048
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-tpsplit-exp12-TP1PP1EP4
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 5e-05
  lr_decay_iters .................................. 5000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 300
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 32768
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.001
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_ffn_hidden_size ............................. 2752
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_lpr_loss_coeff .............................. 0.001
  moe_lpr_stage ................................... 1
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 4
  moe_token_dispatcher_type ....................... alltoall
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  moelpr_train_embeddings ......................... False
  nccl_communicator_config_path ................... None
  no_load_optim ................................... True
  no_load_rng ..................................... True
  no_persist_layer_norm ........................... False
  no_save_optim ................................... True
  no_save_rng ..................................... True
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... RMSNorm
  num_attention_heads ............................. 16
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... 12
  num_fewshot ..................................... 5
  num_layers ...................................... 36
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 2
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. True
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ True
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... rope
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  results_path .................................... /root/work/huangxin/nanda/Megatron-LM/llamamoe/eval/results/mcore_qwen2.5-3B-instruct-tpsplit-share-12exp-mmlu_long.json
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 1000000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-tpsplit-exp12-TP1PP1EP4
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 99990,8,2
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... True
  swin_backbone_type .............................. tiny
  task_list ....................................... m_mmlu_hu,m_mmlu_el
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. /root/work/huangxin/nanda/models/Qwen/Qwen2.5-3B-Instruct
  tokenizer_type .................................. HuggingFaceTokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 5000
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. True
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... None
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
  zero_expert_down_proj ........................... False
-------------------- end of arguments ---------------------
> building HuggingFaceTokenizer tokenizer ...
 > padded vocab (size: 151936) with 0 dummy tokens (new size: 151936)
> initializing torch distributed ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.024 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.009 seconds
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
building GPT model ...
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
GPTModel(
  (embedding): LanguageModelEmbedding(
    (word_embeddings): VocabParallelEmbedding()
    (embedding_dropout): Dropout(p=0.0, inplace=False)
  )
  (rotary_pos_emb): RotaryEmbedding()
  (decoder): TransformerBlock(
    (layers): ModuleList(
      (0-35): 36 x TransformerLayer(
        (input_layernorm): IdentityOp()
        (self_attention): SelfAttention(
          (core_attention): TEDotProductAttention(
            (flash_attention): FlashAttention()
            (fused_attention): FusedAttention()
            (unfused_attention): UnfusedDotProductAttention(
              (scale_mask_softmax): FusedScaleMaskSoftmax()
              (attention_dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (linear_proj): TERowParallelLinear()
          (linear_qkv): TELayerNormColumnParallelLinear()
          (q_layernorm): IdentityOp()
          (k_layernorm): IdentityOp()
        )
        (pre_cross_attn_layernorm): IdentityOp()
        (cross_attention): IdentityOp()
        (cross_attn_bda): IdentityFuncOp()
        (pre_mlp_layernorm): RMSNorm()
        (mlp): MoELayer(
          (router): TopKRouter()
          (shared_expert_gate): LanguageRouter()
          (shared_expert): MLP(
            (linear_fc1): ColumnParallelLinear()
            (linear_fc2): RowParallelLinear()
          )
          (experts): SequentialMLP(
            (local_experts): ModuleList(
              (0-2): 3 x MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
            )
          )
        )
      )
    )
    (final_layernorm): RMSNorm()
  )
  (output_layer): ColumnParallelLinear()
)
Fine-tuning method: MoE-LPR stage 1
[Rank 4] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 2] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 0] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 1] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 4913065984
[Rank 5] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 3] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 6] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
[Rank 7] trainable params: 0 || all params: 4,913,065,984 || trainable%: 0.0000
 loading checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-tpsplit-exp12-TP1PP1EP4 at iteration 12000
 checkpoint version 3.0
  successfully loaded checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-tpsplit-exp12-TP1PP1EP4 [ t 0, p 0 ] at iteration 12000
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)

[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_mmlu couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_mmlu/hu/0.0.0/18e6c8e65b2010a9819fcd8152718b17f8c551a7 (last modified on Thu Sep 19 05:26:00 2024).
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_el from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of m_mmlu_hu from None to 5
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
  0%|          | 0/13536 [00:00<?, ?it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  0%|          | 12/13536 [00:12<3:55:17,  1.04s/it]  0%|          | 24/13536 [00:18<2:42:42,  1.38it/s]  0%|          | 36/13536 [00:26<2:37:57,  1.42it/s]  0%|          | 48/13536 [00:32<2:20:11,  1.60it/s]  0%|          | 60/13536 [00:40<2:21:49,  1.58it/s]  1%|          | 72/13536 [00:46<2:11:29,  1.71it/s]  1%|          | 84/13536 [00:53<2:12:42,  1.69it/s]  1%|          | 96/13536 [00:59<2:05:09,  1.79it/s]  1%|          | 108/13536 [01:05<2:01:30,  1.84it/s]  1%|          | 120/13536 [01:11<1:59:26,  1.87it/s]  1%|          | 132/13536 [01:17<1:58:08,  1.89it/s]  1%|          | 144/13536 [01:24<2:01:19,  1.84it/s]  1%|          | 156/13536 [01:31<2:00:44,  1.85it/s]  1%|          | 168/13536 [01:38<2:03:51,  1.80it/s]  1%|▏         | 180/13536 [01:44<2:03:10,  1.81it/s]  1%|▏         | 192/13536 [01:52<2:06:26,  1.76it/s]  2%|▏         | 204/13536 [01:58<2:05:24,  1.77it/s]  2%|▏         | 216/13536 [02:06<2:08:27,  1.73it/s]  2%|▏         | 228/13536 [02:13<2:07:34,  1.74it/s]  2%|▏         | 240/13536 [02:20<2:10:33,  1.70it/s]  2%|▏         | 252/13536 [02:27<2:07:50,  1.73it/s]  2%|▏         | 264/13536 [02:34<2:09:25,  1.71it/s]  2%|▏         | 276/13536 [02:40<2:05:40,  1.76it/s]  2%|▏         | 288/13536 [02:47<2:06:38,  1.74it/s]  2%|▏         | 300/13536 [02:53<2:02:08,  1.81it/s]  2%|▏         | 312/13536 [02:59<1:59:06,  1.85it/s]  2%|▏         | 324/13536 [03:05<1:55:48,  1.90it/s]  2%|▏         | 336/13536 [03:12<1:55:49,  1.90it/s]  3%|▎         | 348/13536 [03:18<1:58:17,  1.86it/s]  3%|▎         | 360/13536 [03:25<1:58:55,  1.85it/s]  3%|▎         | 372/13536 [03:32<2:00:53,  1.81it/s]  3%|▎         | 384/13536 [03:39<2:01:17,  1.81it/s]  3%|▎         | 396/13536 [03:46<2:03:18,  1.78it/s]  3%|▎         | 408/13536 [03:52<2:03:37,  1.77it/s]  3%|▎         | 420/13536 [04:00<2:05:19,  1.74it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  3%|▎         | 432/13536 [04:07<2:05:27,  1.74it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  3%|▎         | 444/13536 [04:14<2:09:13,  1.69it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  3%|▎         | 456/13536 [04:21<2:09:21,  1.69it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  3%|▎         | 468/13536 [04:28<2:08:07,  1.70it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  4%|▎         | 480/13536 [04:35<2:04:31,  1.75it/s]  4%|▎         | 492/13536 [04:41<2:02:40,  1.77it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  4%|▎         | 504/13536 [04:47<1:58:04,  1.84it/s]  4%|▍         | 516/13536 [04:53<1:53:32,  1.91it/s]  4%|▍         | 528/13536 [04:59<1:52:51,  1.92it/s]  4%|▍         | 540/13536 [05:05<1:52:39,  1.92it/s]  4%|▍         | 552/13536 [05:12<1:54:16,  1.89it/s]  4%|▍         | 564/13536 [05:18<1:54:16,  1.89it/s]  4%|▍         | 576/13536 [05:25<1:55:30,  1.87it/s]  4%|▍         | 588/13536 [05:31<1:54:51,  1.88it/s]  4%|▍         | 600/13536 [05:38<1:56:02,  1.86it/s]  5%|▍         | 612/13536 [05:44<1:55:51,  1.86it/s]  5%|▍         | 624/13536 [05:51<1:55:55,  1.86it/s]  5%|▍         | 636/13536 [05:57<1:53:18,  1.90it/s]  5%|▍         | 648/13536 [06:03<1:52:14,  1.91it/s]  5%|▍         | 660/13536 [06:08<1:48:28,  1.98it/s]  5%|▍         | 672/13536 [06:14<1:44:56,  2.04it/s]  5%|▌         | 684/13536 [06:19<1:41:58,  2.10it/s]  5%|▌         | 696/13536 [06:25<1:40:40,  2.13it/s]  5%|▌         | 708/13536 [06:30<1:41:40,  2.10it/s]  5%|▌         | 720/13536 [06:36<1:41:50,  2.10it/s]  5%|▌         | 732/13536 [06:42<1:42:55,  2.07it/s]  5%|▌         | 744/13536 [06:48<1:42:49,  2.07it/s]  6%|▌         | 756/13536 [06:54<1:43:58,  2.05it/s]  6%|▌         | 768/13536 [07:00<1:43:51,  2.05it/s]  6%|▌         | 780/13536 [07:06<1:44:53,  2.03it/s]  6%|▌         | 792/13536 [07:11<1:42:52,  2.06it/s]  6%|▌         | 804/13536 [07:17<1:41:44,  2.09it/s]  6%|▌         | 816/13536 [07:22<1:38:57,  2.14it/s]  6%|▌         | 828/13536 [07:27<1:36:20,  2.20it/s]  6%|▌         | 840/13536 [07:32<1:34:05,  2.25it/s]  6%|▋         | 852/13536 [07:38<1:32:45,  2.28it/s]  6%|▋         | 864/13536 [07:43<1:33:06,  2.27it/s]  6%|▋         | 876/13536 [07:48<1:33:07,  2.27it/s]  7%|▋         | 888/13536 [07:54<1:34:09,  2.24it/s]  7%|▋         | 900/13536 [07:59<1:34:21,  2.23it/s]  7%|▋         | 912/13536 [08:05<1:34:46,  2.22it/s]  7%|▋         | 924/13536 [08:10<1:34:47,  2.22it/s]  7%|▋         | 936/13536 [08:16<1:35:30,  2.20it/s]  7%|▋         | 948/13536 [08:21<1:35:25,  2.20it/s]  7%|▋         | 960/13536 [08:27<1:36:00,  2.18it/s]  7%|▋         | 972/13536 [08:32<1:35:57,  2.18it/s]  7%|▋         | 984/13536 [08:38<1:35:26,  2.19it/s]  7%|▋         | 996/13536 [08:43<1:33:53,  2.23it/s]  7%|▋         | 1008/13536 [08:48<1:32:36,  2.25it/s]  8%|▊         | 1020/13536 [08:53<1:30:52,  2.30it/s]  8%|▊         | 1032/13536 [08:58<1:29:11,  2.34it/s]  8%|▊         | 1044/13536 [09:03<1:27:34,  2.38it/s]  8%|▊         | 1056/13536 [09:07<1:26:11,  2.41it/s]  8%|▊         | 1068/13536 [09:12<1:25:00,  2.44it/s]  8%|▊         | 1080/13536 [09:17<1:24:29,  2.46it/s]  8%|▊         | 1092/13536 [09:22<1:24:08,  2.46it/s]  8%|▊         | 1104/13536 [09:27<1:24:04,  2.46it/s]  8%|▊         | 1116/13536 [09:32<1:23:42,  2.47it/s]  8%|▊         | 1128/13536 [09:36<1:23:28,  2.48it/s]  8%|▊         | 1140/13536 [09:41<1:23:31,  2.47it/s]  9%|▊         | 1152/13536 [09:46<1:23:36,  2.47it/s]  9%|▊         | 1164/13536 [09:51<1:23:49,  2.46it/s]  9%|▊         | 1176/13536 [09:56<1:23:45,  2.46it/s]  9%|▉         | 1188/13536 [10:01<1:24:00,  2.45it/s]  9%|▉         | 1200/13536 [10:06<1:24:01,  2.45it/s]  9%|▉         | 1212/13536 [10:11<1:24:32,  2.43it/s]  9%|▉         | 1224/13536 [10:16<1:24:29,  2.43it/s]  9%|▉         | 1236/13536 [10:21<1:25:04,  2.41it/s]  9%|▉         | 1248/13536 [10:26<1:24:51,  2.41it/s]  9%|▉         | 1260/13536 [10:31<1:24:37,  2.42it/s]  9%|▉         | 1272/13536 [10:36<1:23:32,  2.45it/s]  9%|▉         | 1284/13536 [10:40<1:22:40,  2.47it/s] 10%|▉         | 1296/13536 [10:45<1:21:24,  2.51it/s] 10%|▉         | 1308/13536 [10:50<1:20:35,  2.53it/s] 10%|▉         | 1320/13536 [10:54<1:19:23,  2.56it/s] 10%|▉         | 1332/13536 [10:59<1:18:21,  2.60it/s] 10%|▉         | 1344/13536 [11:03<1:17:28,  2.62it/s] 10%|█         | 1356/13536 [11:08<1:16:54,  2.64it/s] 10%|█         | 1368/13536 [11:12<1:16:20,  2.66it/s] 10%|█         | 1380/13536 [11:16<1:15:48,  2.67it/s] 10%|█         | 1392/13536 [11:21<1:15:16,  2.69it/s] 10%|█         | 1404/13536 [11:25<1:14:44,  2.71it/s] 10%|█         | 1416/13536 [11:30<1:14:18,  2.72it/s] 11%|█         | 1428/13536 [11:34<1:13:44,  2.74it/s] 11%|█         | 1440/13536 [11:38<1:13:39,  2.74it/s] 11%|█         | 1452/13536 [11:43<1:13:41,  2.73it/s] 11%|█         | 1464/13536 [11:47<1:13:28,  2.74it/s] 11%|█         | 1476/13536 [11:51<1:13:30,  2.73it/s] 11%|█         | 1488/13536 [11:56<1:13:06,  2.75it/s] 11%|█         | 1500/13536 [12:00<1:12:43,  2.76it/s] 11%|█         | 1512/13536 [12:04<1:12:39,  2.76it/s] 11%|█▏        | 1524/13536 [12:09<1:12:21,  2.77it/s] 11%|█▏        | 1536/13536 [12:13<1:12:26,  2.76it/s] 11%|█▏        | 1548/13536 [12:17<1:12:05,  2.77it/s] 12%|█▏        | 1560/13536 [12:22<1:11:36,  2.79it/s] 12%|█▏        | 1572/13536 [12:26<1:11:43,  2.78it/s] 12%|█▏        | 1584/13536 [12:30<1:11:26,  2.79it/s] 12%|█▏        | 1596/13536 [12:34<1:11:14,  2.79it/s] 12%|█▏        | 1608/13536 [12:39<1:11:10,  2.79it/s] 12%|█▏        | 1620/13536 [12:43<1:11:02,  2.80it/s] 12%|█▏        | 1632/13536 [12:47<1:10:51,  2.80it/s] 12%|█▏        | 1644/13536 [12:52<1:10:53,  2.80it/s] 12%|█▏        | 1656/13536 [12:56<1:10:23,  2.81it/s] 12%|█▏        | 1668/13536 [13:00<1:10:23,  2.81it/s] 12%|█▏        | 1680/13536 [13:04<1:10:13,  2.81it/s] 12%|█▎        | 1692/13536 [13:09<1:10:01,  2.82it/s] 13%|█▎        | 1704/13536 [13:13<1:09:30,  2.84it/s] 13%|█▎        | 1716/13536 [13:17<1:09:12,  2.85it/s] 13%|█▎        | 1728/13536 [13:21<1:08:51,  2.86it/s] 13%|█▎        | 1740/13536 [13:25<1:08:43,  2.86it/s] 13%|█▎        | 1752/13536 [13:29<1:08:21,  2.87it/s] 13%|█▎        | 1764/13536 [13:34<1:08:00,  2.89it/s] 13%|█▎        | 1776/13536 [13:38<1:07:36,  2.90it/s] 13%|█▎        | 1788/13536 [13:42<1:07:16,  2.91it/s] 13%|█▎        | 1800/13536 [13:46<1:07:00,  2.92it/s] 13%|█▎        | 1812/13536 [13:50<1:06:41,  2.93it/s] 13%|█▎        | 1824/13536 [13:54<1:06:29,  2.94it/s] 14%|█▎        | 1836/13536 [13:58<1:06:14,  2.94it/s] 14%|█▎        | 1848/13536 [14:02<1:06:05,  2.95it/s] 14%|█▎        | 1860/13536 [14:06<1:05:58,  2.95it/s] 14%|█▍        | 1872/13536 [14:10<1:05:40,  2.96it/s] 14%|█▍        | 1884/13536 [14:14<1:05:31,  2.96it/s] 14%|█▍        | 1896/13536 [14:18<1:05:23,  2.97it/s] 14%|█▍        | 1908/13536 [14:22<1:05:05,  2.98it/s] 14%|█▍        | 1920/13536 [14:26<1:04:53,  2.98it/s] 14%|█▍        | 1932/13536 [14:30<1:04:37,  2.99it/s] 14%|█▍        | 1944/13536 [14:34<1:04:17,  3.01it/s] 14%|█▍        | 1956/13536 [14:38<1:04:04,  3.01it/s] 15%|█▍        | 1968/13536 [14:42<1:03:52,  3.02it/s] 15%|█▍        | 1980/13536 [14:46<1:03:36,  3.03it/s] 15%|█▍        | 1992/13536 [14:50<1:03:22,  3.04it/s] 15%|█▍        | 2004/13536 [14:54<1:03:08,  3.04it/s] 15%|█▍        | 2016/13536 [14:58<1:02:55,  3.05it/s] 15%|█▍        | 2028/13536 [15:02<1:02:43,  3.06it/s] 15%|█▌        | 2040/13536 [15:06<1:02:33,  3.06it/s] 15%|█▌        | 2052/13536 [15:09<1:02:26,  3.07it/s] 15%|█▌        | 2064/13536 [15:13<1:02:14,  3.07it/s] 15%|█▌        | 2076/13536 [15:17<1:02:03,  3.08it/s] 15%|█▌        | 2088/13536 [15:21<1:01:53,  3.08it/s] 16%|█▌        | 2100/13536 [15:25<1:01:48,  3.08it/s] 16%|█▌        | 2112/13536 [15:29<1:01:42,  3.09it/s] 16%|█▌        | 2124/13536 [15:33<1:01:24,  3.10it/s] 16%|█▌        | 2136/13536 [15:37<1:01:09,  3.11it/s] 16%|█▌        | 2148/13536 [15:40<1:00:57,  3.11it/s] 16%|█▌        | 2160/13536 [15:44<1:00:45,  3.12it/s] 16%|█▌        | 2172/13536 [15:48<1:00:34,  3.13it/s] 16%|█▌        | 2184/13536 [15:52<1:00:16,  3.14it/s] 16%|█▌        | 2196/13536 [15:56<1:00:08,  3.14it/s] 16%|█▋        | 2208/13536 [15:59<59:53,  3.15it/s]   16%|█▋        | 2220/13536 [16:03<59:44,  3.16it/s] 16%|█▋        | 2232/13536 [16:07<59:39,  3.16it/s] 17%|█▋        | 2244/13536 [16:11<59:27,  3.17it/s] 17%|█▋        | 2256/13536 [16:15<59:23,  3.17it/s] 17%|█▋        | 2268/13536 [16:18<59:13,  3.17it/s] 17%|█▋        | 2280/13536 [16:22<59:02,  3.18it/s] 17%|█▋        | 2292/13536 [16:26<59:12,  3.17it/s] 17%|█▋        | 2304/13536 [16:30<59:09,  3.16it/s] 17%|█▋        | 2316/13536 [16:33<59:03,  3.17it/s] 17%|█▋        | 2328/13536 [16:37<58:56,  3.17it/s] 17%|█▋        | 2340/13536 [16:41<58:52,  3.17it/s] 17%|█▋        | 2352/13536 [16:45<58:55,  3.16it/s] 17%|█▋        | 2364/13536 [16:49<58:49,  3.17it/s] 18%|█▊        | 2376/13536 [16:52<58:47,  3.16it/s] 18%|█▊        | 2388/13536 [16:56<58:45,  3.16it/s] 18%|█▊        | 2400/13536 [17:00<58:38,  3.17it/s] 18%|█▊        | 2412/13536 [17:04<58:40,  3.16it/s] 18%|█▊        | 2424/13536 [17:08<58:36,  3.16it/s] 18%|█▊        | 2436/13536 [17:11<58:30,  3.16it/s] 18%|█▊        | 2448/13536 [17:15<58:14,  3.17it/s] 18%|█▊        | 2460/13536 [17:19<57:50,  3.19it/s] 18%|█▊        | 2472/13536 [17:23<57:34,  3.20it/s] 18%|█▊        | 2484/13536 [17:26<57:20,  3.21it/s] 18%|█▊        | 2496/13536 [17:30<57:07,  3.22it/s] 19%|█▊        | 2508/13536 [17:34<56:47,  3.24it/s] 19%|█▊        | 2520/13536 [17:37<56:28,  3.25it/s] 19%|█▊        | 2532/13536 [17:41<56:15,  3.26it/s] 19%|█▉        | 2544/13536 [17:45<56:05,  3.27it/s] 19%|█▉        | 2556/13536 [17:48<55:52,  3.27it/s] 19%|█▉        | 2568/13536 [17:52<55:41,  3.28it/s] 19%|█▉        | 2580/13536 [17:56<55:34,  3.29it/s] 19%|█▉        | 2592/13536 [17:59<55:16,  3.30it/s] 19%|█▉        | 2604/13536 [18:03<55:04,  3.31it/s] 19%|█▉        | 2616/13536 [18:06<54:53,  3.32it/s] 19%|█▉        | 2628/13536 [18:10<54:46,  3.32it/s] 20%|█▉        | 2640/13536 [18:14<54:37,  3.32it/s] 20%|█▉        | 2652/13536 [18:17<54:25,  3.33it/s] 20%|█▉        | 2664/13536 [18:21<54:09,  3.35it/s] 20%|█▉        | 2676/13536 [18:24<54:05,  3.35it/s] 20%|█▉        | 2688/13536 [18:28<54:03,  3.34it/s] 20%|█▉        | 2700/13536 [18:32<54:04,  3.34it/s] 20%|██        | 2712/13536 [18:35<53:59,  3.34it/s] 20%|██        | 2724/13536 [18:39<53:57,  3.34it/s] 20%|██        | 2736/13536 [18:42<53:54,  3.34it/s] 20%|██        | 2748/13536 [18:46<53:54,  3.34it/s] 20%|██        | 2760/13536 [18:49<53:50,  3.34it/s] 20%|██        | 2772/13536 [18:53<53:49,  3.33it/s] 21%|██        | 2784/13536 [18:57<53:49,  3.33it/s] 21%|██        | 2796/13536 [19:00<53:43,  3.33it/s] 21%|██        | 2808/13536 [19:04<53:42,  3.33it/s] 21%|██        | 2820/13536 [19:08<53:41,  3.33it/s] 21%|██        | 2832/13536 [19:11<53:42,  3.32it/s] 21%|██        | 2844/13536 [19:15<53:53,  3.31it/s] 21%|██        | 2856/13536 [19:19<54:03,  3.29it/s] 21%|██        | 2868/13536 [19:22<54:15,  3.28it/s] 21%|██▏       | 2880/13536 [19:26<54:14,  3.27it/s] 21%|██▏       | 2892/13536 [19:30<54:10,  3.27it/s] 21%|██▏       | 2904/13536 [19:33<54:03,  3.28it/s] 22%|██▏       | 2916/13536 [19:37<54:00,  3.28it/s] 22%|██▏       | 2928/13536 [19:41<53:57,  3.28it/s] 22%|██▏       | 2940/13536 [19:44<53:50,  3.28it/s] 22%|██▏       | 2952/13536 [19:48<53:46,  3.28it/s] 22%|██▏       | 2964/13536 [19:51<53:38,  3.28it/s] 22%|██▏       | 2976/13536 [19:55<53:26,  3.29it/s] 22%|██▏       | 2988/13536 [19:59<53:20,  3.30it/s] 22%|██▏       | 3000/13536 [20:02<53:09,  3.30it/s] 22%|██▏       | 3012/13536 [20:06<53:03,  3.31it/s] 22%|██▏       | 3024/13536 [20:10<52:57,  3.31it/s] 22%|██▏       | 3036/13536 [20:13<52:53,  3.31it/s] 23%|██▎       | 3048/13536 [20:17<52:50,  3.31it/s] 23%|██▎       | 3060/13536 [20:20<52:48,  3.31it/s] 23%|██▎       | 3072/13536 [20:24<52:40,  3.31it/s] 23%|██▎       | 3084/13536 [20:28<52:38,  3.31it/s] 23%|██▎       | 3096/13536 [20:31<52:31,  3.31it/s] 23%|██▎       | 3108/13536 [20:35<52:22,  3.32it/s] 23%|██▎       | 3120/13536 [20:39<52:17,  3.32it/s] 23%|██▎       | 3132/13536 [20:42<52:09,  3.32it/s] 23%|██▎       | 3144/13536 [20:46<52:03,  3.33it/s] 23%|██▎       | 3156/13536 [20:49<51:56,  3.33it/s] 23%|██▎       | 3168/13536 [20:53<51:50,  3.33it/s] 23%|██▎       | 3180/13536 [20:57<51:45,  3.33it/s] 24%|██▎       | 3192/13536 [21:00<51:35,  3.34it/s] 24%|██▎       | 3204/13536 [21:04<51:38,  3.33it/s] 24%|██▍       | 3216/13536 [21:07<51:26,  3.34it/s] 24%|██▍       | 3228/13536 [21:11<51:17,  3.35it/s] 24%|██▍       | 3240/13536 [21:14<51:10,  3.35it/s] 24%|██▍       | 3252/13536 [21:18<51:10,  3.35it/s] 24%|██▍       | 3264/13536 [21:22<51:02,  3.35it/s] 24%|██▍       | 3276/13536 [21:25<50:55,  3.36it/s] 24%|██▍       | 3288/13536 [21:29<50:50,  3.36it/s] 24%|██▍       | 3300/13536 [21:32<50:50,  3.35it/s] 24%|██▍       | 3312/13536 [21:36<50:40,  3.36it/s] 25%|██▍       | 3324/13536 [21:39<50:27,  3.37it/s] 25%|██▍       | 3336/13536 [21:43<50:20,  3.38it/s] 25%|██▍       | 3348/13536 [21:46<50:12,  3.38it/s] 25%|██▍       | 3360/13536 [21:50<50:02,  3.39it/s] 25%|██▍       | 3372/13536 [21:54<49:54,  3.39it/s] 25%|██▌       | 3384/13536 [21:57<49:55,  3.39it/s] 25%|██▌       | 3396/13536 [22:01<49:52,  3.39it/s] 25%|██▌       | 3408/13536 [22:04<49:45,  3.39it/s] 25%|██▌       | 3420/13536 [22:08<49:40,  3.39it/s] 25%|██▌       | 3432/13536 [22:11<49:36,  3.39it/s] 25%|██▌       | 3444/13536 [22:15<49:30,  3.40it/s] 26%|██▌       | 3456/13536 [22:18<49:25,  3.40it/s] 26%|██▌       | 3468/13536 [22:22<49:17,  3.40it/s] 26%|██▌       | 3480/13536 [22:25<49:17,  3.40it/s] 26%|██▌       | 3492/13536 [22:29<49:13,  3.40it/s] 26%|██▌       | 3504/13536 [22:32<49:07,  3.40it/s] 26%|██▌       | 3516/13536 [22:36<49:00,  3.41it/s] 26%|██▌       | 3528/13536 [22:39<48:55,  3.41it/s] 26%|██▌       | 3540/13536 [22:43<48:51,  3.41it/s] 26%|██▌       | 3552/13536 [22:46<48:51,  3.41it/s] 26%|██▋       | 3564/13536 [22:50<48:43,  3.41it/s] 26%|██▋       | 3576/13536 [22:53<48:40,  3.41it/s] 27%|██▋       | 3588/13536 [22:57<48:39,  3.41it/s] 27%|██▋       | 3600/13536 [23:00<48:30,  3.41it/s] 27%|██▋       | 3612/13536 [23:04<48:28,  3.41it/s] 27%|██▋       | 3624/13536 [23:08<48:23,  3.41it/s] 27%|██▋       | 3636/13536 [23:11<48:19,  3.41it/s] 27%|██▋       | 3648/13536 [23:15<48:14,  3.42it/s] 27%|██▋       | 3660/13536 [23:18<48:07,  3.42it/s] 27%|██▋       | 3672/13536 [23:22<48:00,  3.42it/s] 27%|██▋       | 3684/13536 [23:25<47:55,  3.43it/s] 27%|██▋       | 3696/13536 [23:29<47:57,  3.42it/s] 27%|██▋       | 3708/13536 [23:32<47:54,  3.42it/s] 27%|██▋       | 3720/13536 [23:36<47:48,  3.42it/s] 28%|██▊       | 3732/13536 [23:39<47:44,  3.42it/s] 28%|██▊       | 3744/13536 [23:43<47:36,  3.43it/s] 28%|██▊       | 3756/13536 [23:46<47:38,  3.42it/s] 28%|██▊       | 3768/13536 [23:50<47:30,  3.43it/s] 28%|██▊       | 3780/13536 [23:53<47:28,  3.43it/s] 28%|██▊       | 3792/13536 [23:57<47:24,  3.43it/s] 28%|██▊       | 3804/13536 [24:00<47:17,  3.43it/s] 28%|██▊       | 3816/13536 [24:04<47:15,  3.43it/s] 28%|██▊       | 3828/13536 [24:07<47:10,  3.43it/s] 28%|██▊       | 3840/13536 [24:11<47:03,  3.43it/s] 28%|██▊       | 3852/13536 [24:14<47:02,  3.43it/s] 29%|██▊       | 3864/13536 [24:18<46:58,  3.43it/s] 29%|██▊       | 3876/13536 [24:21<46:55,  3.43it/s] 29%|██▊       | 3888/13536 [24:25<46:51,  3.43it/s] 29%|██▉       | 3900/13536 [24:28<46:46,  3.43it/s] 29%|██▉       | 3912/13536 [24:31<46:31,  3.45it/s] 29%|██▉       | 3924/13536 [24:35<46:22,  3.45it/s] 29%|██▉       | 3936/13536 [24:38<46:15,  3.46it/s] 29%|██▉       | 3948/13536 [24:42<46:10,  3.46it/s] 29%|██▉       | 3960/13536 [24:45<46:06,  3.46it/s] 29%|██▉       | 3972/13536 [24:49<46:00,  3.46it/s] 29%|██▉       | 3984/13536 [24:52<45:56,  3.47it/s] 30%|██▉       | 3996/13536 [24:56<45:53,  3.46it/s] 30%|██▉       | 4008/13536 [24:59<45:48,  3.47it/s] 30%|██▉       | 4020/13536 [25:03<45:48,  3.46it/s] 30%|██▉       | 4032/13536 [25:06<45:43,  3.46it/s] 30%|██▉       | 4044/13536 [25:10<45:40,  3.46it/s] 30%|██▉       | 4056/13536 [25:13<45:34,  3.47it/s] 30%|███       | 4068/13536 [25:16<45:32,  3.47it/s] 30%|███       | 4080/13536 [25:20<45:28,  3.47it/s] 30%|███       | 4092/13536 [25:23<45:22,  3.47it/s] 30%|███       | 4104/13536 [25:27<45:18,  3.47it/s] 30%|███       | 4116/13536 [25:30<45:13,  3.47it/s] 30%|███       | 4128/13536 [25:34<45:07,  3.47it/s] 31%|███       | 4140/13536 [25:37<45:07,  3.47it/s] 31%|███       | 4152/13536 [25:41<45:03,  3.47it/s] 31%|███       | 4164/13536 [25:44<45:01,  3.47it/s] 31%|███       | 4176/13536 [25:48<44:54,  3.47it/s] 31%|███       | 4188/13536 [25:51<44:49,  3.48it/s] 31%|███       | 4200/13536 [25:54<44:42,  3.48it/s] 31%|███       | 4212/13536 [25:58<44:37,  3.48it/s] 31%|███       | 4224/13536 [26:01<44:31,  3.49it/s] 31%|███▏      | 4236/13536 [26:05<44:27,  3.49it/s] 31%|███▏      | 4248/13536 [26:08<44:21,  3.49it/s] 31%|███▏      | 4260/13536 [26:12<44:22,  3.48it/s] 32%|███▏      | 4272/13536 [26:15<44:19,  3.48it/s] 32%|███▏      | 4284/13536 [26:19<44:14,  3.49it/s] 32%|███▏      | 4296/13536 [26:22<44:07,  3.49it/s] 32%|███▏      | 4308/13536 [26:25<44:05,  3.49it/s] 32%|███▏      | 4320/13536 [26:29<44:06,  3.48it/s] 32%|███▏      | 4332/13536 [26:32<43:59,  3.49it/s] 32%|███▏      | 4344/13536 [26:36<43:54,  3.49it/s] 32%|███▏      | 4356/13536 [26:39<43:48,  3.49it/s] 32%|███▏      | 4368/13536 [26:43<43:46,  3.49it/s] 32%|███▏      | 4380/13536 [26:46<43:42,  3.49it/s] 32%|███▏      | 4392/13536 [26:49<43:38,  3.49it/s] 33%|███▎      | 4404/13536 [26:53<43:34,  3.49it/s] 33%|███▎      | 4416/13536 [26:56<43:32,  3.49it/s] 33%|███▎      | 4428/13536 [27:00<43:25,  3.50it/s] 33%|███▎      | 4440/13536 [27:03<43:21,  3.50it/s] 33%|███▎      | 4452/13536 [27:07<43:16,  3.50it/s] 33%|███▎      | 4464/13536 [27:10<43:08,  3.50it/s] 33%|███▎      | 4476/13536 [27:13<42:59,  3.51it/s] 33%|███▎      | 4488/13536 [27:17<42:47,  3.52it/s] 33%|███▎      | 4500/13536 [27:20<42:42,  3.53it/s] 33%|███▎      | 4512/13536 [27:24<42:40,  3.52it/s] 33%|███▎      | 4524/13536 [27:27<42:36,  3.52it/s] 34%|███▎      | 4536/13536 [27:30<42:35,  3.52it/s] 34%|███▎      | 4548/13536 [27:34<42:30,  3.52it/s] 34%|███▎      | 4560/13536 [27:37<42:29,  3.52it/s] 34%|███▍      | 4572/13536 [27:41<42:23,  3.52it/s] 34%|███▍      | 4584/13536 [27:44<42:22,  3.52it/s] 34%|███▍      | 4596/13536 [27:47<42:16,  3.52it/s] 34%|███▍      | 4608/13536 [27:51<42:09,  3.53it/s] 34%|███▍      | 4620/13536 [27:54<41:52,  3.55it/s] 34%|███▍      | 4632/13536 [27:58<41:48,  3.55it/s] 34%|███▍      | 4644/13536 [28:01<41:41,  3.55it/s] 34%|███▍      | 4656/13536 [28:04<41:30,  3.57it/s] 34%|███▍      | 4668/13536 [28:08<41:28,  3.56it/s] 35%|███▍      | 4680/13536 [28:11<41:18,  3.57it/s] 35%|███▍      | 4692/13536 [28:14<41:20,  3.57it/s] 35%|███▍      | 4704/13536 [28:18<41:10,  3.57it/s] 35%|███▍      | 4716/13536 [28:21<41:12,  3.57it/s] 35%|███▍      | 4728/13536 [28:24<41:02,  3.58it/s] 35%|███▌      | 4740/13536 [28:28<41:06,  3.57it/s] 35%|███▌      | 4752/13536 [28:31<40:56,  3.58it/s] 35%|███▌      | 4764/13536 [28:35<40:55,  3.57it/s] 35%|███▌      | 4776/13536 [28:38<40:45,  3.58it/s] 35%|███▌      | 4788/13536 [28:41<40:50,  3.57it/s] 35%|███▌      | 4800/13536 [28:45<40:40,  3.58it/s] 36%|███▌      | 4812/13536 [28:48<40:38,  3.58it/s] 36%|███▌      | 4824/13536 [28:51<40:29,  3.59it/s] 36%|███▌      | 4836/13536 [28:55<40:23,  3.59it/s] 36%|███▌      | 4848/13536 [28:58<40:20,  3.59it/s] 36%|███▌      | 4860/13536 [29:01<40:18,  3.59it/s] 36%|███▌      | 4872/13536 [29:05<40:13,  3.59it/s] 36%|███▌      | 4884/13536 [29:08<40:10,  3.59it/s] 36%|███▌      | 4896/13536 [29:11<40:03,  3.60it/s] 36%|███▋      | 4908/13536 [29:15<39:56,  3.60it/s] 36%|███▋      | 4920/13536 [29:18<39:55,  3.60it/s] 36%|███▋      | 4932/13536 [29:21<39:51,  3.60it/s] 37%|███▋      | 4944/13536 [29:25<39:48,  3.60it/s] 37%|███▋      | 4956/13536 [29:28<39:44,  3.60it/s] 37%|███▋      | 4968/13536 [29:31<39:43,  3.59it/s] 37%|███▋      | 4980/13536 [29:35<39:39,  3.60it/s] 37%|███▋      | 4992/13536 [29:38<39:30,  3.60it/s] 37%|███▋      | 5004/13536 [29:41<39:27,  3.60it/s] 37%|███▋      | 5016/13536 [29:45<39:19,  3.61it/s] 37%|███▋      | 5028/13536 [29:48<39:15,  3.61it/s] 37%|███▋      | 5040/13536 [29:51<39:11,  3.61it/s] 37%|███▋      | 5052/13536 [29:55<39:09,  3.61it/s] 37%|███▋      | 5064/13536 [29:58<39:04,  3.61it/s] 38%|███▊      | 5076/13536 [30:01<39:00,  3.62it/s] 38%|███▊      | 5088/13536 [30:04<38:51,  3.62it/s] 38%|███▊      | 5100/13536 [30:08<38:50,  3.62it/s] 38%|███▊      | 5112/13536 [30:11<38:45,  3.62it/s] 38%|███▊      | 5124/13536 [30:14<38:41,  3.62it/s] 38%|███▊      | 5136/13536 [30:18<38:39,  3.62it/s] 38%|███▊      | 5148/13536 [30:21<38:34,  3.62it/s] 38%|███▊      | 5160/13536 [30:24<38:32,  3.62it/s] 38%|███▊      | 5172/13536 [30:28<38:31,  3.62it/s] 38%|███▊      | 5184/13536 [30:31<38:28,  3.62it/s] 38%|███▊      | 5196/13536 [30:34<38:22,  3.62it/s] 38%|███▊      | 5208/13536 [30:38<38:20,  3.62it/s] 39%|███▊      | 5220/13536 [30:41<38:13,  3.63it/s] 39%|███▊      | 5232/13536 [30:44<38:09,  3.63it/s] 39%|███▊      | 5244/13536 [30:48<38:05,  3.63it/s] 39%|███▉      | 5256/13536 [30:51<37:59,  3.63it/s] 39%|███▉      | 5268/13536 [30:54<37:54,  3.63it/s] 39%|███▉      | 5280/13536 [30:57<37:53,  3.63it/s] 39%|███▉      | 5292/13536 [31:01<37:50,  3.63it/s] 39%|███▉      | 5304/13536 [31:04<37:45,  3.63it/s] 39%|███▉      | 5316/13536 [31:07<37:40,  3.64it/s] 39%|███▉      | 5328/13536 [31:11<37:39,  3.63it/s] 39%|███▉      | 5340/13536 [31:14<37:30,  3.64it/s] 40%|███▉      | 5352/13536 [31:17<37:32,  3.63it/s] 40%|███▉      | 5364/13536 [31:21<37:22,  3.64it/s] 40%|███▉      | 5376/13536 [31:24<37:15,  3.65it/s] 40%|███▉      | 5388/13536 [31:27<37:19,  3.64it/s] 40%|███▉      | 5400/13536 [31:30<37:11,  3.65it/s] 40%|███▉      | 5412/13536 [31:34<37:09,  3.64it/s] 40%|████      | 5424/13536 [31:37<37:04,  3.65it/s] 40%|████      | 5436/13536 [31:40<37:04,  3.64it/s] 40%|████      | 5448/13536 [31:44<36:57,  3.65it/s] 40%|████      | 5460/13536 [31:47<36:59,  3.64it/s] 40%|████      | 5472/13536 [31:50<36:47,  3.65it/s] 41%|████      | 5484/13536 [31:53<36:50,  3.64it/s] 41%|████      | 5496/13536 [31:57<36:45,  3.65it/s] 41%|████      | 5508/13536 [32:00<36:41,  3.65it/s] 41%|████      | 5520/13536 [32:03<36:33,  3.65it/s] 41%|████      | 5532/13536 [32:07<36:30,  3.65it/s] 41%|████      | 5544/13536 [32:10<36:20,  3.67it/s] 41%|████      | 5556/13536 [32:13<36:17,  3.66it/s] 41%|████      | 5568/13536 [32:16<36:15,  3.66it/s] 41%|████      | 5580/13536 [32:20<36:12,  3.66it/s] 41%|████▏     | 5592/13536 [32:23<36:04,  3.67it/s] 41%|████▏     | 5604/13536 [32:26<36:01,  3.67it/s] 41%|████▏     | 5616/13536 [32:29<35:56,  3.67it/s] 42%|████▏     | 5628/13536 [32:33<35:55,  3.67it/s] 42%|████▏     | 5640/13536 [32:36<35:52,  3.67it/s] 42%|████▏     | 5652/13536 [32:39<35:34,  3.69it/s] 42%|████▏     | 5664/13536 [32:42<35:19,  3.71it/s] 42%|████▏     | 5676/13536 [32:46<35:12,  3.72it/s] 42%|████▏     | 5688/13536 [32:49<35:03,  3.73it/s] 42%|████▏     | 5700/13536 [32:52<34:58,  3.73it/s] 42%|████▏     | 5712/13536 [32:55<34:49,  3.74it/s] 42%|████▏     | 5724/13536 [32:58<34:43,  3.75it/s] 42%|████▏     | 5736/13536 [33:02<34:44,  3.74it/s] 42%|████▏     | 5748/13536 [33:05<34:39,  3.75it/s] 43%|████▎     | 5760/13536 [33:08<34:40,  3.74it/s] 43%|████▎     | 5772/13536 [33:11<34:35,  3.74it/s] 43%|████▎     | 5784/13536 [33:14<34:35,  3.73it/s] 43%|████▎     | 5796/13536 [33:18<34:31,  3.74it/s] 43%|████▎     | 5808/13536 [33:21<34:29,  3.73it/s] 43%|████▎     | 5820/13536 [33:24<34:25,  3.74it/s] 43%|████▎     | 5832/13536 [33:27<34:25,  3.73it/s] 43%|████▎     | 5844/13536 [33:31<34:20,  3.73it/s] 43%|████▎     | 5856/13536 [33:34<34:15,  3.74it/s] 43%|████▎     | 5868/13536 [33:37<34:10,  3.74it/s] 43%|████▎     | 5880/13536 [33:40<34:07,  3.74it/s] 44%|████▎     | 5892/13536 [33:43<34:01,  3.74it/s] 44%|████▎     | 5904/13536 [33:47<34:00,  3.74it/s] 44%|████▎     | 5916/13536 [33:50<33:55,  3.74it/s] 44%|████▍     | 5928/13536 [33:53<33:49,  3.75it/s] 44%|████▍     | 5940/13536 [33:56<33:48,  3.75it/s] 44%|████▍     | 5952/13536 [33:59<33:42,  3.75it/s] 44%|████▍     | 5964/13536 [34:03<33:39,  3.75it/s] 44%|████▍     | 5976/13536 [34:06<33:33,  3.75it/s] 44%|████▍     | 5988/13536 [34:09<33:32,  3.75it/s] 44%|████▍     | 6000/13536 [34:12<33:27,  3.75it/s] 44%|████▍     | 6012/13536 [34:15<33:26,  3.75it/s] 45%|████▍     | 6024/13536 [34:19<33:21,  3.75it/s] 45%|████▍     | 6036/13536 [34:22<33:24,  3.74it/s] 45%|████▍     | 6048/13536 [34:25<33:13,  3.76it/s] 45%|████▍     | 6060/13536 [34:28<33:10,  3.76it/s] 45%|████▍     | 6072/13536 [34:31<33:04,  3.76it/s] 45%|████▍     | 6084/13536 [34:34<33:01,  3.76it/s] 45%|████▌     | 6096/13536 [34:38<32:57,  3.76it/s] 45%|████▌     | 6108/13536 [34:41<32:53,  3.76it/s] 45%|████▌     | 6120/13536 [34:44<32:49,  3.77it/s] 45%|████▌     | 6132/13536 [34:47<32:46,  3.77it/s] 45%|████▌     | 6144/13536 [34:50<32:39,  3.77it/s] 45%|████▌     | 6156/13536 [34:54<32:34,  3.78it/s] 46%|████▌     | 6168/13536 [34:57<32:31,  3.78it/s] 46%|████▌     | 6180/13536 [35:00<32:31,  3.77it/s] 46%|████▌     | 6192/13536 [35:03<32:27,  3.77it/s] 46%|████▌     | 6204/13536 [35:06<32:22,  3.77it/s] 46%|████▌     | 6216/13536 [35:09<32:18,  3.78it/s] 46%|████▌     | 6228/13536 [35:13<32:17,  3.77it/s] 46%|████▌     | 6240/13536 [35:16<32:15,  3.77it/s] 46%|████▌     | 6252/13536 [35:19<32:09,  3.77it/s] 46%|████▋     | 6264/13536 [35:22<32:07,  3.77it/s] 46%|████▋     | 6276/13536 [35:25<32:05,  3.77it/s] 46%|████▋     | 6288/13536 [35:29<32:04,  3.77it/s] 47%|████▋     | 6300/13536 [35:32<32:02,  3.76it/s] 47%|████▋     | 6312/13536 [35:35<32:02,  3.76it/s] 47%|████▋     | 6324/13536 [35:38<31:58,  3.76it/s] 47%|████▋     | 6336/13536 [35:41<31:57,  3.75it/s] 47%|████▋     | 6348/13536 [35:45<31:56,  3.75it/s] 47%|████▋     | 6360/13536 [35:48<31:56,  3.74it/s] 47%|████▋     | 6372/13536 [35:51<31:52,  3.75it/s] 47%|████▋     | 6384/13536 [35:54<31:49,  3.74it/s] 47%|████▋     | 6396/13536 [35:57<31:46,  3.74it/s] 47%|████▋     | 6408/13536 [36:01<31:45,  3.74it/s] 47%|████▋     | 6420/13536 [36:04<31:41,  3.74it/s] 48%|████▊     | 6432/13536 [36:07<31:39,  3.74it/s] 48%|████▊     | 6444/13536 [36:10<31:38,  3.73it/s] 48%|████▊     | 6456/13536 [36:13<31:34,  3.74it/s] 48%|████▊     | 6468/13536 [36:17<31:33,  3.73it/s] 48%|████▊     | 6480/13536 [36:20<31:29,  3.73it/s] 48%|████▊     | 6492/13536 [36:23<31:29,  3.73it/s] 48%|████▊     | 6504/13536 [36:26<31:25,  3.73it/s] 48%|████▊     | 6516/13536 [36:30<31:24,  3.73it/s] 48%|████▊     | 6528/13536 [36:33<31:20,  3.73it/s] 48%|████▊     | 6540/13536 [36:36<31:19,  3.72it/s] 48%|████▊     | 6552/13536 [36:39<31:15,  3.72it/s] 48%|████▊     | 6564/13536 [36:42<31:13,  3.72it/s] 49%|████▊     | 6576/13536 [36:46<31:10,  3.72it/s] 49%|████▊     | 6588/13536 [36:49<31:09,  3.72it/s] 49%|████▉     | 6600/13536 [36:52<31:03,  3.72it/s] 49%|████▉     | 6612/13536 [36:55<31:02,  3.72it/s] 49%|████▉     | 6624/13536 [36:59<30:59,  3.72it/s] 49%|████▉     | 6636/13536 [37:02<30:57,  3.71it/s] 49%|████▉     | 6648/13536 [37:05<30:56,  3.71it/s] 49%|████▉     | 6660/13536 [37:08<30:53,  3.71it/s] 49%|████▉     | 6672/13536 [37:12<30:49,  3.71it/s] 49%|████▉     | 6684/13536 [37:15<30:49,  3.71it/s] 49%|████▉     | 6696/13536 [37:18<30:43,  3.71it/s] 50%|████▉     | 6708/13536 [37:21<30:37,  3.72it/s] 50%|████▉     | 6720/13536 [37:24<30:34,  3.72it/s] 50%|████▉     | 6732/13536 [37:28<30:30,  3.72it/s] 50%|████▉     | 6744/13536 [37:31<30:27,  3.72it/s] 50%|████▉     | 6756/13536 [37:34<30:18,  3.73it/s] 50%|█████     | 6768/13536 [37:37<30:11,  3.74it/s] 50%|█████     | 6780/13536 [37:41<30:10,  3.73it/s] 50%|█████     | 6792/13536 [37:44<30:05,  3.74it/s] 50%|█████     | 6804/13536 [37:47<30:04,  3.73it/s] 50%|█████     | 6816/13536 [37:50<29:59,  3.74it/s] 50%|█████     | 6828/13536 [37:53<29:58,  3.73it/s] 51%|█████     | 6840/13536 [37:57<29:56,  3.73it/s] 51%|█████     | 6852/13536 [38:00<29:51,  3.73it/s] 51%|█████     | 6864/13536 [38:03<29:48,  3.73it/s] 51%|█████     | 6876/13536 [38:06<29:44,  3.73it/s] 51%|█████     | 6888/13536 [38:09<29:39,  3.74it/s] 51%|█████     | 6900/13536 [38:13<29:35,  3.74it/s] 51%|█████     | 6912/13536 [38:16<29:30,  3.74it/s] 51%|█████     | 6924/13536 [38:19<29:29,  3.74it/s] 51%|█████     | 6936/13536 [38:22<29:24,  3.74it/s] 51%|█████▏    | 6948/13536 [38:26<29:20,  3.74it/s] 51%|█████▏    | 6960/13536 [38:29<29:16,  3.74it/s] 52%|█████▏    | 6972/13536 [38:32<29:12,  3.75it/s] 52%|█████▏    | 6984/13536 [38:35<29:08,  3.75it/s] 52%|█████▏    | 6996/13536 [38:38<29:04,  3.75it/s] 52%|█████▏    | 7008/13536 [38:42<29:00,  3.75it/s] 52%|█████▏    | 7020/13536 [38:45<28:58,  3.75it/s] 52%|█████▏    | 7032/13536 [38:48<28:55,  3.75it/s] 52%|█████▏    | 7044/13536 [38:51<28:51,  3.75it/s] 52%|█████▏    | 7056/13536 [38:54<28:48,  3.75it/s] 52%|█████▏    | 7068/13536 [38:58<28:46,  3.75it/s] 52%|█████▏    | 7080/13536 [39:01<28:39,  3.76it/s] 52%|█████▏    | 7092/13536 [39:04<28:34,  3.76it/s] 52%|█████▏    | 7104/13536 [39:07<28:29,  3.76it/s] 53%|█████▎    | 7116/13536 [39:10<28:27,  3.76it/s] 53%|█████▎    | 7128/13536 [39:13<28:24,  3.76it/s] 53%|█████▎    | 7140/13536 [39:17<28:20,  3.76it/s] 53%|█████▎    | 7152/13536 [39:20<28:15,  3.76it/s] 53%|█████▎    | 7164/13536 [39:23<28:12,  3.76it/s] 53%|█████▎    | 7176/13536 [39:26<28:10,  3.76it/s] 53%|█████▎    | 7188/13536 [39:29<28:06,  3.76it/s] 53%|█████▎    | 7200/13536 [39:33<28:05,  3.76it/s] 53%|█████▎    | 7212/13536 [39:36<28:04,  3.75it/s] 53%|█████▎    | 7224/13536 [39:39<28:03,  3.75it/s] 53%|█████▎    | 7236/13536 [39:42<27:56,  3.76it/s] 54%|█████▎    | 7248/13536 [39:45<27:53,  3.76it/s] 54%|█████▎    | 7260/13536 [39:49<27:51,  3.76it/s] 54%|█████▎    | 7272/13536 [39:52<27:48,  3.75it/s] 54%|█████▍    | 7284/13536 [39:55<27:45,  3.75it/s] 54%|█████▍    | 7296/13536 [39:58<27:44,  3.75it/s] 54%|█████▍    | 7308/13536 [40:01<27:40,  3.75it/s] 54%|█████▍    | 7320/13536 [40:05<27:38,  3.75it/s] 54%|█████▍    | 7332/13536 [40:08<27:33,  3.75it/s] 54%|█████▍    | 7344/13536 [40:11<27:29,  3.75it/s] 54%|█████▍    | 7356/13536 [40:14<27:24,  3.76it/s] 54%|█████▍    | 7368/13536 [40:17<27:22,  3.76it/s] 55%|█████▍    | 7380/13536 [40:21<27:17,  3.76it/s] 55%|█████▍    | 7392/13536 [40:24<27:17,  3.75it/s] 55%|█████▍    | 7404/13536 [40:27<27:14,  3.75it/s] 55%|█████▍    | 7416/13536 [40:30<27:12,  3.75it/s] 55%|█████▍    | 7428/13536 [40:33<27:06,  3.76it/s] 55%|█████▍    | 7440/13536 [40:37<27:00,  3.76it/s] 55%|█████▌    | 7452/13536 [40:40<26:56,  3.76it/s] 55%|█████▌    | 7464/13536 [40:43<26:53,  3.76it/s] 55%|█████▌    | 7476/13536 [40:46<26:50,  3.76it/s] 55%|█████▌    | 7488/13536 [40:49<26:49,  3.76it/s] 55%|█████▌    | 7500/13536 [40:52<26:43,  3.76it/s] 55%|█████▌    | 7512/13536 [40:56<26:39,  3.77it/s] 56%|█████▌    | 7524/13536 [40:59<26:35,  3.77it/s] 56%|█████▌    | 7536/13536 [41:02<26:35,  3.76it/s] 56%|█████▌    | 7548/13536 [41:05<26:30,  3.76it/s] 56%|█████▌    | 7560/13536 [41:08<26:28,  3.76it/s] 56%|█████▌    | 7572/13536 [41:12<26:23,  3.77it/s] 56%|█████▌    | 7584/13536 [41:15<26:19,  3.77it/s] 56%|█████▌    | 7596/13536 [41:18<26:16,  3.77it/s] 56%|█████▌    | 7608/13536 [41:21<26:12,  3.77it/s] 56%|█████▋    | 7620/13536 [41:24<26:11,  3.76it/s] 56%|█████▋    | 7632/13536 [41:28<26:09,  3.76it/s] 56%|█████▋    | 7644/13536 [41:31<26:03,  3.77it/s] 57%|█████▋    | 7656/13536 [41:34<25:59,  3.77it/s] 57%|█████▋    | 7668/13536 [41:37<25:54,  3.77it/s] 57%|█████▋    | 7680/13536 [41:40<25:52,  3.77it/s] 57%|█████▋    | 7692/13536 [41:43<25:49,  3.77it/s] 57%|█████▋    | 7704/13536 [41:47<25:47,  3.77it/s] 57%|█████▋    | 7716/13536 [41:50<25:41,  3.78it/s] 57%|█████▋    | 7728/13536 [41:53<25:38,  3.77it/s] 57%|█████▋    | 7740/13536 [41:56<25:35,  3.78it/s] 57%|█████▋    | 7752/13536 [41:59<25:32,  3.77it/s] 57%|█████▋    | 7764/13536 [42:02<25:26,  3.78it/s] 57%|█████▋    | 7776/13536 [42:06<25:25,  3.78it/s] 58%|█████▊    | 7788/13536 [42:09<25:22,  3.78it/s] 58%|█████▊    | 7800/13536 [42:12<25:20,  3.77it/s] 58%|█████▊    | 7812/13536 [42:15<25:18,  3.77it/s] 58%|█████▊    | 7824/13536 [42:18<25:14,  3.77it/s] 58%|█████▊    | 7836/13536 [42:22<25:04,  3.79it/s] 58%|█████▊    | 7848/13536 [42:25<24:57,  3.80it/s] 58%|█████▊    | 7860/13536 [42:28<24:51,  3.81it/s] 58%|█████▊    | 7872/13536 [42:31<24:44,  3.82it/s] 58%|█████▊    | 7884/13536 [42:34<24:38,  3.82it/s] 58%|█████▊    | 7896/13536 [42:37<24:34,  3.82it/s] 58%|█████▊    | 7908/13536 [42:40<24:29,  3.83it/s] 59%|█████▊    | 7920/13536 [42:43<24:26,  3.83it/s] 59%|█████▊    | 7932/13536 [42:47<24:21,  3.83it/s] 59%|█████▊    | 7944/13536 [42:50<24:18,  3.83it/s] 59%|█████▉    | 7956/13536 [42:53<24:12,  3.84it/s] 59%|█████▉    | 7968/13536 [42:56<24:09,  3.84it/s] 59%|█████▉    | 7980/13536 [42:59<24:05,  3.84it/s] 59%|█████▉    | 7992/13536 [43:02<24:00,  3.85it/s] 59%|█████▉    | 8004/13536 [43:05<23:56,  3.85it/s] 59%|█████▉    | 8016/13536 [43:08<23:54,  3.85it/s] 59%|█████▉    | 8028/13536 [43:12<23:49,  3.85it/s] 59%|█████▉    | 8040/13536 [43:15<23:45,  3.86it/s] 59%|█████▉    | 8052/13536 [43:18<23:40,  3.86it/s] 60%|█████▉    | 8064/13536 [43:21<23:29,  3.88it/s] 60%|█████▉    | 8076/13536 [43:24<23:27,  3.88it/s] 60%|█████▉    | 8088/13536 [43:27<23:23,  3.88it/s] 60%|█████▉    | 8100/13536 [43:30<23:19,  3.88it/s] 60%|█████▉    | 8112/13536 [43:33<23:17,  3.88it/s] 60%|██████    | 8124/13536 [43:36<23:11,  3.89it/s] 60%|██████    | 8136/13536 [43:39<23:07,  3.89it/s] 60%|██████    | 8148/13536 [43:42<23:02,  3.90it/s] 60%|██████    | 8160/13536 [43:45<23:00,  3.90it/s] 60%|██████    | 8172/13536 [43:49<22:55,  3.90it/s] 60%|██████    | 8184/13536 [43:52<22:46,  3.92it/s] 61%|██████    | 8196/13536 [43:55<22:41,  3.92it/s] 61%|██████    | 8208/13536 [43:58<22:37,  3.92it/s] 61%|██████    | 8220/13536 [44:01<22:30,  3.93it/s] 61%|██████    | 8232/13536 [44:04<22:26,  3.94it/s] 61%|██████    | 8244/13536 [44:07<22:21,  3.94it/s] 61%|██████    | 8256/13536 [44:10<22:17,  3.95it/s] 61%|██████    | 8268/13536 [44:13<22:14,  3.95it/s] 61%|██████    | 8280/13536 [44:16<22:12,  3.95it/s] 61%|██████▏   | 8292/13536 [44:19<22:09,  3.94it/s] 61%|██████▏   | 8304/13536 [44:22<22:05,  3.95it/s] 61%|██████▏   | 8316/13536 [44:25<22:03,  3.94it/s] 62%|██████▏   | 8328/13536 [44:28<22:01,  3.94it/s] 62%|██████▏   | 8340/13536 [44:31<21:58,  3.94it/s] 62%|██████▏   | 8352/13536 [44:34<21:55,  3.94it/s] 62%|██████▏   | 8364/13536 [44:37<21:52,  3.94it/s] 62%|██████▏   | 8376/13536 [44:40<21:50,  3.94it/s] 62%|██████▏   | 8388/13536 [44:43<21:48,  3.93it/s] 62%|██████▏   | 8400/13536 [44:46<21:46,  3.93it/s] 62%|██████▏   | 8412/13536 [44:49<21:44,  3.93it/s] 62%|██████▏   | 8424/13536 [44:52<21:42,  3.93it/s] 62%|██████▏   | 8436/13536 [44:56<21:40,  3.92it/s] 62%|██████▏   | 8448/13536 [44:59<21:36,  3.92it/s] 62%|██████▎   | 8460/13536 [45:02<21:35,  3.92it/s] 63%|██████▎   | 8472/13536 [45:05<21:32,  3.92it/s] 63%|██████▎   | 8484/13536 [45:08<21:31,  3.91it/s] 63%|██████▎   | 8496/13536 [45:11<21:27,  3.91it/s] 63%|██████▎   | 8508/13536 [45:14<21:28,  3.90it/s] 63%|██████▎   | 8520/13536 [45:17<21:27,  3.90it/s] 63%|██████▎   | 8532/13536 [45:20<21:28,  3.88it/s] 63%|██████▎   | 8544/13536 [45:23<21:30,  3.87it/s] 63%|██████▎   | 8556/13536 [45:26<21:31,  3.86it/s] 63%|██████▎   | 8568/13536 [45:30<21:32,  3.84it/s] 63%|██████▎   | 8580/13536 [45:33<21:29,  3.84it/s] 63%|██████▎   | 8592/13536 [45:36<21:28,  3.84it/s] 64%|██████▎   | 8604/13536 [45:39<21:25,  3.84it/s] 64%|██████▎   | 8616/13536 [45:42<21:23,  3.83it/s] 64%|██████▎   | 8628/13536 [45:45<21:23,  3.82it/s] 64%|██████▍   | 8640/13536 [45:48<21:20,  3.82it/s] 64%|██████▍   | 8652/13536 [45:52<21:17,  3.82it/s] 64%|██████▍   | 8664/13536 [45:55<21:13,  3.82it/s] 64%|██████▍   | 8676/13536 [45:58<21:14,  3.81it/s] 64%|██████▍   | 8688/13536 [46:01<21:10,  3.82it/s] 64%|██████▍   | 8700/13536 [46:04<21:06,  3.82it/s] 64%|██████▍   | 8712/13536 [46:07<21:02,  3.82it/s] 64%|██████▍   | 8724/13536 [46:10<21:00,  3.82it/s] 65%|██████▍   | 8736/13536 [46:14<20:55,  3.82it/s] 65%|██████▍   | 8748/13536 [46:17<20:54,  3.82it/s] 65%|██████▍   | 8760/13536 [46:20<20:50,  3.82it/s] 65%|██████▍   | 8772/13536 [46:23<20:47,  3.82it/s] 65%|██████▍   | 8784/13536 [46:26<20:43,  3.82it/s] 65%|██████▍   | 8796/13536 [46:29<20:41,  3.82it/s] 65%|██████▌   | 8808/13536 [46:32<20:36,  3.82it/s] 65%|██████▌   | 8820/13536 [46:36<20:34,  3.82it/s] 65%|██████▌   | 8832/13536 [46:39<20:30,  3.82it/s] 65%|██████▌   | 8844/13536 [46:42<20:26,  3.82it/s] 65%|██████▌   | 8856/13536 [46:45<20:24,  3.82it/s] 66%|██████▌   | 8868/13536 [46:48<20:20,  3.82it/s] 66%|██████▌   | 8880/13536 [46:51<20:15,  3.83it/s] 66%|██████▌   | 8892/13536 [46:54<20:08,  3.84it/s] 66%|██████▌   | 8904/13536 [46:57<20:04,  3.85it/s] 66%|██████▌   | 8916/13536 [47:01<19:58,  3.86it/s] 66%|██████▌   | 8928/13536 [47:04<19:54,  3.86it/s] 66%|██████▌   | 8940/13536 [47:07<19:50,  3.86it/s] 66%|██████▌   | 8952/13536 [47:10<19:45,  3.87it/s] 66%|██████▌   | 8964/13536 [47:13<19:40,  3.87it/s] 66%|██████▋   | 8976/13536 [47:16<19:35,  3.88it/s] 66%|██████▋   | 8988/13536 [47:19<19:31,  3.88it/s] 66%|██████▋   | 9000/13536 [47:22<19:28,  3.88it/s] 67%|██████▋   | 9012/13536 [47:25<19:24,  3.88it/s] 67%|██████▋   | 9024/13536 [47:28<19:22,  3.88it/s] 67%|██████▋   | 9036/13536 [47:31<19:17,  3.89it/s] 67%|██████▋   | 9048/13536 [47:35<19:13,  3.89it/s] 67%|██████▋   | 9060/13536 [47:38<19:09,  3.90it/s] 67%|██████▋   | 9072/13536 [47:41<19:06,  3.89it/s] 67%|██████▋   | 9084/13536 [47:44<19:02,  3.90it/s] 67%|██████▋   | 9096/13536 [47:47<18:56,  3.91it/s] 67%|██████▋   | 9108/13536 [47:50<18:53,  3.91it/s] 67%|██████▋   | 9120/13536 [47:53<18:51,  3.90it/s] 67%|██████▋   | 9132/13536 [47:56<18:47,  3.90it/s] 68%|██████▊   | 9144/13536 [47:59<18:42,  3.91it/s] 68%|██████▊   | 9156/13536 [48:02<18:38,  3.92it/s] 68%|██████▊   | 9168/13536 [48:05<18:35,  3.92it/s] 68%|██████▊   | 9180/13536 [48:08<18:32,  3.92it/s] 68%|██████▊   | 9192/13536 [48:11<18:29,  3.92it/s] 68%|██████▊   | 9204/13536 [48:14<18:25,  3.92it/s] 68%|██████▊   | 9216/13536 [48:17<18:20,  3.93it/s] 68%|██████▊   | 9228/13536 [48:20<18:16,  3.93it/s] 68%|██████▊   | 9240/13536 [48:24<18:12,  3.93it/s] 68%|██████▊   | 9252/13536 [48:27<18:08,  3.94it/s] 68%|██████▊   | 9264/13536 [48:30<18:06,  3.93it/s] 69%|██████▊   | 9276/13536 [48:33<18:01,  3.94it/s] 69%|██████▊   | 9288/13536 [48:36<17:58,  3.94it/s] 69%|██████▊   | 9300/13536 [48:39<17:53,  3.95it/s] 69%|██████▉   | 9312/13536 [48:42<17:50,  3.95it/s] 69%|██████▉   | 9324/13536 [48:45<17:44,  3.96it/s] 69%|██████▉   | 9336/13536 [48:48<17:40,  3.96it/s] 69%|██████▉   | 9348/13536 [48:51<17:35,  3.97it/s] 69%|██████▉   | 9360/13536 [48:54<17:32,  3.97it/s] 69%|██████▉   | 9372/13536 [48:57<17:27,  3.97it/s] 69%|██████▉   | 9384/13536 [49:00<17:24,  3.97it/s] 69%|██████▉   | 9396/13536 [49:03<17:20,  3.98it/s] 70%|██████▉   | 9408/13536 [49:06<17:16,  3.98it/s] 70%|██████▉   | 9420/13536 [49:09<17:12,  3.99it/s] 70%|██████▉   | 9432/13536 [49:12<17:09,  3.99it/s] 70%|██████▉   | 9444/13536 [49:15<17:06,  3.99it/s] 70%|██████▉   | 9456/13536 [49:18<17:03,  3.99it/s] 70%|██████▉   | 9468/13536 [49:21<17:00,  3.99it/s] 70%|███████   | 9480/13536 [49:24<16:58,  3.98it/s] 70%|███████   | 9492/13536 [49:27<16:55,  3.98it/s] 70%|███████   | 9504/13536 [49:30<16:53,  3.98it/s] 70%|███████   | 9516/13536 [49:33<16:50,  3.98it/s] 70%|███████   | 9528/13536 [49:36<16:48,  3.97it/s] 70%|███████   | 9540/13536 [49:39<16:46,  3.97it/s] 71%|███████   | 9552/13536 [49:42<16:44,  3.97it/s] 71%|███████   | 9564/13536 [49:45<16:41,  3.97it/s] 71%|███████   | 9576/13536 [49:48<16:39,  3.96it/s] 71%|███████   | 9588/13536 [49:51<16:35,  3.96it/s] 71%|███████   | 9600/13536 [49:54<16:33,  3.96it/s] 71%|███████   | 9612/13536 [49:57<16:29,  3.97it/s] 71%|███████   | 9624/13536 [50:00<16:26,  3.97it/s] 71%|███████   | 9636/13536 [50:03<16:23,  3.97it/s] 71%|███████▏  | 9648/13536 [50:06<16:21,  3.96it/s] 71%|███████▏  | 9660/13536 [50:09<16:18,  3.96it/s] 71%|███████▏  | 9672/13536 [50:12<16:16,  3.96it/s] 72%|███████▏  | 9684/13536 [50:15<16:14,  3.95it/s] 72%|███████▏  | 9696/13536 [50:18<16:11,  3.95it/s] 72%|███████▏  | 9708/13536 [50:21<16:08,  3.95it/s] 72%|███████▏  | 9720/13536 [50:25<16:05,  3.95it/s] 72%|███████▏  | 9732/13536 [50:28<16:03,  3.95it/s] 72%|███████▏  | 9744/13536 [50:31<16:01,  3.94it/s] 72%|███████▏  | 9756/13536 [50:34<15:59,  3.94it/s] 72%|███████▏  | 9768/13536 [50:37<15:55,  3.94it/s] 72%|███████▏  | 9780/13536 [50:40<15:53,  3.94it/s] 72%|███████▏  | 9792/13536 [50:43<15:51,  3.94it/s] 72%|███████▏  | 9804/13536 [50:46<15:49,  3.93it/s] 73%|███████▎  | 9816/13536 [50:49<15:47,  3.92it/s] 73%|███████▎  | 9828/13536 [50:52<15:45,  3.92it/s] 73%|███████▎  | 9840/13536 [50:55<15:41,  3.93it/s] 73%|███████▎  | 9852/13536 [50:58<15:40,  3.92it/s] 73%|███████▎  | 9864/13536 [51:01<15:35,  3.93it/s] 73%|███████▎  | 9876/13536 [51:04<15:33,  3.92it/s] 73%|███████▎  | 9888/13536 [51:07<15:29,  3.92it/s] 73%|███████▎  | 9900/13536 [51:10<15:27,  3.92it/s] 73%|███████▎  | 9912/13536 [51:13<15:24,  3.92it/s] 73%|███████▎  | 9924/13536 [51:17<15:22,  3.92it/s] 73%|███████▎  | 9936/13536 [51:20<15:18,  3.92it/s] 73%|███████▎  | 9948/13536 [51:23<15:13,  3.93it/s] 74%|███████▎  | 9960/13536 [51:26<15:07,  3.94it/s] 74%|███████▎  | 9972/13536 [51:29<15:02,  3.95it/s] 74%|███████▍  | 9984/13536 [51:32<14:58,  3.95it/s] 74%|███████▍  | 9996/13536 [51:35<14:53,  3.96it/s] 74%|███████▍  | 10008/13536 [51:38<14:48,  3.97it/s] 74%|███████▍  | 10020/13536 [51:41<14:43,  3.98it/s] 74%|███████▍  | 10032/13536 [51:44<14:39,  3.99it/s] 74%|███████▍  | 10044/13536 [51:47<14:35,  3.99it/s] 74%|███████▍  | 10056/13536 [51:50<14:31,  3.99it/s] 74%|███████▍  | 10068/13536 [51:53<14:28,  3.99it/s] 74%|███████▍  | 10080/13536 [51:56<14:24,  4.00it/s] 75%|███████▍  | 10092/13536 [51:59<14:19,  4.01it/s] 75%|███████▍  | 10104/13536 [52:02<14:14,  4.02it/s] 75%|███████▍  | 10116/13536 [52:05<14:10,  4.02it/s] 75%|███████▍  | 10128/13536 [52:08<14:06,  4.03it/s] 75%|███████▍  | 10140/13536 [52:11<14:01,  4.04it/s] 75%|███████▌  | 10152/13536 [52:14<13:57,  4.04it/s] 75%|███████▌  | 10164/13536 [52:16<13:52,  4.05it/s] 75%|███████▌  | 10176/13536 [52:19<13:50,  4.05it/s] 75%|███████▌  | 10188/13536 [52:22<13:45,  4.06it/s] 75%|███████▌  | 10200/13536 [52:25<13:43,  4.05it/s] 75%|███████▌  | 10212/13536 [52:28<13:40,  4.05it/s] 76%|███████▌  | 10224/13536 [52:31<13:35,  4.06it/s] 76%|███████▌  | 10236/13536 [52:34<13:31,  4.07it/s] 76%|███████▌  | 10248/13536 [52:37<13:27,  4.07it/s] 76%|███████▌  | 10260/13536 [52:40<13:24,  4.07it/s] 76%|███████▌  | 10272/13536 [52:43<13:19,  4.08it/s] 76%|███████▌  | 10284/13536 [52:46<13:16,  4.08it/s] 76%|███████▌  | 10296/13536 [52:49<13:12,  4.09it/s] 76%|███████▌  | 10308/13536 [52:52<13:06,  4.10it/s] 76%|███████▌  | 10320/13536 [52:55<13:02,  4.11it/s] 76%|███████▋  | 10332/13536 [52:58<12:58,  4.12it/s] 76%|███████▋  | 10344/13536 [53:00<12:54,  4.12it/s] 77%|███████▋  | 10356/13536 [53:03<12:49,  4.13it/s] 77%|███████▋  | 10368/13536 [53:06<12:45,  4.14it/s] 77%|███████▋  | 10380/13536 [53:09<12:41,  4.14it/s] 77%|███████▋  | 10392/13536 [53:12<12:37,  4.15it/s] 77%|███████▋  | 10404/13536 [53:15<12:34,  4.15it/s] 77%|███████▋  | 10416/13536 [53:18<12:32,  4.15it/s] 77%|███████▋  | 10428/13536 [53:21<12:30,  4.14it/s] 77%|███████▋  | 10440/13536 [53:24<12:29,  4.13it/s] 77%|███████▋  | 10452/13536 [53:27<12:27,  4.13it/s] 77%|███████▋  | 10464/13536 [53:29<12:27,  4.11it/s] 77%|███████▋  | 10476/13536 [53:32<12:24,  4.11it/s] 77%|███████▋  | 10488/13536 [53:35<12:22,  4.10it/s] 78%|███████▊  | 10500/13536 [53:38<12:19,  4.10it/s] 78%|███████▊  | 10512/13536 [53:41<12:16,  4.11it/s] 78%|███████▊  | 10524/13536 [53:44<12:14,  4.10it/s] 78%|███████▊  | 10536/13536 [53:47<12:12,  4.10it/s] 78%|███████▊  | 10548/13536 [53:50<12:11,  4.09it/s] 78%|███████▊  | 10560/13536 [53:53<12:06,  4.10it/s] 78%|███████▊  | 10572/13536 [53:56<12:04,  4.09it/s] 78%|███████▊  | 10584/13536 [53:59<12:00,  4.10it/s] 78%|███████▊  | 10596/13536 [54:02<11:56,  4.10it/s] 78%|███████▊  | 10608/13536 [54:05<11:51,  4.11it/s] 78%|███████▊  | 10620/13536 [54:07<11:47,  4.12it/s] 79%|███████▊  | 10632/13536 [54:10<11:42,  4.13it/s] 79%|███████▊  | 10644/13536 [54:13<11:38,  4.14it/s] 79%|███████▊  | 10656/13536 [54:16<11:33,  4.15it/s] 79%|███████▉  | 10668/13536 [54:19<11:29,  4.16it/s] 79%|███████▉  | 10680/13536 [54:22<11:23,  4.18it/s] 79%|███████▉  | 10692/13536 [54:25<11:19,  4.19it/s] 79%|███████▉  | 10704/13536 [54:28<11:15,  4.20it/s] 79%|███████▉  | 10716/13536 [54:30<11:10,  4.21it/s] 79%|███████▉  | 10728/13536 [54:33<11:05,  4.22it/s] 79%|███████▉  | 10740/13536 [54:36<11:01,  4.23it/s] 79%|███████▉  | 10752/13536 [54:39<10:57,  4.24it/s] 80%|███████▉  | 10764/13536 [54:42<10:53,  4.24it/s] 80%|███████▉  | 10776/13536 [54:44<10:49,  4.25it/s] 80%|███████▉  | 10788/13536 [54:47<10:47,  4.24it/s] 80%|███████▉  | 10800/13536 [54:50<10:45,  4.24it/s] 80%|███████▉  | 10812/13536 [54:53<10:43,  4.24it/s] 80%|███████▉  | 10824/13536 [54:56<10:39,  4.24it/s] 80%|████████  | 10836/13536 [54:59<10:36,  4.24it/s] 80%|████████  | 10848/13536 [55:01<10:32,  4.25it/s] 80%|████████  | 10860/13536 [55:04<10:29,  4.25it/s] 80%|████████  | 10872/13536 [55:07<10:26,  4.25it/s] 80%|████████  | 10884/13536 [55:10<10:24,  4.25it/s] 80%|████████  | 10896/13536 [55:13<10:20,  4.25it/s] 81%|████████  | 10908/13536 [55:16<10:18,  4.25it/s] 81%|████████  | 10920/13536 [55:18<10:14,  4.26it/s] 81%|████████  | 10932/13536 [55:21<10:09,  4.27it/s] 81%|████████  | 10944/13536 [55:24<10:06,  4.28it/s] 81%|████████  | 10956/13536 [55:27<10:02,  4.28it/s] 81%|████████  | 10968/13536 [55:30<09:59,  4.28it/s] 81%|████████  | 10980/13536 [55:32<09:56,  4.28it/s] 81%|████████  | 10992/13536 [55:35<09:53,  4.29it/s] 81%|████████▏ | 11004/13536 [55:38<09:48,  4.30it/s] 81%|████████▏ | 11016/13536 [55:41<09:45,  4.30it/s] 81%|████████▏ | 11028/13536 [55:43<09:42,  4.31it/s] 82%|████████▏ | 11040/13536 [55:46<09:40,  4.30it/s] 82%|████████▏ | 11052/13536 [55:49<09:37,  4.30it/s] 82%|████████▏ | 11064/13536 [55:52<09:34,  4.30it/s] 82%|████████▏ | 11076/13536 [55:55<09:30,  4.31it/s] 82%|████████▏ | 11088/13536 [55:57<09:26,  4.33it/s] 82%|████████▏ | 11100/13536 [56:00<09:23,  4.32it/s] 82%|████████▏ | 11112/13536 [56:03<09:20,  4.33it/s] 82%|████████▏ | 11124/13536 [56:06<09:16,  4.34it/s] 82%|████████▏ | 11136/13536 [56:08<09:12,  4.34it/s] 82%|████████▏ | 11148/13536 [56:11<09:11,  4.33it/s] 82%|████████▏ | 11160/13536 [56:14<09:08,  4.34it/s] 83%|████████▎ | 11172/13536 [56:17<09:04,  4.34it/s] 83%|████████▎ | 11184/13536 [56:20<09:01,  4.34it/s] 83%|████████▎ | 11196/13536 [56:22<08:59,  4.33it/s] 83%|████████▎ | 11208/13536 [56:25<08:56,  4.34it/s] 83%|████████▎ | 11220/13536 [56:28<08:52,  4.35it/s] 83%|████████▎ | 11232/13536 [56:31<08:50,  4.35it/s] 83%|████████▎ | 11244/13536 [56:33<08:47,  4.34it/s] 83%|████████▎ | 11256/13536 [56:36<08:43,  4.35it/s] 83%|████████▎ | 11268/13536 [56:39<08:41,  4.35it/s] 83%|████████▎ | 11280/13536 [56:42<08:38,  4.35it/s] 83%|████████▎ | 11292/13536 [56:44<08:34,  4.36it/s] 84%|████████▎ | 11304/13536 [56:47<08:32,  4.36it/s] 84%|████████▎ | 11316/13536 [56:50<08:30,  4.35it/s] 84%|████████▎ | 11328/13536 [56:53<08:26,  4.36it/s] 84%|████████▍ | 11340/13536 [56:55<08:23,  4.36it/s] 84%|████████▍ | 11352/13536 [56:58<08:20,  4.37it/s] 84%|████████▍ | 11364/13536 [57:01<08:15,  4.38it/s] 84%|████████▍ | 11376/13536 [57:04<08:12,  4.38it/s] 84%|████████▍ | 11388/13536 [57:06<08:08,  4.39it/s] 84%|████████▍ | 11400/13536 [57:09<08:06,  4.39it/s] 84%|████████▍ | 11412/13536 [57:12<08:04,  4.39it/s] 84%|████████▍ | 11424/13536 [57:14<08:00,  4.39it/s] 84%|████████▍ | 11436/13536 [57:17<07:59,  4.38it/s] 85%|████████▍ | 11448/13536 [57:20<07:55,  4.39it/s] 85%|████████▍ | 11460/13536 [57:23<07:53,  4.39it/s] 85%|████████▍ | 11472/13536 [57:25<07:50,  4.39it/s] 85%|████████▍ | 11484/13536 [57:28<07:48,  4.38it/s] 85%|████████▍ | 11496/13536 [57:31<07:46,  4.38it/s] 85%|████████▌ | 11508/13536 [57:34<07:41,  4.39it/s] 85%|████████▌ | 11520/13536 [57:36<07:38,  4.40it/s] 85%|████████▌ | 11532/13536 [57:39<07:35,  4.40it/s] 85%|████████▌ | 11544/13536 [57:42<07:32,  4.40it/s] 85%|████████▌ | 11556/13536 [57:45<07:30,  4.40it/s] 85%|████████▌ | 11568/13536 [57:47<07:27,  4.40it/s] 86%|████████▌ | 11580/13536 [57:50<07:24,  4.40it/s] 86%|████████▌ | 11592/13536 [57:53<07:21,  4.40it/s] 86%|████████▌ | 11604/13536 [57:55<07:20,  4.39it/s] 86%|████████▌ | 11616/13536 [57:58<07:16,  4.40it/s] 86%|████████▌ | 11628/13536 [58:01<07:14,  4.39it/s] 86%|████████▌ | 11640/13536 [58:04<07:10,  4.41it/s] 86%|████████▌ | 11652/13536 [58:06<07:08,  4.40it/s] 86%|████████▌ | 11664/13536 [58:09<07:04,  4.41it/s] 86%|████████▋ | 11676/13536 [58:12<07:02,  4.40it/s] 86%|████████▋ | 11688/13536 [58:14<06:58,  4.41it/s] 86%|████████▋ | 11700/13536 [58:17<06:55,  4.42it/s] 87%|████████▋ | 11712/13536 [58:20<06:51,  4.43it/s] 87%|████████▋ | 11724/13536 [58:23<06:49,  4.43it/s] 87%|████████▋ | 11736/13536 [58:25<06:45,  4.44it/s] 87%|████████▋ | 11748/13536 [58:28<06:43,  4.43it/s] 87%|████████▋ | 11760/13536 [58:31<06:41,  4.43it/s] 87%|████████▋ | 11772/13536 [58:33<06:38,  4.43it/s] 87%|████████▋ | 11784/13536 [58:36<06:35,  4.43it/s] 87%|████████▋ | 11796/13536 [58:39<06:32,  4.43it/s] 87%|████████▋ | 11808/13536 [58:42<06:30,  4.43it/s] 87%|████████▋ | 11820/13536 [58:44<06:27,  4.43it/s] 87%|████████▋ | 11832/13536 [58:47<06:25,  4.42it/s] 88%|████████▊ | 11844/13536 [58:50<06:21,  4.44it/s] 88%|████████▊ | 11856/13536 [58:52<06:19,  4.43it/s] 88%|████████▊ | 11868/13536 [58:55<06:15,  4.44it/s] 88%|████████▊ | 11880/13536 [58:58<06:13,  4.44it/s] 88%|████████▊ | 11892/13536 [59:00<06:10,  4.44it/s] 88%|████████▊ | 11904/13536 [59:03<06:07,  4.44it/s] 88%|████████▊ | 11916/13536 [59:06<06:05,  4.44it/s] 88%|████████▊ | 11928/13536 [59:09<06:01,  4.44it/s] 88%|████████▊ | 11940/13536 [59:11<05:59,  4.44it/s] 88%|████████▊ | 11952/13536 [59:14<05:56,  4.44it/s] 88%|████████▊ | 11964/13536 [59:17<05:53,  4.45it/s] 88%|████████▊ | 11976/13536 [59:19<05:51,  4.44it/s] 89%|████████▊ | 11988/13536 [59:22<05:47,  4.46it/s] 89%|████████▊ | 12000/13536 [59:25<05:44,  4.46it/s] 89%|████████▊ | 12012/13536 [59:27<05:41,  4.46it/s] 89%|████████▉ | 12024/13536 [59:30<05:38,  4.47it/s] 89%|████████▉ | 12036/13536 [59:33<05:35,  4.47it/s] 89%|████████▉ | 12048/13536 [59:36<05:33,  4.46it/s] 89%|████████▉ | 12060/13536 [59:38<05:30,  4.47it/s] 89%|████████▉ | 12072/13536 [59:41<05:27,  4.47it/s] 89%|████████▉ | 12084/13536 [59:44<05:25,  4.47it/s] 89%|████████▉ | 12096/13536 [59:46<05:22,  4.47it/s] 89%|████████▉ | 12108/13536 [59:49<05:19,  4.47it/s] 90%|████████▉ | 12120/13536 [59:52<05:17,  4.47it/s] 90%|████████▉ | 12132/13536 [59:54<05:14,  4.47it/s] 90%|████████▉ | 12144/13536 [59:57<05:11,  4.46it/s] 90%|████████▉ | 12156/13536 [1:00:00<05:09,  4.46it/s] 90%|████████▉ | 12168/13536 [1:00:02<05:06,  4.46it/s] 90%|████████▉ | 12180/13536 [1:00:05<05:03,  4.46it/s] 90%|█████████ | 12192/13536 [1:00:08<05:00,  4.47it/s] 90%|█████████ | 12204/13536 [1:00:10<04:57,  4.48it/s] 90%|█████████ | 12216/13536 [1:00:13<04:53,  4.49it/s] 90%|█████████ | 12228/13536 [1:00:16<04:51,  4.49it/s] 90%|█████████ | 12240/13536 [1:00:18<04:47,  4.51it/s] 91%|█████████ | 12252/13536 [1:00:21<04:44,  4.52it/s] 91%|█████████ | 12264/13536 [1:00:24<04:40,  4.53it/s] 91%|█████████ | 12276/13536 [1:00:26<04:37,  4.54it/s] 91%|█████████ | 12288/13536 [1:00:29<04:34,  4.54it/s] 91%|█████████ | 12300/13536 [1:00:32<04:31,  4.55it/s] 91%|█████████ | 12312/13536 [1:00:34<04:29,  4.54it/s] 91%|█████████ | 12324/13536 [1:00:37<04:27,  4.53it/s] 91%|█████████ | 12336/13536 [1:00:39<04:24,  4.54it/s] 91%|█████████ | 12348/13536 [1:00:42<04:21,  4.55it/s] 91%|█████████▏| 12360/13536 [1:00:45<04:17,  4.56it/s] 91%|█████████▏| 12372/13536 [1:00:47<04:14,  4.58it/s] 91%|█████████▏| 12384/13536 [1:00:50<04:11,  4.58it/s] 92%|█████████▏| 12396/13536 [1:00:53<04:08,  4.59it/s] 92%|█████████▏| 12408/13536 [1:00:55<04:05,  4.60it/s] 92%|█████████▏| 12420/13536 [1:00:58<04:02,  4.60it/s] 92%|█████████▏| 12432/13536 [1:01:00<03:59,  4.60it/s] 92%|█████████▏| 12444/13536 [1:01:03<03:57,  4.59it/s] 92%|█████████▏| 12456/13536 [1:01:06<03:55,  4.58it/s] 92%|█████████▏| 12468/13536 [1:01:08<03:52,  4.59it/s] 92%|█████████▏| 12480/13536 [1:01:11<03:50,  4.59it/s] 92%|█████████▏| 12492/13536 [1:01:13<03:47,  4.58it/s] 92%|█████████▏| 12504/13536 [1:01:16<03:44,  4.59it/s] 92%|█████████▏| 12516/13536 [1:01:19<03:42,  4.58it/s] 93%|█████████▎| 12528/13536 [1:01:21<03:39,  4.58it/s] 93%|█████████▎| 12540/13536 [1:01:24<03:37,  4.58it/s] 93%|█████████▎| 12552/13536 [1:01:27<03:34,  4.59it/s] 93%|█████████▎| 12564/13536 [1:01:29<03:31,  4.60it/s] 93%|█████████▎| 12576/13536 [1:01:32<03:28,  4.60it/s] 93%|█████████▎| 12588/13536 [1:01:34<03:25,  4.60it/s] 93%|█████████▎| 12600/13536 [1:01:37<03:22,  4.61it/s] 93%|█████████▎| 12612/13536 [1:01:40<03:19,  4.62it/s] 93%|█████████▎| 12624/13536 [1:01:42<03:17,  4.63it/s] 93%|█████████▎| 12636/13536 [1:01:45<03:14,  4.63it/s] 93%|█████████▎| 12648/13536 [1:01:47<03:11,  4.64it/s] 94%|█████████▎| 12660/13536 [1:01:50<03:08,  4.64it/s] 94%|█████████▎| 12672/13536 [1:01:52<03:05,  4.65it/s] 94%|█████████▎| 12684/13536 [1:01:55<03:03,  4.65it/s] 94%|█████████▍| 12696/13536 [1:01:58<03:00,  4.66it/s] 94%|█████████▍| 12708/13536 [1:02:00<02:57,  4.67it/s] 94%|█████████▍| 12720/13536 [1:02:03<02:54,  4.69it/s] 94%|█████████▍| 12732/13536 [1:02:05<02:51,  4.70it/s] 94%|█████████▍| 12744/13536 [1:02:08<02:47,  4.72it/s] 94%|█████████▍| 12756/13536 [1:02:10<02:45,  4.73it/s] 94%|█████████▍| 12768/13536 [1:02:13<02:42,  4.73it/s] 94%|█████████▍| 12780/13536 [1:02:15<02:39,  4.74it/s] 95%|█████████▍| 12792/13536 [1:02:18<02:36,  4.74it/s] 95%|█████████▍| 12804/13536 [1:02:20<02:34,  4.74it/s] 95%|█████████▍| 12816/13536 [1:02:23<02:31,  4.75it/s] 95%|█████████▍| 12828/13536 [1:02:25<02:29,  4.75it/s] 95%|█████████▍| 12840/13536 [1:02:28<02:26,  4.74it/s] 95%|█████████▍| 12852/13536 [1:02:30<02:23,  4.76it/s] 95%|█████████▌| 12864/13536 [1:02:33<02:20,  4.77it/s] 95%|█████████▌| 12876/13536 [1:02:35<02:18,  4.78it/s] 95%|█████████▌| 12888/13536 [1:02:38<02:15,  4.79it/s] 95%|█████████▌| 12900/13536 [1:02:40<02:12,  4.79it/s] 95%|█████████▌| 12912/13536 [1:02:43<02:10,  4.80it/s] 95%|█████████▌| 12924/13536 [1:02:45<02:07,  4.80it/s] 96%|█████████▌| 12936/13536 [1:02:48<02:05,  4.80it/s] 96%|█████████▌| 12948/13536 [1:02:50<02:02,  4.80it/s] 96%|█████████▌| 12960/13536 [1:02:53<01:59,  4.80it/s] 96%|█████████▌| 12972/13536 [1:02:55<01:57,  4.81it/s] 96%|█████████▌| 12984/13536 [1:02:58<01:54,  4.80it/s] 96%|█████████▌| 12996/13536 [1:03:00<01:52,  4.82it/s] 96%|█████████▌| 13008/13536 [1:03:03<01:49,  4.82it/s] 96%|█████████▌| 13020/13536 [1:03:05<01:47,  4.82it/s] 96%|█████████▋| 13032/13536 [1:03:08<01:44,  4.83it/s] 96%|█████████▋| 13044/13536 [1:03:10<01:41,  4.82it/s] 96%|█████████▋| 13056/13536 [1:03:13<01:39,  4.83it/s] 97%|█████████▋| 13068/13536 [1:03:15<01:36,  4.83it/s] 97%|█████████▋| 13080/13536 [1:03:18<01:34,  4.84it/s] 97%|█████████▋| 13092/13536 [1:03:20<01:31,  4.84it/s] 97%|█████████▋| 13104/13536 [1:03:23<01:29,  4.85it/s] 97%|█████████▋| 13116/13536 [1:03:25<01:26,  4.84it/s] 97%|█████████▋| 13128/13536 [1:03:28<01:24,  4.84it/s] 97%|█████████▋| 13140/13536 [1:03:30<01:21,  4.86it/s] 97%|█████████▋| 13152/13536 [1:03:33<01:19,  4.86it/s] 97%|█████████▋| 13164/13536 [1:03:35<01:16,  4.85it/s] 97%|█████████▋| 13176/13536 [1:03:38<01:14,  4.85it/s] 97%|█████████▋| 13188/13536 [1:03:40<01:11,  4.87it/s] 98%|█████████▊| 13200/13536 [1:03:42<01:08,  4.88it/s] 98%|█████████▊| 13212/13536 [1:03:45<01:06,  4.89it/s] 98%|█████████▊| 13224/13536 [1:03:47<01:03,  4.89it/s] 98%|█████████▊| 13236/13536 [1:03:50<01:01,  4.89it/s] 98%|█████████▊| 13248/13536 [1:03:52<00:58,  4.90it/s] 98%|█████████▊| 13260/13536 [1:03:55<00:56,  4.89it/s] 98%|█████████▊| 13272/13536 [1:03:57<00:53,  4.90it/s] 98%|█████████▊| 13284/13536 [1:04:00<00:51,  4.88it/s] 98%|█████████▊| 13296/13536 [1:04:02<00:49,  4.90it/s] 98%|█████████▊| 13308/13536 [1:04:04<00:46,  4.90it/s] 98%|█████████▊| 13320/13536 [1:04:07<00:44,  4.90it/s] 98%|█████████▊| 13332/13536 [1:04:09<00:41,  4.91it/s] 99%|█████████▊| 13344/13536 [1:04:12<00:39,  4.90it/s] 99%|█████████▊| 13356/13536 [1:04:14<00:36,  4.91it/s] 99%|█████████▉| 13368/13536 [1:04:17<00:34,  4.91it/s] 99%|█████████▉| 13380/13536 [1:04:19<00:31,  4.91it/s] 99%|█████████▉| 13392/13536 [1:04:22<00:29,  4.91it/s] 99%|█████████▉| 13404/13536 [1:04:24<00:26,  4.91it/s] 99%|█████████▉| 13416/13536 [1:04:26<00:24,  4.92it/s] 99%|█████████▉| 13428/13536 [1:04:29<00:21,  4.92it/s] 99%|█████████▉| 13440/13536 [1:04:31<00:19,  4.94it/s] 99%|█████████▉| 13452/13536 [1:04:34<00:17,  4.94it/s] 99%|█████████▉| 13464/13536 [1:04:36<00:14,  4.94it/s]100%|█████████▉| 13476/13536 [1:04:39<00:12,  4.93it/s]100%|█████████▉| 13488/13536 [1:04:41<00:09,  4.94it/s]100%|█████████▉| 13500/13536 [1:04:43<00:07,  4.95it/s]100%|█████████▉| 13512/13536 [1:04:46<00:04,  4.95it/s]100%|█████████▉| 13524/13536 [1:04:48<00:02,  4.96it/s]100%|██████████| 13536/13536 [1:04:51<00:00,  4.97it/s]100%|██████████| 13536/13536 [1:04:51<00:00,  3.48it/s]
fatal: not a git repository (or any of the parent directories): .git
{'m_mmlu_el': {'alias': 'm_mmlu_el', 'acc,none': 0.4768551488391967, 'acc_stderr,none': 0.004215073928242422}, 'm_mmlu_hu': {'alias': 'm_mmlu_hu', 'acc,none': 0.5022266584766585, 'acc_stderr,none': 0.004381372494992046}}
