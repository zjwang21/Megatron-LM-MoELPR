W1006 12:45:14.578610 139925611000768 torch/distributed/run.py:757] 
W1006 12:45:14.578610 139925611000768 torch/distributed/run.py:757] *****************************************
W1006 12:45:14.578610 139925611000768 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1006 12:45:14.578610 139925611000768 torch/distributed/run.py:757] *****************************************
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/root/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
using world size: 8, data-parallel size: 8, context-parallel size: 1, tensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0
WARNING: overriding default arguments for no_load_rng:True                        with no_load_rng:True
WARNING: overriding default arguments for no_load_optim:True                        with no_load_optim:True
WARNING: overriding default arguments for micro_batch_size:1                        with micro_batch_size:4
WARNING: overriding default arguments for exit_on_missing_checkpoint:True                        with exit_on_missing_checkpoint:False
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adaptive_seq_len ................................ True
  add_bias_linear ................................. False
  add_position_embedding .......................... False
  add_qkv_bias .................................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... False
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.0
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ False
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  bsz ............................................. 8
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/root/work/huangxin/nanda/Megatron-LM/llamamoe/data/data-bin/elhutr_qwen2.5_30b_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... True
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 1000000
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  enable_shared_expert ............................ True
  encoder_num_layers .............................. 36
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 2048
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1000
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 2
  ffn_hidden_size ................................. 11008
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 1024
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... True
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.0
  hidden_size ..................................... 2048
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 5e-05
  lr_decay_iters .................................. 5000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 300
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 32768
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.001
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_ffn_hidden_size ............................. 5504
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_lpr_loss_coeff .............................. 0.001
  moe_lpr_stage ................................... 1
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... alltoall
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  moelpr_train_embeddings ......................... False
  nccl_communicator_config_path ................... None
  no_load_optim ................................... True
  no_load_rng ..................................... True
  no_persist_layer_norm ........................... False
  no_save_optim ................................... True
  no_save_rng ..................................... True
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... RMSNorm
  num_attention_heads ............................. 16
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... 6
  num_fewshot ..................................... 10
  num_layers ...................................... 36
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 2
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. True
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ True
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... rope
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  results_path .................................... /root/work/huangxin/nanda/Megatron-LM/llamamoe/eval/results/mcore_qwen2.5-3B-instruct-share-6exp-hellaswag_expanded.json
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 1000000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 99990,8,2
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... True
  swin_backbone_type .............................. tiny
  task_list ....................................... hellaswag_el,hellaswag_hu,hellaswag_tr
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. /root/work/huangxin/nanda/models/Qwen/Qwen2.5-3B-Instruct
  tokenizer_type .................................. HuggingFaceTokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 5000
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. True
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... None
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
  zero_expert_down_proj ........................... False
-------------------- end of arguments ---------------------
> building HuggingFaceTokenizer tokenizer ...
 > padded vocab (size: 151936) with 0 dummy tokens (new size: 151936)
> initializing torch distributed ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/root/work/huangxin/nanda/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.022 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.009 seconds
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
[INFO     | lm-eval            ]: `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.
building GPT model ...
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context
[Rank 1] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
GPTModel(
  (embedding): LanguageModelEmbedding(
    (word_embeddings): VocabParallelEmbedding()
    (embedding_dropout): Dropout(p=0.0, inplace=False)
  )
  (rotary_pos_emb): RotaryEmbedding()
  (decoder): TransformerBlock(
    (layers): ModuleList(
      (0-35): 36 x TransformerLayer(
        (input_layernorm): IdentityOp()
        (self_attention): SelfAttention(
          (core_attention): TEDotProductAttention(
            (flash_attention): FlashAttention()
            (fused_attention): FusedAttention()
            (unfused_attention): UnfusedDotProductAttention(
              (scale_mask_softmax): FusedScaleMaskSoftmax()
              (attention_dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (linear_proj): TERowParallelLinear()
          (linear_qkv): TELayerNormColumnParallelLinear()
          (q_layernorm): IdentityOp()
          (k_layernorm): IdentityOp()
        )
        (pre_cross_attn_layernorm): IdentityOp()
        (cross_attention): IdentityOp()
        (cross_attn_bda): IdentityFuncOp()
        (pre_mlp_layernorm): RMSNorm()
        (mlp): MoELayer(
          (router): TopKRouter()
          (shared_expert_gate): LanguageRouter()
          (shared_expert): MLP(
            (linear_fc1): ColumnParallelLinear()
            (linear_fc2): RowParallelLinear()
          )
          (experts): SequentialMLP(
            (local_experts): ModuleList(
              (0-2): 3 x MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
            )
          )
        )
      )
    )
    (final_layernorm): RMSNorm()
  )
  (output_layer): ColumnParallelLinear()
)
Fine-tuning method: MoE-LPR stage 1
[Rank 7] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 2] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 3] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 4] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 6] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000
[Rank 5] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000[Rank 0] trainable params: 0 || all params: 6,738,718,720 || trainable%: 0.0000

 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6738718720
 loading checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2 at iteration 12000
 checkpoint version 3.0
  successfully loaded checkpoint from /root/work/huangxin/nanda/models/Qwen2.5-3B-Instruct-qwenmoe-mcore-exp6-TP1PP1EP2 [ t 0, p 0 ] at iteration 12000
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
[INFO     | lm-eval            ]: Using pre-initialized model
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
DistributedDataParallel(
  (module): Float16Module(
    (module): GPTModel(
      (embedding): LanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): RotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-35): 36 x TransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): TEDotProductAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear()
              (linear_qkv): TELayerNormColumnParallelLinear()
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): RMSNorm()
            (mlp): MoELayer(
              (router): TopKRouter()
              (shared_expert_gate): LanguageRouter()
              (shared_expert): MLP(
                (linear_fc1): ColumnParallelLinear()
                (linear_fc2): RowParallelLinear()
              )
              (experts): SequentialMLP(
                (local_experts): ModuleList(
                  (0-2): 3 x MLP(
                    (linear_fc1): ColumnParallelLinear()
                    (linear_fc2): RowParallelLinear()
                  )
                )
              )
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): ColumnParallelLinear()
    )
  )
)
[INFO     | lm-eval            ]: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
[INFO     | lm-eval            ]: Using pre-initialized model
Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since ilsp/hellaswag_greek couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'default' at /root/work/huangxin/nanda/data/cache/ilsp___hellaswag_greek/default/0.0.0/ac871418b051baaf0fe8fbd5d5f335d5fa8a1d66 (last modified on Thu Sep 19 15:25:10 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
[WARNING  | datasets.load      ]: Using the latest cached version of the dataset since alexandrainst/m_hellaswag couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | datasets.packaged_modules.cache.cache]: Found the latest cached dataset configuration 'hu' at /root/work/huangxin/nanda/data/cache/alexandrainst___m_hellaswag/hu/0.0.0/9d31dc982bd6285e081e3e3136332a38b9c1d7b7 (last modified on Thu Sep 19 15:25:21 2024).
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_tr from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_hu from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[WARNING  | lm-eval            ]: Overwriting default num_fewshot of hellaswag_el from None to 10
[INFO     | lm-eval            ]: Setting fewshot random generator seed to 1234
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
[INFO     | lm-eval            ]: Running loglikelihood requests
  0%|          | 0/14596 [00:00<?, ?it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
  0%|          | 8/14596 [00:13<6:55:31,  1.71s/it]  0%|          | 16/14596 [00:21<5:05:41,  1.26s/it]  0%|          | 24/14596 [00:28<4:24:58,  1.09s/it]  0%|          | 32/14596 [00:33<3:46:18,  1.07it/s]  0%|          | 40/14596 [00:41<3:52:06,  1.05it/s]  0%|          | 48/14596 [00:47<3:32:03,  1.14it/s]  0%|          | 56/14596 [00:54<3:26:28,  1.17it/s]  0%|          | 64/14596 [01:02<3:41:57,  1.09it/s]  0%|          | 72/14596 [01:08<3:31:11,  1.15it/s]  1%|          | 80/14596 [01:15<3:27:38,  1.17it/s]  1%|          | 88/14596 [01:21<3:23:21,  1.19it/s]  1%|          | 96/14596 [01:27<3:14:37,  1.24it/s]  1%|          | 104/14596 [01:36<3:33:29,  1.13it/s]  1%|          | 112/14596 [01:41<3:22:45,  1.19it/s]  1%|          | 120/14596 [01:48<3:24:24,  1.18it/s]  1%|          | 128/14596 [01:56<3:28:54,  1.15it/s]  1%|          | 136/14596 [02:01<3:14:00,  1.24it/s]  1%|          | 144/14596 [02:09<3:31:24,  1.14it/s]  1%|          | 152/14596 [02:15<3:22:17,  1.19it/s]  1%|          | 160/14596 [02:22<3:19:35,  1.21it/s]  1%|          | 168/14596 [02:29<3:28:05,  1.16it/s]  1%|          | 176/14596 [02:35<3:19:09,  1.21it/s]  1%|▏         | 184/14596 [02:43<3:25:17,  1.17it/s]  1%|▏         | 192/14596 [02:50<3:27:55,  1.15it/s]  1%|▏         | 200/14596 [02:55<3:16:07,  1.22it/s]  1%|▏         | 208/14596 [03:04<3:35:40,  1.11it/s]  1%|▏         | 216/14596 [03:09<3:19:05,  1.20it/s]  2%|▏         | 224/14596 [03:16<3:20:20,  1.20it/s]  2%|▏         | 232/14596 [03:24<3:28:28,  1.15it/s]  2%|▏         | 240/14596 [03:29<3:14:24,  1.23it/s]  2%|▏         | 248/14596 [03:38<3:33:38,  1.12it/s]  2%|▏         | 256/14596 [03:44<3:24:31,  1.17it/s]  2%|▏         | 264/14596 [03:50<3:15:46,  1.22it/s]  2%|▏         | 272/14596 [03:58<3:28:49,  1.14it/s]  2%|▏         | 280/14596 [04:04<3:22:57,  1.18it/s]  2%|▏         | 288/14596 [04:11<3:22:03,  1.18it/s]  2%|▏         | 296/14596 [04:19<3:28:04,  1.15it/s]  2%|▏         | 304/14596 [04:26<3:29:53,  1.13it/s]  2%|▏         | 312/14596 [04:32<3:23:23,  1.17it/s]  2%|▏         | 320/14596 [04:39<3:20:14,  1.19it/s]  2%|▏         | 328/14596 [04:46<3:30:51,  1.13it/s]  2%|▏         | 336/14596 [04:53<3:26:03,  1.15it/s]  2%|▏         | 344/14596 [05:00<3:23:04,  1.17it/s]  2%|▏         | 352/14596 [05:06<3:21:56,  1.18it/s]  2%|▏         | 360/14596 [05:14<3:29:32,  1.13it/s]  3%|▎         | 368/14596 [05:20<3:19:10,  1.19it/s]  3%|▎         | 376/14596 [05:27<3:17:45,  1.20it/s]  3%|▎         | 384/14596 [05:34<3:27:52,  1.14it/s]  3%|▎         | 392/14596 [05:41<3:23:15,  1.16it/s]  3%|▎         | 400/14596 [05:47<3:19:22,  1.19it/s]  3%|▎         | 408/14596 [05:54<3:19:35,  1.18it/s]  3%|▎         | 416/14596 [06:02<3:25:16,  1.15it/s]  3%|▎         | 424/14596 [06:08<3:22:46,  1.16it/s]  3%|▎         | 432/14596 [06:15<3:20:04,  1.18it/s]  3%|▎         | 440/14596 [06:21<3:17:57,  1.19it/s]  3%|▎         | 448/14596 [06:29<3:26:23,  1.14it/s]  3%|▎         | 456/14596 [06:35<3:18:03,  1.19it/s]  3%|▎         | 464/14596 [06:41<3:15:10,  1.21it/s]  3%|▎         | 472/14596 [06:49<3:25:00,  1.15it/s]  3%|▎         | 480/14596 [06:56<3:23:31,  1.16it/s]  3%|▎         | 488/14596 [07:02<3:17:23,  1.19it/s]  3%|▎         | 496/14596 [07:09<3:16:07,  1.20it/s]  3%|▎         | 504/14596 [07:17<3:25:55,  1.14it/s]  4%|▎         | 512/14596 [07:23<3:21:47,  1.16it/s]  4%|▎         | 520/14596 [07:30<3:16:40,  1.19it/s]  4%|▎         | 528/14596 [07:36<3:16:09,  1.20it/s]  4%|▎         | 536/14596 [07:44<3:27:45,  1.13it/s]  4%|▎         | 544/14596 [07:51<3:21:11,  1.16it/s]  4%|▍         | 552/14596 [07:57<3:15:42,  1.20it/s]  4%|▍         | 560/14596 [08:04<3:19:40,  1.17it/s]  4%|▍         | 568/14596 [08:12<3:25:46,  1.14it/s]  4%|▍         | 576/14596 [08:18<3:19:18,  1.17it/s]  4%|▍         | 584/14596 [08:24<3:13:04,  1.21it/s]  4%|▍         | 592/14596 [08:32<3:21:39,  1.16it/s]  4%|▍         | 600/14596 [08:39<3:23:36,  1.15it/s]  4%|▍         | 608/14596 [08:45<3:17:41,  1.18it/s]  4%|▍         | 616/14596 [08:52<3:16:07,  1.19it/s]  4%|▍         | 624/14596 [08:59<3:24:35,  1.14it/s]  4%|▍         | 632/14596 [09:06<3:18:04,  1.17it/s]  4%|▍         | 640/14596 [09:12<3:16:28,  1.18it/s]  4%|▍         | 648/14596 [09:19<3:19:09,  1.17it/s]  4%|▍         | 656/14596 [09:26<3:14:27,  1.19it/s]  5%|▍         | 664/14596 [09:33<3:17:32,  1.18it/s]  5%|▍         | 672/14596 [09:39<3:10:19,  1.22it/s]  5%|▍         | 680/14596 [09:45<3:08:03,  1.23it/s]  5%|▍         | 688/14596 [09:53<3:18:10,  1.17it/s]  5%|▍         | 696/14596 [09:59<3:16:46,  1.18it/s]  5%|▍         | 704/14596 [10:06<3:11:18,  1.21it/s]  5%|▍         | 712/14596 [10:12<3:11:26,  1.21it/s]  5%|▍         | 720/14596 [10:20<3:18:18,  1.17it/s]  5%|▍         | 728/14596 [10:26<3:14:48,  1.19it/s]  5%|▌         | 736/14596 [10:33<3:12:39,  1.20it/s]  5%|▌         | 744/14596 [10:39<3:10:02,  1.21it/s]  5%|▌         | 752/14596 [10:47<3:18:02,  1.17it/s]  5%|▌         | 760/14596 [10:53<3:14:30,  1.19it/s]  5%|▌         | 768/14596 [11:00<3:12:46,  1.20it/s]  5%|▌         | 776/14596 [11:06<3:11:18,  1.20it/s]  5%|▌         | 784/14596 [11:13<3:14:48,  1.18it/s]  5%|▌         | 792/14596 [11:20<3:11:39,  1.20it/s]  5%|▌         | 800/14596 [11:26<3:11:51,  1.20it/s]  6%|▌         | 808/14596 [11:33<3:08:54,  1.22it/s]  6%|▌         | 816/14596 [11:40<3:16:10,  1.17it/s]  6%|▌         | 824/14596 [11:46<3:11:41,  1.20it/s]  6%|▌         | 832/14596 [11:53<3:10:49,  1.20it/s]  6%|▌         | 840/14596 [12:00<3:10:48,  1.20it/s]  6%|▌         | 848/14596 [12:07<3:13:54,  1.18it/s]  6%|▌         | 856/14596 [12:13<3:09:45,  1.21it/s]  6%|▌         | 864/14596 [12:20<3:10:27,  1.20it/s]  6%|▌         | 872/14596 [12:27<3:12:07,  1.19it/s]  6%|▌         | 880/14596 [12:34<3:15:53,  1.17it/s]  6%|▌         | 888/14596 [12:40<3:07:00,  1.22it/s]  6%|▌         | 896/14596 [12:46<3:05:51,  1.23it/s]  6%|▌         | 904/14596 [12:53<3:07:50,  1.21it/s]  6%|▌         | 912/14596 [12:59<3:03:42,  1.24it/s]  6%|▋         | 920/14596 [13:06<3:06:31,  1.22it/s]  6%|▋         | 928/14596 [13:12<3:07:22,  1.22it/s]  6%|▋         | 936/14596 [13:19<3:04:18,  1.24it/s]  6%|▋         | 944/14596 [13:25<3:01:48,  1.25it/s]  7%|▋         | 952/14596 [13:31<3:02:36,  1.25it/s]  7%|▋         | 960/14596 [13:39<3:15:52,  1.16it/s]  7%|▋         | 968/14596 [13:45<3:05:55,  1.22it/s]  7%|▋         | 976/14596 [13:51<3:00:43,  1.26it/s]  7%|▋         | 984/14596 [13:58<3:08:36,  1.20it/s]  7%|▋         | 992/14596 [14:04<3:01:51,  1.25it/s]  7%|▋         | 1000/14596 [14:12<3:11:39,  1.18it/s]  7%|▋         | 1008/14596 [14:18<3:03:50,  1.23it/s]  7%|▋         | 1016/14596 [14:24<3:04:17,  1.23it/s]  7%|▋         | 1024/14596 [14:32<3:13:47,  1.17it/s]  7%|▋         | 1032/14596 [14:36<2:55:07,  1.29it/s]  7%|▋         | 1040/14596 [14:45<3:11:14,  1.18it/s]  7%|▋         | 1048/14596 [14:51<3:04:19,  1.22it/s]  7%|▋         | 1056/14596 [14:57<3:05:59,  1.21it/s]  7%|▋         | 1064/14596 [15:05<3:14:08,  1.16it/s]  7%|▋         | 1072/14596 [15:10<2:56:44,  1.28it/s]  7%|▋         | 1080/14596 [15:18<3:12:14,  1.17it/s]  7%|▋         | 1088/14596 [15:24<3:07:01,  1.20it/s]  8%|▊         | 1096/14596 [15:31<3:06:24,  1.21it/s]  8%|▊         | 1104/14596 [15:38<3:14:00,  1.16it/s]  8%|▊         | 1112/14596 [15:44<3:02:53,  1.23it/s]  8%|▊         | 1120/14596 [15:51<3:11:20,  1.17it/s]  8%|▊         | 1128/14596 [15:58<3:07:24,  1.20it/s]  8%|▊         | 1136/14596 [16:04<3:03:31,  1.22it/s]  8%|▊         | 1144/14596 [16:13<3:21:26,  1.11it/s]  8%|▊         | 1152/14596 [16:18<3:05:34,  1.21it/s]  8%|▊         | 1160/14596 [16:25<3:06:14,  1.20it/s]  8%|▊         | 1168/14596 [16:31<3:06:50,  1.20it/s]  8%|▊         | 1176/14596 [16:38<3:05:56,  1.20it/s]  8%|▊         | 1184/14596 [16:46<3:17:04,  1.13it/s]  8%|▊         | 1192/14596 [16:52<3:11:47,  1.16it/s]  8%|▊         | 1200/14596 [16:59<3:05:40,  1.20it/s]  8%|▊         | 1208/14596 [17:07<3:19:32,  1.12it/s]  8%|▊         | 1216/14596 [17:12<3:02:29,  1.22it/s]  8%|▊         | 1224/14596 [17:19<3:06:47,  1.19it/s]  8%|▊         | 1232/14596 [17:26<3:04:57,  1.20it/s]  8%|▊         | 1240/14596 [17:32<2:59:44,  1.24it/s]  9%|▊         | 1248/14596 [17:40<3:16:34,  1.13it/s]  9%|▊         | 1256/14596 [17:46<3:03:28,  1.21it/s]  9%|▊         | 1264/14596 [17:52<3:01:58,  1.22it/s]  9%|▊         | 1272/14596 [17:58<2:59:05,  1.24it/s]  9%|▉         | 1280/14596 [18:04<2:55:45,  1.26it/s]  9%|▉         | 1288/14596 [18:12<3:10:40,  1.16it/s]  9%|▉         | 1296/14596 [18:19<3:07:24,  1.18it/s]  9%|▉         | 1304/14596 [18:25<3:01:21,  1.22it/s]  9%|▉         | 1312/14596 [18:31<2:56:51,  1.25it/s]  9%|▉         | 1320/14596 [18:37<2:57:04,  1.25it/s]  9%|▉         | 1328/14596 [18:45<3:06:28,  1.19it/s]  9%|▉         | 1336/14596 [18:52<3:05:45,  1.19it/s]  9%|▉         | 1344/14596 [18:58<2:58:49,  1.24it/s]  9%|▉         | 1352/14596 [19:04<2:59:27,  1.23it/s]  9%|▉         | 1360/14596 [19:12<3:07:33,  1.18it/s]  9%|▉         | 1368/14596 [19:18<3:05:53,  1.19it/s]  9%|▉         | 1376/14596 [19:25<3:03:45,  1.20it/s]  9%|▉         | 1384/14596 [19:31<3:01:31,  1.21it/s] 10%|▉         | 1392/14596 [19:39<3:11:28,  1.15it/s] 10%|▉         | 1400/14596 [19:45<3:02:48,  1.20it/s] 10%|▉         | 1408/14596 [19:52<3:02:55,  1.20it/s] 10%|▉         | 1416/14596 [19:59<3:10:15,  1.15it/s] 10%|▉         | 1424/14596 [20:06<3:06:58,  1.17it/s] 10%|▉         | 1432/14596 [20:12<3:04:58,  1.19it/s] 10%|▉         | 1440/14596 [20:19<3:04:30,  1.19it/s] 10%|▉         | 1448/14596 [20:26<3:06:22,  1.18it/s] 10%|▉         | 1456/14596 [20:33<3:06:59,  1.17it/s] 10%|█         | 1464/14596 [20:39<3:01:47,  1.20it/s] 10%|█         | 1472/14596 [20:45<2:56:22,  1.24it/s] 10%|█         | 1480/14596 [20:52<2:59:42,  1.22it/s] 10%|█         | 1488/14596 [20:58<2:59:20,  1.22it/s] 10%|█         | 1496/14596 [21:05<3:02:07,  1.20it/s] 10%|█         | 1504/14596 [21:12<3:01:22,  1.20it/s] 10%|█         | 1512/14596 [21:17<2:51:28,  1.27it/s] 10%|█         | 1520/14596 [21:24<2:52:38,  1.26it/s] 10%|█         | 1528/14596 [21:32<3:07:53,  1.16it/s] 11%|█         | 1536/14596 [21:38<2:58:29,  1.22it/s] 11%|█         | 1544/14596 [21:44<2:55:59,  1.24it/s] 11%|█         | 1552/14596 [21:51<3:02:03,  1.19it/s] 11%|█         | 1560/14596 [21:57<2:51:42,  1.27it/s] 11%|█         | 1568/14596 [22:05<3:06:51,  1.16it/s] 11%|█         | 1576/14596 [22:11<2:56:46,  1.23it/s] 11%|█         | 1584/14596 [22:17<2:53:35,  1.25it/s] 11%|█         | 1592/14596 [22:24<3:00:12,  1.20it/s] 11%|█         | 1600/14596 [22:30<2:55:18,  1.24it/s] 11%|█         | 1608/14596 [22:38<3:06:45,  1.16it/s] 11%|█         | 1616/14596 [22:44<2:59:04,  1.21it/s] 11%|█         | 1624/14596 [22:50<2:55:57,  1.23it/s] 11%|█         | 1632/14596 [22:58<3:03:44,  1.18it/s] 11%|█         | 1640/14596 [23:03<2:51:19,  1.26it/s] 11%|█▏        | 1648/14596 [23:11<3:04:12,  1.17it/s] 11%|█▏        | 1656/14596 [23:17<2:55:53,  1.23it/s] 11%|█▏        | 1664/14596 [23:23<2:55:40,  1.23it/s] 11%|█▏        | 1672/14596 [23:31<3:07:40,  1.15it/s] 12%|█▏        | 1680/14596 [23:36<2:51:19,  1.26it/s] 12%|█▏        | 1688/14596 [23:44<2:59:52,  1.20it/s] 12%|█▏        | 1696/14596 [23:50<2:54:03,  1.24it/s] 12%|█▏        | 1704/14596 [23:56<2:51:57,  1.25it/s] 12%|█▏        | 1712/14596 [24:03<3:00:56,  1.19it/s] 12%|█▏        | 1720/14596 [24:09<2:55:10,  1.23it/s] 12%|█▏        | 1728/14596 [24:16<2:56:19,  1.22it/s] 12%|█▏        | 1736/14596 [24:23<2:56:18,  1.22it/s] 12%|█▏        | 1744/14596 [24:29<2:51:58,  1.25it/s] 12%|█▏        | 1752/14596 [24:37<3:02:43,  1.17it/s] 12%|█▏        | 1760/14596 [24:42<2:53:57,  1.23it/s] 12%|█▏        | 1768/14596 [24:49<2:52:45,  1.24it/s] 12%|█▏        | 1776/14596 [24:57<3:04:37,  1.16it/s] 12%|█▏        | 1784/14596 [25:03<2:58:02,  1.20it/s] 12%|█▏        | 1792/14596 [25:09<2:57:40,  1.20it/s] 12%|█▏        | 1800/14596 [25:16<2:58:45,  1.19it/s] 12%|█▏        | 1808/14596 [25:23<3:00:34,  1.18it/s] 12%|█▏        | 1816/14596 [25:30<2:58:41,  1.19it/s] 12%|█▏        | 1824/14596 [25:36<2:59:03,  1.19it/s] 13%|█▎        | 1832/14596 [25:43<2:56:19,  1.21it/s] 13%|█▎        | 1840/14596 [25:51<3:04:40,  1.15it/s] 13%|█▎        | 1848/14596 [25:56<2:55:24,  1.21it/s] 13%|█▎        | 1856/14596 [26:03<2:54:13,  1.22it/s] 13%|█▎        | 1864/14596 [26:11<3:04:11,  1.15it/s] 13%|█▎        | 1872/14596 [26:17<2:59:11,  1.18it/s] 13%|█▎        | 1880/14596 [26:23<2:56:57,  1.20it/s] 13%|█▎        | 1888/14596 [26:30<2:56:37,  1.20it/s] 13%|█▎        | 1896/14596 [26:37<2:59:42,  1.18it/s] 13%|█▎        | 1904/14596 [26:44<2:59:19,  1.18it/s] 13%|█▎        | 1912/14596 [26:50<2:57:03,  1.19it/s] 13%|█▎        | 1920/14596 [26:57<2:57:02,  1.19it/s] 13%|█▎        | 1928/14596 [27:05<3:02:50,  1.15it/s] 13%|█▎        | 1936/14596 [27:11<2:56:28,  1.20it/s] 13%|█▎        | 1944/14596 [27:17<2:53:08,  1.22it/s] 13%|█▎        | 1952/14596 [27:25<3:04:29,  1.14it/s] 13%|█▎        | 1960/14596 [27:31<2:55:36,  1.20it/s] 13%|█▎        | 1968/14596 [27:37<2:54:31,  1.21it/s] 14%|█▎        | 1976/14596 [27:45<3:02:52,  1.15it/s] 14%|█▎        | 1984/14596 [27:52<2:58:07,  1.18it/s] 14%|█▎        | 1992/14596 [27:58<2:55:42,  1.20it/s] 14%|█▎        | 2000/14596 [28:05<2:55:54,  1.19it/s] 14%|█▍        | 2008/14596 [28:12<2:58:39,  1.17it/s] 14%|█▍        | 2016/14596 [28:19<2:57:58,  1.18it/s] 14%|█▍        | 2024/14596 [28:25<2:57:11,  1.18it/s] 14%|█▍        | 2032/14596 [28:32<2:53:28,  1.21it/s] 14%|█▍        | 2040/14596 [28:39<3:02:08,  1.15it/s] 14%|█▍        | 2048/14596 [28:45<2:53:24,  1.21it/s] 14%|█▍        | 2056/14596 [28:52<2:51:34,  1.22it/s] 14%|█▍        | 2064/14596 [29:00<3:03:18,  1.14it/s] 14%|█▍        | 2072/14596 [29:06<2:56:17,  1.18it/s] 14%|█▍        | 2080/14596 [29:12<2:54:31,  1.20it/s] 14%|█▍        | 2088/14596 [29:19<2:54:59,  1.19it/s] 14%|█▍        | 2096/14596 [29:27<3:00:47,  1.15it/s] 14%|█▍        | 2104/14596 [29:33<2:52:41,  1.21it/s] 14%|█▍        | 2112/14596 [29:39<2:50:17,  1.22it/s] 15%|█▍        | 2120/14596 [29:47<3:00:19,  1.15it/s] 15%|█▍        | 2128/14596 [29:53<2:57:04,  1.17it/s] 15%|█▍        | 2136/14596 [30:00<2:52:20,  1.21it/s] 15%|█▍        | 2144/14596 [30:06<2:51:30,  1.21it/s] 15%|█▍        | 2152/14596 [30:14<2:59:25,  1.16it/s] 15%|█▍        | 2160/14596 [30:20<2:51:11,  1.21it/s] 15%|█▍        | 2168/14596 [30:26<2:50:46,  1.21it/s] 15%|█▍        | 2176/14596 [30:34<3:00:39,  1.15it/s] 15%|█▍        | 2184/14596 [30:40<2:54:49,  1.18it/s] 15%|█▌        | 2192/14596 [30:47<2:50:56,  1.21it/s] 15%|█▌        | 2200/14596 [30:53<2:52:18,  1.20it/s] 15%|█▌        | 2208/14596 [31:01<2:58:00,  1.16it/s] 15%|█▌        | 2216/14596 [31:07<2:53:19,  1.19it/s] 15%|█▌        | 2224/14596 [31:13<2:50:29,  1.21it/s] 15%|█▌        | 2232/14596 [31:21<2:56:21,  1.17it/s] 15%|█▌        | 2240/14596 [31:28<2:57:22,  1.16it/s] 15%|█▌        | 2248/14596 [31:34<2:50:28,  1.21it/s] 15%|█▌        | 2256/14596 [31:40<2:47:18,  1.23it/s] 16%|█▌        | 2264/14596 [31:48<3:01:37,  1.13it/s] 16%|█▌        | 2272/14596 [31:54<2:53:20,  1.18it/s] 16%|█▌        | 2280/14596 [32:01<2:52:17,  1.19it/s] 16%|█▌        | 2288/14596 [32:10<3:06:21,  1.10it/s] 16%|█▌        | 2296/14596 [32:15<2:50:32,  1.20it/s] 16%|█▌        | 2304/14596 [32:22<2:51:21,  1.20it/s] 16%|█▌        | 2312/14596 [32:29<2:56:44,  1.16it/s] 16%|█▌        | 2320/14596 [32:35<2:51:53,  1.19it/s] 16%|█▌        | 2328/14596 [32:43<2:57:00,  1.16it/s] 16%|█▌        | 2336/14596 [32:50<2:55:38,  1.16it/s] 16%|█▌        | 2344/14596 [32:55<2:44:51,  1.24it/s] 16%|█▌        | 2352/14596 [33:04<3:03:10,  1.11it/s] 16%|█▌        | 2360/14596 [33:09<2:45:45,  1.23it/s] 16%|█▌        | 2368/14596 [33:16<2:47:29,  1.22it/s] 16%|█▋        | 2376/14596 [33:23<2:57:37,  1.15it/s] 16%|█▋        | 2384/14596 [33:29<2:47:19,  1.22it/s] 16%|█▋        | 2392/14596 [33:37<2:55:04,  1.16it/s] 16%|█▋        | 2400/14596 [33:44<2:54:24,  1.17it/s] 16%|█▋        | 2408/14596 [33:49<2:45:44,  1.23it/s] 17%|█▋        | 2416/14596 [33:57<2:56:07,  1.15it/s] 17%|█▋        | 2424/14596 [34:04<2:54:04,  1.17it/s] 17%|█▋        | 2432/14596 [34:10<2:49:01,  1.20it/s] 17%|█▋        | 2440/14596 [34:18<2:56:22,  1.15it/s] 17%|█▋        | 2448/14596 [34:24<2:52:32,  1.17it/s] 17%|█▋        | 2456/14596 [34:30<2:45:48,  1.22it/s] 17%|█▋        | 2464/14596 [34:38<2:57:49,  1.14it/s] 17%|█▋        | 2472/14596 [34:44<2:47:00,  1.21it/s] 17%|█▋        | 2480/14596 [34:50<2:44:57,  1.22it/s] 17%|█▋        | 2488/14596 [34:58<2:57:02,  1.14it/s] 17%|█▋        | 2496/14596 [35:04<2:47:19,  1.21it/s] 17%|█▋        | 2504/14596 [35:11<2:46:07,  1.21it/s] 17%|█▋        | 2512/14596 [35:18<2:50:40,  1.18it/s] 17%|█▋        | 2520/14596 [35:25<2:51:24,  1.17it/s] 17%|█▋        | 2528/14596 [35:31<2:45:28,  1.22it/s] 17%|█▋        | 2536/14596 [35:37<2:44:13,  1.22it/s] 17%|█▋        | 2544/14596 [35:45<2:52:18,  1.17it/s] 17%|█▋        | 2552/14596 [35:51<2:48:05,  1.19it/s] 18%|█▊        | 2560/14596 [35:57<2:44:56,  1.22it/s] 18%|█▊        | 2568/14596 [36:04<2:47:37,  1.20it/s] 18%|█▊        | 2576/14596 [36:12<2:51:53,  1.17it/s] 18%|█▊        | 2584/14596 [36:18<2:45:05,  1.21it/s] 18%|█▊        | 2592/14596 [36:24<2:42:36,  1.23it/s] 18%|█▊        | 2600/14596 [36:32<2:53:05,  1.16it/s] 18%|█▊        | 2608/14596 [36:38<2:48:22,  1.19it/s] 18%|█▊        | 2616/14596 [36:44<2:43:18,  1.22it/s] 18%|█▊        | 2624/14596 [36:51<2:45:45,  1.20it/s] 18%|█▊        | 2632/14596 [36:59<2:52:02,  1.16it/s] 18%|█▊        | 2640/14596 [37:05<2:44:50,  1.21it/s] 18%|█▊        | 2648/14596 [37:11<2:42:32,  1.23it/s] 18%|█▊        | 2656/14596 [37:19<2:53:58,  1.14it/s] 18%|█▊        | 2664/14596 [37:25<2:47:34,  1.19it/s] 18%|█▊        | 2672/14596 [37:31<2:44:04,  1.21it/s] 18%|█▊        | 2680/14596 [37:39<2:48:30,  1.18it/s] 18%|█▊        | 2688/14596 [37:46<2:50:17,  1.17it/s] 18%|█▊        | 2696/14596 [37:52<2:44:47,  1.20it/s] 19%|█▊        | 2704/14596 [37:58<2:42:04,  1.22it/s] 19%|█▊        | 2712/14596 [38:06<2:51:47,  1.15it/s] 19%|█▊        | 2720/14596 [38:12<2:45:15,  1.20it/s] 19%|█▊        | 2728/14596 [38:18<2:41:35,  1.22it/s] 19%|█▊        | 2736/14596 [38:25<2:45:17,  1.20it/s] 19%|█▉        | 2744/14596 [38:33<2:50:45,  1.16it/s] 19%|█▉        | 2752/14596 [38:39<2:43:04,  1.21it/s] 19%|█▉        | 2760/14596 [38:45<2:40:33,  1.23it/s] 19%|█▉        | 2768/14596 [38:53<2:53:18,  1.14it/s] 19%|█▉        | 2776/14596 [38:59<2:44:06,  1.20it/s] 19%|█▉        | 2784/14596 [39:05<2:41:05,  1.22it/s] 19%|█▉        | 2792/14596 [39:13<2:49:24,  1.16it/s] 19%|█▉        | 2800/14596 [39:19<2:45:02,  1.19it/s] 19%|█▉        | 2808/14596 [39:26<2:41:35,  1.22it/s] 19%|█▉        | 2816/14596 [39:32<2:43:01,  1.20it/s] 19%|█▉        | 2824/14596 [39:40<2:48:13,  1.17it/s] 19%|█▉        | 2832/14596 [39:46<2:42:41,  1.21it/s] 19%|█▉        | 2840/14596 [39:52<2:39:13,  1.23it/s] 20%|█▉        | 2848/14596 [39:59<2:43:24,  1.20it/s] 20%|█▉        | 2856/14596 [40:06<2:45:28,  1.18it/s] 20%|█▉        | 2864/14596 [40:12<2:41:21,  1.21it/s] 20%|█▉        | 2872/14596 [40:18<2:37:42,  1.24it/s] 20%|█▉        | 2880/14596 [40:26<2:48:41,  1.16it/s] 20%|█▉        | 2888/14596 [40:32<2:40:19,  1.22it/s] 20%|█▉        | 2896/14596 [40:38<2:38:47,  1.23it/s] 20%|█▉        | 2904/14596 [40:47<2:50:07,  1.15it/s] 20%|█▉        | 2912/14596 [40:52<2:41:37,  1.20it/s] 20%|██        | 2920/14596 [40:59<2:40:09,  1.22it/s] 20%|██        | 2928/14596 [41:06<2:43:22,  1.19it/s] 20%|██        | 2936/14596 [41:13<2:44:19,  1.18it/s] 20%|██        | 2944/14596 [41:19<2:37:05,  1.24it/s] 20%|██        | 2952/14596 [41:25<2:38:00,  1.23it/s] 20%|██        | 2960/14596 [41:33<2:47:39,  1.16it/s] 20%|██        | 2968/14596 [41:39<2:39:35,  1.21it/s] 20%|██        | 2976/14596 [41:45<2:39:15,  1.22it/s] 20%|██        | 2984/14596 [41:53<2:45:19,  1.17it/s] 20%|██        | 2992/14596 [41:59<2:43:09,  1.19it/s] 21%|██        | 3000/14596 [42:06<2:38:37,  1.22it/s] 21%|██        | 3008/14596 [42:12<2:37:23,  1.23it/s] 21%|██        | 3016/14596 [42:20<2:46:20,  1.16it/s] 21%|██        | 3024/14596 [42:25<2:36:30,  1.23it/s] 21%|██        | 3032/14596 [42:32<2:38:25,  1.22it/s] 21%|██        | 3040/14596 [42:40<2:46:35,  1.16it/s] 21%|██        | 3048/14596 [42:46<2:40:21,  1.20it/s] 21%|██        | 3056/14596 [42:52<2:37:45,  1.22it/s] 21%|██        | 3064/14596 [42:59<2:40:19,  1.20it/s] 21%|██        | 3072/14596 [43:06<2:43:17,  1.18it/s] 21%|██        | 3080/14596 [43:12<2:37:07,  1.22it/s] 21%|██        | 3088/14596 [43:19<2:35:51,  1.23it/s] 21%|██        | 3096/14596 [43:27<2:48:24,  1.14it/s] 21%|██▏       | 3104/14596 [43:32<2:37:48,  1.21it/s] 21%|██▏       | 3112/14596 [43:39<2:37:15,  1.22it/s] 21%|██▏       | 3120/14596 [43:47<2:51:20,  1.12it/s] 21%|██▏       | 3128/14596 [43:52<2:34:27,  1.24it/s] 21%|██▏       | 3136/14596 [43:59<2:39:42,  1.20it/s] 22%|██▏       | 3144/14596 [44:07<2:44:39,  1.16it/s] 22%|██▏       | 3152/14596 [44:13<2:39:19,  1.20it/s] 22%|██▏       | 3160/14596 [44:19<2:36:49,  1.22it/s] 22%|██▏       | 3168/14596 [44:26<2:35:26,  1.23it/s] 22%|██▏       | 3176/14596 [44:33<2:43:32,  1.16it/s] 22%|██▏       | 3184/14596 [44:39<2:34:16,  1.23it/s] 22%|██▏       | 3192/14596 [44:46<2:34:50,  1.23it/s] 22%|██▏       | 3200/14596 [44:53<2:43:50,  1.16it/s] 22%|██▏       | 3208/14596 [44:59<2:35:42,  1.22it/s] 22%|██▏       | 3216/14596 [45:06<2:35:41,  1.22it/s] 22%|██▏       | 3224/14596 [45:13<2:38:44,  1.19it/s] 22%|██▏       | 3232/14596 [45:20<2:40:40,  1.18it/s] 22%|██▏       | 3240/14596 [45:26<2:36:44,  1.21it/s] 22%|██▏       | 3248/14596 [45:32<2:33:50,  1.23it/s] 22%|██▏       | 3256/14596 [45:40<2:44:08,  1.15it/s] 22%|██▏       | 3264/14596 [45:46<2:36:33,  1.21it/s] 22%|██▏       | 3272/14596 [45:52<2:33:13,  1.23it/s] 22%|██▏       | 3280/14596 [46:01<2:45:44,  1.14it/s] 23%|██▎       | 3288/14596 [46:05<2:30:04,  1.26it/s] 23%|██▎       | 3296/14596 [46:13<2:34:55,  1.22it/s] 23%|██▎       | 3304/14596 [46:19<2:36:13,  1.20it/s] 23%|██▎       | 3312/14596 [46:24<2:24:42,  1.30it/s] 23%|██▎       | 3320/14596 [46:33<2:40:49,  1.17it/s] 23%|██▎       | 3328/14596 [46:38<2:28:44,  1.26it/s] 23%|██▎       | 3336/14596 [46:44<2:29:44,  1.25it/s] 23%|██▎       | 3344/14596 [46:53<2:43:06,  1.15it/s] 23%|██▎       | 3352/14596 [46:57<2:27:10,  1.27it/s] 23%|██▎       | 3360/14596 [47:04<2:31:04,  1.24it/s] 23%|██▎       | 3368/14596 [47:11<2:30:31,  1.24it/s] 23%|██▎       | 3376/14596 [47:16<2:25:31,  1.29it/s] 23%|██▎       | 3384/14596 [47:24<2:37:19,  1.19it/s] 23%|██▎       | 3392/14596 [47:30<2:28:03,  1.26it/s] 23%|██▎       | 3400/14596 [47:36<2:28:49,  1.25it/s] 23%|██▎       | 3408/14596 [47:44<2:37:20,  1.19it/s] 23%|██▎       | 3416/14596 [47:50<2:29:58,  1.24it/s] 23%|██▎       | 3424/14596 [47:56<2:30:02,  1.24it/s] 24%|██▎       | 3432/14596 [48:03<2:31:36,  1.23it/s] 24%|██▎       | 3440/14596 [48:10<2:36:12,  1.19it/s] 24%|██▎       | 3448/14596 [48:16<2:29:36,  1.24it/s] 24%|██▎       | 3456/14596 [48:22<2:29:41,  1.24it/s] 24%|██▎       | 3464/14596 [48:30<2:40:56,  1.15it/s] 24%|██▍       | 3472/14596 [48:35<2:29:00,  1.24it/s] 24%|██▍       | 3480/14596 [48:42<2:31:59,  1.22it/s] 24%|██▍       | 3488/14596 [48:50<2:39:02,  1.16it/s] 24%|██▍       | 3496/14596 [48:56<2:30:27,  1.23it/s] 24%|██▍       | 3504/14596 [49:02<2:32:22,  1.21it/s] 24%|██▍       | 3512/14596 [49:08<2:28:30,  1.24it/s] 24%|██▍       | 3520/14596 [49:14<2:21:58,  1.30it/s] 24%|██▍       | 3528/14596 [49:22<2:38:24,  1.16it/s] 24%|██▍       | 3536/14596 [49:27<2:24:11,  1.28it/s] 24%|██▍       | 3544/14596 [49:34<2:26:41,  1.26it/s] 24%|██▍       | 3552/14596 [49:41<2:34:30,  1.19it/s] 24%|██▍       | 3560/14596 [49:47<2:28:21,  1.24it/s] 24%|██▍       | 3568/14596 [49:54<2:30:13,  1.22it/s] 24%|██▍       | 3576/14596 [50:00<2:25:30,  1.26it/s] 25%|██▍       | 3584/14596 [50:07<2:28:19,  1.24it/s] 25%|██▍       | 3592/14596 [50:14<2:36:22,  1.17it/s] 25%|██▍       | 3600/14596 [50:20<2:29:46,  1.22it/s] 25%|██▍       | 3608/14596 [50:26<2:26:23,  1.25it/s] 25%|██▍       | 3616/14596 [50:34<2:36:04,  1.17it/s] 25%|██▍       | 3624/14596 [50:40<2:29:49,  1.22it/s] 25%|██▍       | 3632/14596 [50:46<2:29:02,  1.23it/s] 25%|██▍       | 3640/14596 [50:54<2:33:52,  1.19it/s] 25%|██▍       | 3648/14596 [51:00<2:33:17,  1.19it/s] 25%|██▌       | 3656/14596 [51:07<2:30:01,  1.22it/s] 25%|██▌       | 3664/14596 [51:13<2:29:22,  1.22it/s] 25%|██▌       | 3672/14596 [51:21<2:37:36,  1.16it/s] 25%|██▌       | 3680/14596 [51:27<2:33:28,  1.19it/s] 25%|██▌       | 3688/14596 [51:33<2:29:29,  1.22it/s] 25%|██▌       | 3696/14596 [51:41<2:38:16,  1.15it/s] 25%|██▌       | 3704/14596 [51:47<2:32:08,  1.19it/s] 25%|██▌       | 3712/14596 [51:53<2:27:27,  1.23it/s] 25%|██▌       | 3720/14596 [52:01<2:37:45,  1.15it/s] 26%|██▌       | 3728/14596 [52:07<2:29:27,  1.21it/s] 26%|██▌       | 3736/14596 [52:13<2:26:16,  1.24it/s] 26%|██▌       | 3744/14596 [52:22<2:39:21,  1.13it/s] 26%|██▌       | 3752/14596 [52:27<2:25:31,  1.24it/s] 26%|██▌       | 3760/14596 [52:34<2:28:59,  1.21it/s] 26%|██▌       | 3768/14596 [52:41<2:35:40,  1.16it/s] 26%|██▌       | 3776/14596 [52:47<2:29:38,  1.21it/s] 26%|██▌       | 3784/14596 [52:54<2:27:20,  1.22it/s] 26%|██▌       | 3792/14596 [53:00<2:27:38,  1.22it/s] 26%|██▌       | 3800/14596 [53:08<2:34:10,  1.17it/s] 26%|██▌       | 3808/14596 [53:14<2:25:58,  1.23it/s] 26%|██▌       | 3816/14596 [53:20<2:26:16,  1.23it/s] 26%|██▌       | 3824/14596 [53:28<2:38:38,  1.13it/s] 26%|██▋       | 3832/14596 [53:34<2:28:08,  1.21it/s] 26%|██▋       | 3840/14596 [53:41<2:29:36,  1.20it/s] 26%|██▋       | 3848/14596 [53:49<2:42:00,  1.11it/s] 26%|██▋       | 3856/14596 [53:54<2:26:22,  1.22it/s] 26%|██▋       | 3864/14596 [54:01<2:29:56,  1.19it/s] 27%|██▋       | 3872/14596 [54:10<2:39:33,  1.12it/s] 27%|██▋       | 3880/14596 [54:15<2:27:08,  1.21it/s] 27%|██▋       | 3888/14596 [54:22<2:30:16,  1.19it/s] 27%|██▋       | 3896/14596 [54:29<2:32:42,  1.17it/s] 27%|██▋       | 3904/14596 [54:35<2:24:32,  1.23it/s] 27%|██▋       | 3912/14596 [54:43<2:35:14,  1.15it/s] 27%|██▋       | 3920/14596 [54:49<2:32:23,  1.17it/s] 27%|██▋       | 3928/14596 [54:55<2:26:42,  1.21it/s] 27%|██▋       | 3936/14596 [55:03<2:31:49,  1.17it/s] 27%|██▋       | 3944/14596 [55:09<2:28:09,  1.20it/s] 27%|██▋       | 3952/14596 [55:15<2:23:19,  1.24it/s] 27%|██▋       | 3960/14596 [55:22<2:29:20,  1.19it/s] 27%|██▋       | 3968/14596 [55:29<2:26:05,  1.21it/s] 27%|██▋       | 3976/14596 [55:35<2:21:31,  1.25it/s] 27%|██▋       | 3984/14596 [55:42<2:30:38,  1.17it/s] 27%|██▋       | 3992/14596 [55:48<2:23:37,  1.23it/s] 27%|██▋       | 4000/14596 [55:55<2:23:05,  1.23it/s] 27%|██▋       | 4008/14596 [56:03<2:33:23,  1.15it/s] 28%|██▊       | 4016/14596 [56:08<2:22:08,  1.24it/s] 28%|██▊       | 4024/14596 [56:15<2:25:17,  1.21it/s] 28%|██▊       | 4032/14596 [56:22<2:30:19,  1.17it/s] 28%|██▊       | 4040/14596 [56:28<2:20:43,  1.25it/s] 28%|██▊       | 4048/14596 [56:35<2:27:31,  1.19it/s] 28%|██▊       | 4056/14596 [56:42<2:26:07,  1.20it/s] 28%|██▊       | 4064/14596 [56:47<2:19:45,  1.26it/s] 28%|██▊       | 4072/14596 [56:56<2:31:51,  1.16it/s] 28%|██▊       | 4080/14596 [57:02<2:29:11,  1.17it/s] 28%|██▊       | 4088/14596 [57:09<2:27:32,  1.19it/s] 28%|██▊       | 4096/14596 [57:16<2:28:43,  1.18it/s] 28%|██▊       | 4104/14596 [57:22<2:28:06,  1.18it/s] 28%|██▊       | 4112/14596 [57:30<2:32:03,  1.15it/s] 28%|██▊       | 4120/14596 [57:36<2:26:27,  1.19it/s] 28%|██▊       | 4128/14596 [57:42<2:24:13,  1.21it/s] 28%|██▊       | 4136/14596 [57:50<2:31:55,  1.15it/s] 28%|██▊       | 4144/14596 [57:56<2:24:57,  1.20it/s] 28%|██▊       | 4152/14596 [58:02<2:21:41,  1.23it/s] 29%|██▊       | 4160/14596 [58:10<2:32:39,  1.14it/s] 29%|██▊       | 4168/14596 [58:16<2:22:30,  1.22it/s] 29%|██▊       | 4176/14596 [58:22<2:21:29,  1.23it/s] 29%|██▊       | 4184/14596 [58:31<2:32:43,  1.14it/s] 29%|██▊       | 4192/14596 [58:36<2:21:47,  1.22it/s] 29%|██▉       | 4200/14596 [58:43<2:22:22,  1.22it/s] 29%|██▉       | 4208/14596 [58:50<2:29:34,  1.16it/s] 29%|██▉       | 4216/14596 [58:56<2:22:16,  1.22it/s] 29%|██▉       | 4224/14596 [59:02<2:20:58,  1.23it/s] 29%|██▉       | 4232/14596 [59:10<2:25:49,  1.18it/s] 29%|██▉       | 4240/14596 [59:16<2:25:15,  1.19it/s] 29%|██▉       | 4248/14596 [59:22<2:20:17,  1.23it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 29%|██▉       | 4256/14596 [59:29<2:18:32,  1.24it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 29%|██▉       | 4264/14596 [59:36<2:27:31,  1.17it/s] 29%|██▉       | 4272/14596 [59:43<2:25:50,  1.18it/s] 29%|██▉       | 4280/14596 [59:49<2:21:30,  1.21it/s] 29%|██▉       | 4288/14596 [59:56<2:22:25,  1.21it/s] 29%|██▉       | 4296/14596 [1:00:03<2:23:51,  1.19it/s] 29%|██▉       | 4304/14596 [1:00:09<2:20:11,  1.22it/s] 30%|██▉       | 4312/14596 [1:00:15<2:19:46,  1.23it/s] 30%|██▉       | 4320/14596 [1:00:23<2:25:23,  1.18it/s] 30%|██▉       | 4328/14596 [1:00:29<2:20:47,  1.22it/s] 30%|██▉       | 4336/14596 [1:00:35<2:18:58,  1.23it/s] 30%|██▉       | 4344/14596 [1:00:43<2:25:20,  1.18it/s] 30%|██▉       | 4352/14596 [1:00:49<2:21:19,  1.21it/s] 30%|██▉       | 4360/14596 [1:00:55<2:17:00,  1.25it/s] 30%|██▉       | 4368/14596 [1:01:02<2:23:50,  1.19it/s] 30%|██▉       | 4376/14596 [1:01:09<2:19:33,  1.22it/s] 30%|███       | 4384/14596 [1:01:15<2:15:38,  1.25it/s] 30%|███       | 4392/14596 [1:01:22<2:22:05,  1.20it/s] 30%|███       | 4400/14596 [1:01:28<2:20:53,  1.21it/s] 30%|███       | 4408/14596 [1:01:34<2:16:54,  1.24it/s] 30%|███       | 4416/14596 [1:01:43<2:28:48,  1.14it/s] 30%|███       | 4424/14596 [1:01:48<2:18:29,  1.22it/s] 30%|███       | 4432/14596 [1:01:55<2:18:59,  1.22it/s] 30%|███       | 4440/14596 [1:02:03<2:31:02,  1.12it/s] 30%|███       | 4448/14596 [1:02:09<2:18:28,  1.22it/s] 31%|███       | 4456/14596 [1:02:15<2:18:43,  1.22it/s] 31%|███       | 4464/14596 [1:02:24<2:32:00,  1.11it/s] 31%|███       | 4472/14596 [1:02:29<2:18:33,  1.22it/s] 31%|███       | 4480/14596 [1:02:35<2:16:16,  1.24it/s] 31%|███       | 4488/14596 [1:02:44<2:29:44,  1.13it/s] 31%|███       | 4496/14596 [1:02:50<2:23:37,  1.17it/s] 31%|███       | 4504/14596 [1:02:56<2:22:03,  1.18it/s] 31%|███       | 4512/14596 [1:03:03<2:21:02,  1.19it/s] 31%|███       | 4520/14596 [1:03:10<2:21:38,  1.19it/s] 31%|███       | 4528/14596 [1:03:17<2:23:38,  1.17it/s] 31%|███       | 4536/14596 [1:03:24<2:23:03,  1.17it/s] 31%|███       | 4544/14596 [1:03:31<2:23:31,  1.17it/s] 31%|███       | 4552/14596 [1:03:37<2:21:29,  1.18it/s] 31%|███       | 4560/14596 [1:03:44<2:20:40,  1.19it/s] 31%|███▏      | 4568/14596 [1:03:50<2:17:43,  1.21it/s] 31%|███▏      | 4576/14596 [1:03:57<2:17:20,  1.22it/s] 31%|███▏      | 4584/14596 [1:04:04<2:24:26,  1.16it/s] 31%|███▏      | 4592/14596 [1:04:11<2:23:20,  1.16it/s] 32%|███▏      | 4600/14596 [1:04:18<2:20:29,  1.19it/s] 32%|███▏      | 4608/14596 [1:04:24<2:19:01,  1.20it/s] 32%|███▏      | 4616/14596 [1:04:32<2:22:53,  1.16it/s] 32%|███▏      | 4624/14596 [1:04:38<2:17:34,  1.21it/s] 32%|███▏      | 4632/14596 [1:04:44<2:18:00,  1.20it/s] 32%|███▏      | 4640/14596 [1:04:53<2:27:51,  1.12it/s] 32%|███▏      | 4648/14596 [1:04:57<2:13:43,  1.24it/s] 32%|███▏      | 4656/14596 [1:05:04<2:15:15,  1.22it/s] 32%|███▏      | 4664/14596 [1:05:13<2:28:00,  1.12it/s] 32%|███▏      | 4672/14596 [1:05:18<2:15:41,  1.22it/s] 32%|███▏      | 4680/14596 [1:05:24<2:13:29,  1.24it/s] 32%|███▏      | 4688/14596 [1:05:33<2:25:37,  1.13it/s] 32%|███▏      | 4696/14596 [1:05:39<2:21:49,  1.16it/s] 32%|███▏      | 4704/14596 [1:05:46<2:19:52,  1.18it/s] 32%|███▏      | 4712/14596 [1:05:52<2:20:05,  1.18it/s] 32%|███▏      | 4720/14596 [1:06:00<2:22:50,  1.15it/s] 32%|███▏      | 4728/14596 [1:06:06<2:17:39,  1.19it/s] 32%|███▏      | 4736/14596 [1:06:12<2:16:06,  1.21it/s] 33%|███▎      | 4744/14596 [1:06:19<2:18:18,  1.19it/s] 33%|███▎      | 4752/14596 [1:06:26<2:19:01,  1.18it/s] 33%|███▎      | 4760/14596 [1:06:32<2:15:49,  1.21it/s] 33%|███▎      | 4768/14596 [1:06:39<2:15:50,  1.21it/s] 33%|███▎      | 4776/14596 [1:06:46<2:18:36,  1.18it/s] 33%|███▎      | 4784/14596 [1:06:53<2:17:19,  1.19it/s] 33%|███▎      | 4792/14596 [1:06:59<2:16:42,  1.20it/s] 33%|███▎      | 4800/14596 [1:07:06<2:14:25,  1.21it/s] 33%|███▎      | 4808/14596 [1:07:13<2:19:08,  1.17it/s] 33%|███▎      | 4816/14596 [1:07:19<2:14:48,  1.21it/s] 33%|███▎      | 4824/14596 [1:07:27<2:20:13,  1.16it/s] 33%|███▎      | 4832/14596 [1:07:33<2:13:04,  1.22it/s] 33%|███▎      | 4840/14596 [1:07:39<2:11:07,  1.24it/s] 33%|███▎      | 4848/14596 [1:07:47<2:20:25,  1.16it/s] 33%|███▎      | 4856/14596 [1:07:53<2:19:15,  1.17it/s] 33%|███▎      | 4864/14596 [1:07:59<2:12:52,  1.22it/s] 33%|███▎      | 4872/14596 [1:08:06<2:15:18,  1.20it/s] 33%|███▎      | 4880/14596 [1:08:13<2:18:07,  1.17it/s] 33%|███▎      | 4888/14596 [1:08:20<2:17:59,  1.17it/s] 34%|███▎      | 4896/14596 [1:08:27<2:17:16,  1.18it/s] 34%|███▎      | 4904/14596 [1:08:34<2:15:52,  1.19it/s] 34%|███▎      | 4912/14596 [1:08:40<2:15:40,  1.19it/s] 34%|███▎      | 4920/14596 [1:08:46<2:11:57,  1.22it/s] 34%|███▍      | 4928/14596 [1:08:53<2:11:54,  1.22it/s] 34%|███▍      | 4936/14596 [1:09:00<2:13:58,  1.20it/s] 34%|███▍      | 4944/14596 [1:09:06<2:11:44,  1.22it/s] 34%|███▍      | 4952/14596 [1:09:13<2:10:58,  1.23it/s] 34%|███▍      | 4960/14596 [1:09:19<2:11:57,  1.22it/s] 34%|███▍      | 4968/14596 [1:09:26<2:12:31,  1.21it/s] 34%|███▍      | 4976/14596 [1:09:32<2:10:05,  1.23it/s] 34%|███▍      | 4984/14596 [1:09:39<2:09:51,  1.23it/s] 34%|███▍      | 4992/14596 [1:09:46<2:11:52,  1.21it/s] 34%|███▍      | 5000/14596 [1:09:52<2:09:58,  1.23it/s] 34%|███▍      | 5008/14596 [1:09:58<2:08:58,  1.24it/s] 34%|███▍      | 5016/14596 [1:10:04<2:07:33,  1.25it/s] 34%|███▍      | 5024/14596 [1:10:11<2:10:58,  1.22it/s] 34%|███▍      | 5032/14596 [1:10:18<2:10:27,  1.22it/s] 35%|███▍      | 5040/14596 [1:10:25<2:10:57,  1.22it/s] 35%|███▍      | 5048/14596 [1:10:31<2:11:26,  1.21it/s] 35%|███▍      | 5056/14596 [1:10:38<2:11:04,  1.21it/s] 35%|███▍      | 5064/14596 [1:10:45<2:11:33,  1.21it/s] 35%|███▍      | 5072/14596 [1:10:51<2:08:50,  1.23it/s] 35%|███▍      | 5080/14596 [1:10:58<2:11:07,  1.21it/s] 35%|███▍      | 5088/14596 [1:11:04<2:11:56,  1.20it/s] 35%|███▍      | 5096/14596 [1:11:11<2:08:59,  1.23it/s] 35%|███▍      | 5104/14596 [1:11:17<2:08:37,  1.23it/s] 35%|███▌      | 5112/14596 [1:11:24<2:12:59,  1.19it/s] 35%|███▌      | 5120/14596 [1:11:32<2:16:43,  1.16it/s] 35%|███▌      | 5128/14596 [1:11:37<2:07:46,  1.24it/s] 35%|███▌      | 5136/14596 [1:11:44<2:09:44,  1.22it/s] 35%|███▌      | 5144/14596 [1:11:51<2:12:58,  1.18it/s] 35%|███▌      | 5152/14596 [1:11:58<2:15:40,  1.16it/s] 35%|███▌      | 5160/14596 [1:12:04<2:09:45,  1.21it/s] 35%|███▌      | 5168/14596 [1:12:11<2:11:37,  1.19it/s] 35%|███▌      | 5176/14596 [1:12:18<2:11:45,  1.19it/s] 36%|███▌      | 5184/14596 [1:12:25<2:12:37,  1.18it/s] 36%|███▌      | 5192/14596 [1:12:32<2:12:52,  1.18it/s] 36%|███▌      | 5200/14596 [1:12:38<2:09:22,  1.21it/s] 36%|███▌      | 5208/14596 [1:12:45<2:11:05,  1.19it/s] 36%|███▌      | 5216/14596 [1:12:51<2:08:49,  1.21it/s] 36%|███▌      | 5224/14596 [1:12:58<2:10:47,  1.19it/s] 36%|███▌      | 5232/14596 [1:13:04<2:08:19,  1.22it/s] 36%|███▌      | 5240/14596 [1:13:11<2:09:45,  1.20it/s] 36%|███▌      | 5248/14596 [1:13:18<2:08:23,  1.21it/s] 36%|███▌      | 5256/14596 [1:13:24<2:10:04,  1.20it/s] 36%|███▌      | 5264/14596 [1:13:31<2:06:59,  1.22it/s] 36%|███▌      | 5272/14596 [1:13:37<2:08:42,  1.21it/s] 36%|███▌      | 5280/14596 [1:13:44<2:07:17,  1.22it/s] 36%|███▌      | 5288/14596 [1:13:51<2:11:12,  1.18it/s] 36%|███▋      | 5296/14596 [1:13:57<2:07:42,  1.21it/s] 36%|███▋      | 5304/14596 [1:14:04<2:09:21,  1.20it/s] 36%|███▋      | 5312/14596 [1:14:10<2:06:11,  1.23it/s] 36%|███▋      | 5320/14596 [1:14:18<2:10:51,  1.18it/s] 37%|███▋      | 5328/14596 [1:14:24<2:05:59,  1.23it/s] 37%|███▋      | 5336/14596 [1:14:31<2:07:57,  1.21it/s] 37%|███▋      | 5344/14596 [1:14:37<2:06:30,  1.22it/s] 37%|███▋      | 5352/14596 [1:14:44<2:09:59,  1.19it/s] 37%|███▋      | 5360/14596 [1:14:50<2:03:23,  1.25it/s] 37%|███▋      | 5368/14596 [1:14:56<2:04:15,  1.24it/s] 37%|███▋      | 5376/14596 [1:15:03<2:06:01,  1.22it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 37%|███▋      | 5384/14596 [1:15:10<2:10:26,  1.18it/s] 37%|███▋      | 5392/14596 [1:15:16<2:01:26,  1.26it/s] 37%|███▋      | 5400/14596 [1:15:22<2:01:47,  1.26it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 37%|███▋      | 5408/14596 [1:15:29<2:04:39,  1.23it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 37%|███▋      | 5416/14596 [1:15:37<2:13:01,  1.15it/s] 37%|███▋      | 5424/14596 [1:15:43<2:08:39,  1.19it/s] 37%|███▋      | 5432/14596 [1:15:50<2:06:25,  1.21it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 37%|███▋      | 5440/14596 [1:15:56<2:04:52,  1.22it/s] 37%|███▋      | 5448/14596 [1:16:03<2:05:02,  1.22it/s] 37%|███▋      | 5456/14596 [1:16:09<2:05:47,  1.21it/s] 37%|███▋      | 5464/14596 [1:16:15<2:01:57,  1.25it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 37%|███▋      | 5472/14596 [1:16:22<2:04:48,  1.22it/s] 38%|███▊      | 5480/14596 [1:16:28<2:03:03,  1.23it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 38%|███▊      | 5488/14596 [1:16:36<2:06:40,  1.20it/s] 38%|███▊      | 5496/14596 [1:16:42<2:04:01,  1.22it/s] 38%|███▊      | 5504/14596 [1:16:48<2:04:21,  1.22it/s] 38%|███▊      | 5512/14596 [1:16:55<2:02:42,  1.23it/s] 38%|███▊      | 5520/14596 [1:17:02<2:06:15,  1.20it/s] 38%|███▊      | 5528/14596 [1:17:09<2:06:39,  1.19it/s] 38%|███▊      | 5536/14596 [1:17:15<2:03:18,  1.22it/s] 38%|███▊      | 5544/14596 [1:17:22<2:06:55,  1.19it/s] 38%|███▊      | 5552/14596 [1:17:28<2:00:39,  1.25it/s] 38%|███▊      | 5560/14596 [1:17:35<2:04:00,  1.21it/s] 38%|███▊      | 5568/14596 [1:17:41<2:02:30,  1.23it/s] 38%|███▊      | 5576/14596 [1:17:48<2:08:16,  1.17it/s] 38%|███▊      | 5584/14596 [1:17:55<2:03:55,  1.21it/s] 38%|███▊      | 5592/14596 [1:18:01<2:02:19,  1.23it/s] 38%|███▊      | 5600/14596 [1:18:07<2:01:50,  1.23it/s] 38%|███▊      | 5608/14596 [1:18:15<2:05:59,  1.19it/s] 38%|███▊      | 5616/14596 [1:18:21<2:04:17,  1.20it/s] 39%|███▊      | 5624/14596 [1:18:27<2:01:23,  1.23it/s] 39%|███▊      | 5632/14596 [1:18:34<2:02:00,  1.22it/s] 39%|███▊      | 5640/14596 [1:18:41<2:03:48,  1.21it/s] 39%|███▊      | 5648/14596 [1:18:48<2:05:56,  1.18it/s] 39%|███▉      | 5656/14596 [1:18:54<2:01:46,  1.22it/s] 39%|███▉      | 5664/14596 [1:19:01<2:03:20,  1.21it/s] 39%|███▉      | 5672/14596 [1:19:07<2:02:44,  1.21it/s] 39%|███▉      | 5680/14596 [1:19:13<1:59:56,  1.24it/s] 39%|███▉      | 5688/14596 [1:19:20<2:02:46,  1.21it/s] 39%|███▉      | 5696/14596 [1:19:26<2:00:07,  1.23it/s] 39%|███▉      | 5704/14596 [1:19:33<2:02:35,  1.21it/s] 39%|███▉      | 5712/14596 [1:19:39<1:59:48,  1.24it/s] 39%|███▉      | 5720/14596 [1:19:46<2:00:49,  1.22it/s] 39%|███▉      | 5728/14596 [1:19:53<2:00:22,  1.23it/s] 39%|███▉      | 5736/14596 [1:19:59<1:58:05,  1.25it/s] 39%|███▉      | 5744/14596 [1:20:06<2:01:00,  1.22it/s] 39%|███▉      | 5752/14596 [1:20:12<1:57:32,  1.25it/s] 39%|███▉      | 5760/14596 [1:20:18<1:58:54,  1.24it/s] 40%|███▉      | 5768/14596 [1:20:25<1:57:40,  1.25it/s] 40%|███▉      | 5776/14596 [1:20:31<2:00:31,  1.22it/s] 40%|███▉      | 5784/14596 [1:20:37<1:55:01,  1.28it/s] 40%|███▉      | 5792/14596 [1:20:44<1:56:32,  1.26it/s] 40%|███▉      | 5800/14596 [1:20:50<1:54:44,  1.28it/s] 40%|███▉      | 5808/14596 [1:20:56<1:56:15,  1.26it/s] 40%|███▉      | 5816/14596 [1:21:02<1:54:24,  1.28it/s] 40%|███▉      | 5824/14596 [1:21:09<1:56:45,  1.25it/s] 40%|███▉      | 5832/14596 [1:21:15<1:55:53,  1.26it/s] 40%|████      | 5840/14596 [1:21:22<1:55:57,  1.26it/s] 40%|████      | 5848/14596 [1:21:28<1:58:34,  1.23it/s] 40%|████      | 5856/14596 [1:21:34<1:53:55,  1.28it/s] 40%|████      | 5864/14596 [1:21:41<1:56:21,  1.25it/s] 40%|████      | 5872/14596 [1:21:47<1:55:05,  1.26it/s] 40%|████      | 5880/14596 [1:21:54<1:57:56,  1.23it/s] 40%|████      | 5888/14596 [1:22:00<1:54:13,  1.27it/s] 40%|████      | 5896/14596 [1:22:06<1:55:30,  1.26it/s] 40%|████      | 5904/14596 [1:22:12<1:53:07,  1.28it/s] 41%|████      | 5912/14596 [1:22:18<1:51:27,  1.30it/s] 41%|████      | 5920/14596 [1:22:24<1:50:46,  1.31it/s] 41%|████      | 5928/14596 [1:22:30<1:48:09,  1.34it/s] 41%|████      | 5936/14596 [1:22:36<1:49:29,  1.32it/s] 41%|████      | 5944/14596 [1:22:43<1:50:59,  1.30it/s] 41%|████      | 5952/14596 [1:22:48<1:49:29,  1.32it/s] 41%|████      | 5960/14596 [1:22:54<1:48:34,  1.33it/s] 41%|████      | 5968/14596 [1:23:00<1:48:20,  1.33it/s] 41%|████      | 5976/14596 [1:23:07<1:49:20,  1.31it/s] 41%|████      | 5984/14596 [1:23:13<1:48:53,  1.32it/s] 41%|████      | 5992/14596 [1:23:18<1:46:10,  1.35it/s] 41%|████      | 6000/14596 [1:23:25<1:49:45,  1.31it/s] 41%|████      | 6008/14596 [1:23:31<1:50:17,  1.30it/s] 41%|████      | 6016/14596 [1:23:37<1:46:34,  1.34it/s] 41%|████▏     | 6024/14596 [1:23:42<1:45:23,  1.36it/s] 41%|████▏     | 6032/14596 [1:23:49<1:49:28,  1.30it/s] 41%|████▏     | 6040/14596 [1:23:55<1:48:09,  1.32it/s] 41%|████▏     | 6048/14596 [1:24:01<1:46:26,  1.34it/s] 41%|████▏     | 6056/14596 [1:24:07<1:47:47,  1.32it/s] 42%|████▏     | 6064/14596 [1:24:12<1:44:47,  1.36it/s] 42%|████▏     | 6072/14596 [1:24:19<1:48:24,  1.31it/s] 42%|████▏     | 6080/14596 [1:24:25<1:46:02,  1.34it/s] 42%|████▏     | 6088/14596 [1:24:32<1:50:17,  1.29it/s] 42%|████▏     | 6096/14596 [1:24:37<1:47:25,  1.32it/s] 42%|████▏     | 6104/14596 [1:24:44<1:49:47,  1.29it/s] 42%|████▏     | 6112/14596 [1:24:50<1:47:33,  1.31it/s] 42%|████▏     | 6120/14596 [1:24:56<1:49:57,  1.28it/s] 42%|████▏     | 6128/14596 [1:25:03<1:51:40,  1.26it/s] 42%|████▏     | 6136/14596 [1:25:08<1:48:17,  1.30it/s] 42%|████▏     | 6144/14596 [1:25:15<1:51:56,  1.26it/s] 42%|████▏     | 6152/14596 [1:25:21<1:47:16,  1.31it/s] 42%|████▏     | 6160/14596 [1:25:27<1:50:33,  1.27it/s] 42%|████▏     | 6168/14596 [1:25:33<1:46:38,  1.32it/s] 42%|████▏     | 6176/14596 [1:25:40<1:50:13,  1.27it/s] 42%|████▏     | 6184/14596 [1:25:45<1:46:37,  1.31it/s] 42%|████▏     | 6192/14596 [1:25:52<1:48:48,  1.29it/s] 42%|████▏     | 6200/14596 [1:25:58<1:49:04,  1.28it/s] 43%|████▎     | 6208/14596 [1:26:04<1:48:14,  1.29it/s] 43%|████▎     | 6216/14596 [1:26:11<1:49:40,  1.27it/s] 43%|████▎     | 6224/14596 [1:26:17<1:48:20,  1.29it/s] 43%|████▎     | 6232/14596 [1:26:23<1:47:18,  1.30it/s] 43%|████▎     | 6240/14596 [1:26:29<1:47:49,  1.29it/s] 43%|████▎     | 6248/14596 [1:26:36<1:48:39,  1.28it/s] 43%|████▎     | 6256/14596 [1:26:42<1:49:48,  1.27it/s] 43%|████▎     | 6264/14596 [1:26:48<1:47:24,  1.29it/s] 43%|████▎     | 6272/14596 [1:26:54<1:45:19,  1.32it/s] 43%|████▎     | 6280/14596 [1:27:00<1:45:22,  1.32it/s] 43%|████▎     | 6288/14596 [1:27:06<1:45:18,  1.31it/s] 43%|████▎     | 6296/14596 [1:27:12<1:43:20,  1.34it/s] 43%|████▎     | 6304/14596 [1:27:17<1:40:26,  1.38it/s] 43%|████▎     | 6312/14596 [1:27:23<1:40:36,  1.37it/s] 43%|████▎     | 6320/14596 [1:27:29<1:43:43,  1.33it/s] 43%|████▎     | 6328/14596 [1:27:35<1:42:29,  1.34it/s] 43%|████▎     | 6336/14596 [1:27:41<1:40:19,  1.37it/s] 43%|████▎     | 6344/14596 [1:27:46<1:38:36,  1.39it/s] 44%|████▎     | 6352/14596 [1:27:53<1:44:42,  1.31it/s] 44%|████▎     | 6360/14596 [1:27:58<1:38:47,  1.39it/s] 44%|████▎     | 6368/14596 [1:28:04<1:41:35,  1.35it/s] 44%|████▎     | 6376/14596 [1:28:10<1:38:19,  1.39it/s] 44%|████▎     | 6384/14596 [1:28:16<1:42:06,  1.34it/s] 44%|████▍     | 6392/14596 [1:28:22<1:40:09,  1.37it/s] 44%|████▍     | 6400/14596 [1:28:28<1:40:20,  1.36it/s] 44%|████▍     | 6408/14596 [1:28:34<1:39:34,  1.37it/s] 44%|████▍     | 6416/14596 [1:28:39<1:38:37,  1.38it/s] 44%|████▍     | 6424/14596 [1:28:46<1:42:05,  1.33it/s] 44%|████▍     | 6432/14596 [1:28:51<1:37:46,  1.39it/s] 44%|████▍     | 6440/14596 [1:28:58<1:42:08,  1.33it/s] 44%|████▍     | 6448/14596 [1:29:03<1:40:33,  1.35it/s] 44%|████▍     | 6456/14596 [1:29:09<1:41:13,  1.34it/s] 44%|████▍     | 6464/14596 [1:29:16<1:44:13,  1.30it/s] 44%|████▍     | 6472/14596 [1:29:21<1:37:54,  1.38it/s] 44%|████▍     | 6480/14596 [1:29:27<1:38:25,  1.37it/s] 44%|████▍     | 6488/14596 [1:29:32<1:37:21,  1.39it/s] 45%|████▍     | 6496/14596 [1:29:39<1:40:48,  1.34it/s] 45%|████▍     | 6504/14596 [1:29:44<1:34:35,  1.43it/s] 45%|████▍     | 6512/14596 [1:29:49<1:35:02,  1.42it/s] 45%|████▍     | 6520/14596 [1:29:56<1:39:13,  1.36it/s] 45%|████▍     | 6528/14596 [1:30:02<1:38:17,  1.37it/s] 45%|████▍     | 6536/14596 [1:30:07<1:37:04,  1.38it/s] 45%|████▍     | 6544/14596 [1:30:13<1:37:12,  1.38it/s] 45%|████▍     | 6552/14596 [1:30:19<1:36:08,  1.39it/s] 45%|████▍     | 6560/14596 [1:30:25<1:39:16,  1.35it/s] 45%|████▍     | 6568/14596 [1:30:30<1:34:58,  1.41it/s] 45%|████▌     | 6576/14596 [1:30:36<1:37:47,  1.37it/s] 45%|████▌     | 6584/14596 [1:30:42<1:35:51,  1.39it/s] 45%|████▌     | 6592/14596 [1:30:48<1:38:38,  1.35it/s] 45%|████▌     | 6600/14596 [1:30:53<1:34:03,  1.42it/s] 45%|████▌     | 6608/14596 [1:30:59<1:36:52,  1.37it/s] 45%|████▌     | 6616/14596 [1:31:05<1:35:09,  1.40it/s] 45%|████▌     | 6624/14596 [1:31:11<1:37:01,  1.37it/s] 45%|████▌     | 6632/14596 [1:31:17<1:38:17,  1.35it/s] 45%|████▌     | 6640/14596 [1:31:22<1:35:05,  1.39it/s] 46%|████▌     | 6648/14596 [1:31:29<1:38:40,  1.34it/s] 46%|████▌     | 6656/14596 [1:31:35<1:37:57,  1.35it/s] 46%|████▌     | 6664/14596 [1:31:41<1:39:01,  1.34it/s] 46%|████▌     | 6672/14596 [1:31:47<1:38:41,  1.34it/s] 46%|████▌     | 6680/14596 [1:31:52<1:35:14,  1.39it/s] 46%|████▌     | 6688/14596 [1:31:58<1:37:53,  1.35it/s] 46%|████▌     | 6696/14596 [1:32:04<1:36:59,  1.36it/s] 46%|████▌     | 6704/14596 [1:32:10<1:37:32,  1.35it/s] 46%|████▌     | 6712/14596 [1:32:17<1:39:24,  1.32it/s] 46%|████▌     | 6720/14596 [1:32:22<1:35:24,  1.38it/s] 46%|████▌     | 6728/14596 [1:32:28<1:35:34,  1.37it/s] 46%|████▌     | 6736/14596 [1:32:34<1:37:07,  1.35it/s] 46%|████▌     | 6744/14596 [1:32:40<1:35:53,  1.36it/s] 46%|████▋     | 6752/14596 [1:32:46<1:37:50,  1.34it/s] 46%|████▋     | 6760/14596 [1:32:52<1:36:25,  1.35it/s] 46%|████▋     | 6768/14596 [1:32:57<1:35:10,  1.37it/s] 46%|████▋     | 6776/14596 [1:33:04<1:38:12,  1.33it/s] 46%|████▋     | 6784/14596 [1:33:09<1:33:36,  1.39it/s] 47%|████▋     | 6792/14596 [1:33:15<1:33:27,  1.39it/s] 47%|████▋     | 6800/14596 [1:33:21<1:34:21,  1.38it/s] 47%|████▋     | 6808/14596 [1:33:26<1:33:38,  1.39it/s] 47%|████▋     | 6816/14596 [1:33:33<1:36:07,  1.35it/s] 47%|████▋     | 6824/14596 [1:33:38<1:33:17,  1.39it/s] 47%|████▋     | 6832/14596 [1:33:44<1:33:29,  1.38it/s] 47%|████▋     | 6840/14596 [1:33:50<1:36:17,  1.34it/s] 47%|████▋     | 6848/14596 [1:33:55<1:30:46,  1.42it/s] 47%|████▋     | 6856/14596 [1:34:01<1:34:11,  1.37it/s] 47%|████▋     | 6864/14596 [1:34:07<1:34:53,  1.36it/s] 47%|████▋     | 6872/14596 [1:34:13<1:31:45,  1.40it/s] 47%|████▋     | 6880/14596 [1:34:19<1:35:02,  1.35it/s] 47%|████▋     | 6888/14596 [1:34:24<1:32:07,  1.39it/s] 47%|████▋     | 6896/14596 [1:34:30<1:32:07,  1.39it/s] 47%|████▋     | 6904/14596 [1:34:37<1:36:08,  1.33it/s] 47%|████▋     | 6912/14596 [1:34:41<1:30:10,  1.42it/s] 47%|████▋     | 6920/14596 [1:34:48<1:33:12,  1.37it/s] 47%|████▋     | 6928/14596 [1:34:54<1:33:17,  1.37it/s] 48%|████▊     | 6936/14596 [1:34:59<1:30:20,  1.41it/s] 48%|████▊     | 6944/14596 [1:35:05<1:33:58,  1.36it/s] 48%|████▊     | 6952/14596 [1:35:11<1:31:04,  1.40it/s] 48%|████▊     | 6960/14596 [1:35:16<1:30:45,  1.40it/s] 48%|████▊     | 6968/14596 [1:35:23<1:34:40,  1.34it/s] 48%|████▊     | 6976/14596 [1:35:28<1:29:34,  1.42it/s] 48%|████▊     | 6984/14596 [1:35:34<1:31:49,  1.38it/s] 48%|████▊     | 6992/14596 [1:35:40<1:34:17,  1.34it/s] 48%|████▊     | 7000/14596 [1:35:45<1:28:47,  1.43it/s] 48%|████▊     | 7008/14596 [1:35:51<1:31:56,  1.38it/s] 48%|████▊     | 7016/14596 [1:35:57<1:31:33,  1.38it/s] 48%|████▊     | 7024/14596 [1:36:02<1:29:02,  1.42it/s] 48%|████▊     | 7032/14596 [1:36:09<1:32:32,  1.36it/s] 48%|████▊     | 7040/14596 [1:36:14<1:29:09,  1.41it/s] 48%|████▊     | 7048/14596 [1:36:20<1:30:38,  1.39it/s] 48%|████▊     | 7056/14596 [1:36:26<1:32:06,  1.36it/s] 48%|████▊     | 7064/14596 [1:36:31<1:27:30,  1.43it/s] 48%|████▊     | 7072/14596 [1:36:37<1:31:39,  1.37it/s] 49%|████▊     | 7080/14596 [1:36:43<1:28:38,  1.41it/s] 49%|████▊     | 7088/14596 [1:36:49<1:29:51,  1.39it/s] 49%|████▊     | 7096/14596 [1:36:55<1:33:02,  1.34it/s] 49%|████▊     | 7104/14596 [1:37:00<1:27:33,  1.43it/s] 49%|████▊     | 7112/14596 [1:37:06<1:30:58,  1.37it/s] 49%|████▉     | 7120/14596 [1:37:11<1:25:55,  1.45it/s] 49%|████▉     | 7128/14596 [1:37:17<1:28:37,  1.40it/s] 49%|████▉     | 7136/14596 [1:37:22<1:26:28,  1.44it/s] 49%|████▉     | 7144/14596 [1:37:28<1:25:14,  1.46it/s] 49%|████▉     | 7152/14596 [1:37:33<1:25:46,  1.45it/s] 49%|████▉     | 7160/14596 [1:37:39<1:26:59,  1.42it/s] 49%|████▉     | 7168/14596 [1:37:44<1:24:29,  1.47it/s] 49%|████▉     | 7176/14596 [1:37:50<1:26:37,  1.43it/s] 49%|████▉     | 7184/14596 [1:37:56<1:29:28,  1.38it/s] 49%|████▉     | 7192/14596 [1:38:01<1:24:25,  1.46it/s] 49%|████▉     | 7200/14596 [1:38:07<1:25:43,  1.44it/s] 49%|████▉     | 7208/14596 [1:38:12<1:24:41,  1.45it/s] 49%|████▉     | 7216/14596 [1:38:18<1:26:39,  1.42it/s] 49%|████▉     | 7224/14596 [1:38:24<1:27:52,  1.40it/s] 50%|████▉     | 7232/14596 [1:38:29<1:23:50,  1.46it/s] 50%|████▉     | 7240/14596 [1:38:35<1:25:24,  1.44it/s] 50%|████▉     | 7248/14596 [1:38:40<1:24:00,  1.46it/s] 50%|████▉     | 7256/14596 [1:38:46<1:26:19,  1.42it/s] 50%|████▉     | 7264/14596 [1:38:52<1:27:42,  1.39it/s] 50%|████▉     | 7272/14596 [1:38:57<1:24:15,  1.45it/s] 50%|████▉     | 7280/14596 [1:39:03<1:27:10,  1.40it/s] 50%|████▉     | 7288/14596 [1:39:09<1:26:13,  1.41it/s] 50%|████▉     | 7296/14596 [1:39:14<1:24:32,  1.44it/s] 50%|█████     | 7304/14596 [1:39:20<1:27:50,  1.38it/s] 50%|█████     | 7312/14596 [1:39:26<1:26:10,  1.41it/s] 50%|█████     | 7320/14596 [1:39:31<1:25:41,  1.42it/s] 50%|█████     | 7328/14596 [1:39:38<1:28:05,  1.38it/s] 50%|█████     | 7336/14596 [1:39:43<1:26:56,  1.39it/s] 50%|█████     | 7344/14596 [1:39:48<1:23:15,  1.45it/s] 50%|█████     | 7352/14596 [1:39:54<1:25:55,  1.41it/s] 50%|█████     | 7360/14596 [1:39:59<1:21:20,  1.48it/s] 50%|█████     | 7368/14596 [1:40:05<1:22:54,  1.45it/s] 51%|█████     | 7376/14596 [1:40:10<1:23:06,  1.45it/s] 51%|█████     | 7384/14596 [1:40:15<1:21:31,  1.47it/s] 51%|█████     | 7392/14596 [1:40:21<1:20:40,  1.49it/s] 51%|█████     | 7400/14596 [1:40:27<1:23:20,  1.44it/s] 51%|█████     | 7408/14596 [1:40:33<1:25:03,  1.41it/s] 51%|█████     | 7416/14596 [1:40:37<1:21:04,  1.48it/s] 51%|█████     | 7424/14596 [1:40:43<1:22:17,  1.45it/s] 51%|█████     | 7432/14596 [1:40:49<1:22:10,  1.45it/s] 51%|█████     | 7440/14596 [1:40:54<1:22:16,  1.45it/s] 51%|█████     | 7448/14596 [1:41:00<1:23:28,  1.43it/s] 51%|█████     | 7456/14596 [1:41:05<1:21:51,  1.45it/s] 51%|█████     | 7464/14596 [1:41:11<1:21:10,  1.46it/s] 51%|█████     | 7472/14596 [1:41:17<1:23:18,  1.43it/s] 51%|█████     | 7480/14596 [1:41:21<1:19:19,  1.49it/s] 51%|█████▏    | 7488/14596 [1:41:27<1:20:46,  1.47it/s] 51%|█████▏    | 7496/14596 [1:41:33<1:24:11,  1.41it/s] 51%|█████▏    | 7504/14596 [1:41:39<1:22:25,  1.43it/s] 51%|█████▏    | 7512/14596 [1:41:44<1:20:17,  1.47it/s] 52%|█████▏    | 7520/14596 [1:41:49<1:21:20,  1.45it/s] 52%|█████▏    | 7528/14596 [1:41:55<1:20:45,  1.46it/s] 52%|█████▏    | 7536/14596 [1:42:00<1:17:31,  1.52it/s] 52%|█████▏    | 7544/14596 [1:42:05<1:19:10,  1.48it/s] 52%|█████▏    | 7552/14596 [1:42:11<1:20:03,  1.47it/s] 52%|█████▏    | 7560/14596 [1:42:16<1:18:53,  1.49it/s] 52%|█████▏    | 7568/14596 [1:42:21<1:18:17,  1.50it/s] 52%|█████▏    | 7576/14596 [1:42:27<1:18:46,  1.49it/s] 52%|█████▏    | 7584/14596 [1:42:33<1:21:24,  1.44it/s] 52%|█████▏    | 7592/14596 [1:42:38<1:19:04,  1.48it/s] 52%|█████▏    | 7600/14596 [1:42:43<1:19:31,  1.47it/s] 52%|█████▏    | 7608/14596 [1:42:49<1:20:52,  1.44it/s] 52%|█████▏    | 7616/14596 [1:42:54<1:18:55,  1.47it/s] 52%|█████▏    | 7624/14596 [1:43:00<1:18:03,  1.49it/s] 52%|█████▏    | 7632/14596 [1:43:06<1:21:04,  1.43it/s] 52%|█████▏    | 7640/14596 [1:43:11<1:17:38,  1.49it/s] 52%|█████▏    | 7648/14596 [1:43:16<1:18:54,  1.47it/s] 52%|█████▏    | 7656/14596 [1:43:22<1:18:36,  1.47it/s] 53%|█████▎    | 7664/14596 [1:43:28<1:21:27,  1.42it/s] 53%|█████▎    | 7672/14596 [1:43:33<1:18:33,  1.47it/s] 53%|█████▎    | 7680/14596 [1:43:38<1:18:34,  1.47it/s] 53%|█████▎    | 7688/14596 [1:43:44<1:19:37,  1.45it/s] 53%|█████▎    | 7696/14596 [1:43:50<1:21:36,  1.41it/s] 53%|█████▎    | 7704/14596 [1:43:55<1:18:49,  1.46it/s] 53%|█████▎    | 7712/14596 [1:44:00<1:17:16,  1.48it/s] 53%|█████▎    | 7720/14596 [1:44:06<1:17:48,  1.47it/s] 53%|█████▎    | 7728/14596 [1:44:11<1:17:48,  1.47it/s] 53%|█████▎    | 7736/14596 [1:44:16<1:14:29,  1.53it/s] 53%|█████▎    | 7744/14596 [1:44:21<1:15:20,  1.52it/s] 53%|█████▎    | 7752/14596 [1:44:27<1:16:21,  1.49it/s] 53%|█████▎    | 7760/14596 [1:44:32<1:16:49,  1.48it/s] 53%|█████▎    | 7768/14596 [1:44:37<1:16:05,  1.50it/s] 53%|█████▎    | 7776/14596 [1:44:42<1:14:29,  1.53it/s] 53%|█████▎    | 7784/14596 [1:44:48<1:16:29,  1.48it/s] 53%|█████▎    | 7792/14596 [1:44:54<1:17:59,  1.45it/s] 53%|█████▎    | 7800/14596 [1:44:59<1:16:24,  1.48it/s] 53%|█████▎    | 7808/14596 [1:45:04<1:15:21,  1.50it/s] 54%|█████▎    | 7816/14596 [1:45:10<1:17:03,  1.47it/s] 54%|█████▎    | 7824/14596 [1:45:15<1:13:42,  1.53it/s] 54%|█████▎    | 7832/14596 [1:45:20<1:14:56,  1.50it/s] 54%|█████▎    | 7840/14596 [1:45:26<1:15:33,  1.49it/s] 54%|█████▍    | 7848/14596 [1:45:32<1:17:55,  1.44it/s] 54%|█████▍    | 7856/14596 [1:45:37<1:15:24,  1.49it/s] 54%|█████▍    | 7864/14596 [1:45:42<1:16:11,  1.47it/s] 54%|█████▍    | 7872/14596 [1:45:48<1:16:32,  1.46it/s] 54%|█████▍    | 7880/14596 [1:45:54<1:18:35,  1.42it/s] 54%|█████▍    | 7888/14596 [1:45:59<1:17:10,  1.45it/s] 54%|█████▍    | 7896/14596 [1:46:04<1:13:58,  1.51it/s] 54%|█████▍    | 7904/14596 [1:46:09<1:14:17,  1.50it/s] 54%|█████▍    | 7912/14596 [1:46:15<1:16:18,  1.46it/s] 54%|█████▍    | 7920/14596 [1:46:19<1:11:20,  1.56it/s] 54%|█████▍    | 7928/14596 [1:46:25<1:12:12,  1.54it/s] 54%|█████▍    | 7936/14596 [1:46:31<1:14:39,  1.49it/s] 54%|█████▍    | 7944/14596 [1:46:35<1:12:21,  1.53it/s] 54%|█████▍    | 7952/14596 [1:46:41<1:12:42,  1.52it/s] 55%|█████▍    | 7960/14596 [1:46:46<1:13:10,  1.51it/s] 55%|█████▍    | 7968/14596 [1:46:51<1:12:58,  1.51it/s] 55%|█████▍    | 7976/14596 [1:46:57<1:13:54,  1.49it/s] 55%|█████▍    | 7984/14596 [1:47:03<1:14:57,  1.47it/s] 55%|█████▍    | 7992/14596 [1:47:07<1:11:34,  1.54it/s] 55%|█████▍    | 8000/14596 [1:47:13<1:13:00,  1.51it/s] 55%|█████▍    | 8008/14596 [1:47:18<1:13:57,  1.48it/s] 55%|█████▍    | 8016/14596 [1:47:23<1:12:10,  1.52it/s] 55%|█████▍    | 8024/14596 [1:47:29<1:13:03,  1.50it/s] 55%|█████▌    | 8032/14596 [1:47:34<1:13:46,  1.48it/s] 55%|█████▌    | 8040/14596 [1:47:40<1:15:25,  1.45it/s] 55%|█████▌    | 8048/14596 [1:47:45<1:11:37,  1.52it/s] 55%|█████▌    | 8056/14596 [1:47:50<1:09:47,  1.56it/s] 55%|█████▌    | 8064/14596 [1:47:56<1:12:52,  1.49it/s] 55%|█████▌    | 8072/14596 [1:48:01<1:11:29,  1.52it/s] 55%|█████▌    | 8080/14596 [1:48:05<1:09:13,  1.57it/s] 55%|█████▌    | 8088/14596 [1:48:11<1:11:05,  1.53it/s] 55%|█████▌    | 8096/14596 [1:48:16<1:10:35,  1.53it/s] 56%|█████▌    | 8104/14596 [1:48:21<1:10:35,  1.53it/s] 56%|█████▌    | 8112/14596 [1:48:27<1:12:41,  1.49it/s] 56%|█████▌    | 8120/14596 [1:48:32<1:13:09,  1.48it/s] 56%|█████▌    | 8128/14596 [1:48:37<1:09:46,  1.55it/s] 56%|█████▌    | 8136/14596 [1:48:43<1:12:06,  1.49it/s] 56%|█████▌    | 8144/14596 [1:48:48<1:10:11,  1.53it/s] 56%|█████▌    | 8152/14596 [1:48:53<1:09:13,  1.55it/s] 56%|█████▌    | 8160/14596 [1:48:58<1:09:55,  1.53it/s] 56%|█████▌    | 8168/14596 [1:49:04<1:12:08,  1.49it/s] 56%|█████▌    | 8176/14596 [1:49:09<1:12:26,  1.48it/s] 56%|█████▌    | 8184/14596 [1:49:14<1:09:16,  1.54it/s] 56%|█████▌    | 8192/14596 [1:49:19<1:09:03,  1.55it/s] 56%|█████▌    | 8200/14596 [1:49:25<1:11:11,  1.50it/s] 56%|█████▌    | 8208/14596 [1:49:30<1:08:58,  1.54it/s] 56%|█████▋    | 8216/14596 [1:49:35<1:07:10,  1.58it/s] 56%|█████▋    | 8224/14596 [1:49:40<1:08:00,  1.56it/s] 56%|█████▋    | 8232/14596 [1:49:45<1:09:23,  1.53it/s] 56%|█████▋    | 8240/14596 [1:49:51<1:09:15,  1.53it/s] 57%|█████▋    | 8248/14596 [1:49:56<1:08:28,  1.54it/s] 57%|█████▋    | 8256/14596 [1:50:01<1:10:02,  1.51it/s] 57%|█████▋    | 8264/14596 [1:50:06<1:07:44,  1.56it/s] 57%|█████▋    | 8272/14596 [1:50:12<1:09:46,  1.51it/s] 57%|█████▋    | 8280/14596 [1:50:17<1:09:46,  1.51it/s] 57%|█████▋    | 8288/14596 [1:50:21<1:06:27,  1.58it/s] 57%|█████▋    | 8296/14596 [1:50:27<1:07:27,  1.56it/s] 57%|█████▋    | 8304/14596 [1:50:32<1:08:33,  1.53it/s] 57%|█████▋    | 8312/14596 [1:50:38<1:09:59,  1.50it/s] 57%|█████▋    | 8320/14596 [1:50:43<1:08:33,  1.53it/s] 57%|█████▋    | 8328/14596 [1:50:48<1:06:27,  1.57it/s] 57%|█████▋    | 8336/14596 [1:50:53<1:07:03,  1.56it/s] 57%|█████▋    | 8344/14596 [1:50:58<1:09:05,  1.51it/s] 57%|█████▋    | 8352/14596 [1:51:03<1:06:27,  1.57it/s] 57%|█████▋    | 8360/14596 [1:51:08<1:05:34,  1.58it/s] 57%|█████▋    | 8368/14596 [1:51:13<1:06:20,  1.56it/s] 57%|█████▋    | 8376/14596 [1:51:18<1:06:32,  1.56it/s] 57%|█████▋    | 8384/14596 [1:51:24<1:06:10,  1.56it/s] 57%|█████▋    | 8392/14596 [1:51:29<1:07:07,  1.54it/s] 58%|█████▊    | 8400/14596 [1:51:34<1:08:23,  1.51it/s] 58%|█████▊    | 8408/14596 [1:51:39<1:06:23,  1.55it/s] 58%|█████▊    | 8416/14596 [1:51:44<1:05:47,  1.57it/s] 58%|█████▊    | 8424/14596 [1:51:50<1:06:59,  1.54it/s] 58%|█████▊    | 8432/14596 [1:51:55<1:08:00,  1.51it/s] 58%|█████▊    | 8440/14596 [1:52:00<1:06:31,  1.54it/s] 58%|█████▊    | 8448/14596 [1:52:06<1:07:11,  1.53it/s] 58%|█████▊    | 8456/14596 [1:52:11<1:06:28,  1.54it/s] 58%|█████▊    | 8464/14596 [1:52:16<1:07:37,  1.51it/s] 58%|█████▊    | 8472/14596 [1:52:22<1:08:05,  1.50it/s] 58%|█████▊    | 8480/14596 [1:52:27<1:06:47,  1.53it/s] 58%|█████▊    | 8488/14596 [1:52:31<1:04:38,  1.57it/s] 58%|█████▊    | 8496/14596 [1:52:36<1:03:32,  1.60it/s] 58%|█████▊    | 8504/14596 [1:52:42<1:05:42,  1.55it/s] 58%|█████▊    | 8512/14596 [1:52:47<1:05:37,  1.55it/s] 58%|█████▊    | 8520/14596 [1:52:52<1:03:40,  1.59it/s] 58%|█████▊    | 8528/14596 [1:52:57<1:04:00,  1.58it/s] 58%|█████▊    | 8536/14596 [1:53:02<1:05:41,  1.54it/s] 59%|█████▊    | 8544/14596 [1:53:07<1:03:42,  1.58it/s] 59%|█████▊    | 8552/14596 [1:53:12<1:04:49,  1.55it/s] 59%|█████▊    | 8560/14596 [1:53:18<1:05:03,  1.55it/s] 59%|█████▊    | 8568/14596 [1:53:23<1:04:53,  1.55it/s] 59%|█████▉    | 8576/14596 [1:53:27<1:03:18,  1.58it/s] 59%|█████▉    | 8584/14596 [1:53:33<1:04:12,  1.56it/s] 59%|█████▉    | 8592/14596 [1:53:38<1:04:12,  1.56it/s] 59%|█████▉    | 8600/14596 [1:53:43<1:05:04,  1.54it/s] 59%|█████▉    | 8608/14596 [1:53:49<1:06:07,  1.51it/s] 59%|█████▉    | 8616/14596 [1:53:54<1:06:42,  1.49it/s] 59%|█████▉    | 8624/14596 [1:53:59<1:04:01,  1.55it/s] 59%|█████▉    | 8632/14596 [1:54:04<1:02:00,  1.60it/s] 59%|█████▉    | 8640/14596 [1:54:09<1:02:46,  1.58it/s] 59%|█████▉    | 8648/14596 [1:54:14<1:04:45,  1.53it/s] 59%|█████▉    | 8656/14596 [1:54:19<1:02:34,  1.58it/s] 59%|█████▉    | 8664/14596 [1:54:24<1:02:15,  1.59it/s] 59%|█████▉    | 8672/14596 [1:54:29<1:01:40,  1.60it/s] 59%|█████▉    | 8680/14596 [1:54:34<1:02:38,  1.57it/s] 60%|█████▉    | 8688/14596 [1:54:39<1:02:14,  1.58it/s] 60%|█████▉    | 8696/14596 [1:54:44<1:01:41,  1.59it/s] 60%|█████▉    | 8704/14596 [1:54:49<1:02:31,  1.57it/s] 60%|█████▉    | 8712/14596 [1:54:55<1:03:41,  1.54it/s] 60%|█████▉    | 8720/14596 [1:55:00<1:04:04,  1.53it/s] 60%|█████▉    | 8728/14596 [1:55:05<1:02:26,  1.57it/s] 60%|█████▉    | 8736/14596 [1:55:10<1:01:10,  1.60it/s] 60%|█████▉    | 8744/14596 [1:55:15<1:02:47,  1.55it/s] 60%|█████▉    | 8752/14596 [1:55:20<1:02:48,  1.55it/s] 60%|██████    | 8760/14596 [1:55:26<1:03:18,  1.54it/s] 60%|██████    | 8768/14596 [1:55:31<1:04:19,  1.51it/s] 60%|██████    | 8776/14596 [1:55:36<1:02:05,  1.56it/s] 60%|██████    | 8784/14596 [1:55:41<1:02:16,  1.56it/s] 60%|██████    | 8792/14596 [1:55:47<1:03:32,  1.52it/s] 60%|██████    | 8800/14596 [1:55:52<1:02:37,  1.54it/s] 60%|██████    | 8808/14596 [1:55:57<1:02:59,  1.53it/s] 60%|██████    | 8816/14596 [1:56:02<1:03:29,  1.52it/s] 60%|██████    | 8824/14596 [1:56:08<1:03:35,  1.51it/s] 61%|██████    | 8832/14596 [1:56:12<1:01:02,  1.57it/s] 61%|██████    | 8840/14596 [1:56:18<1:02:12,  1.54it/s] 61%|██████    | 8848/14596 [1:56:23<1:02:35,  1.53it/s] 61%|██████    | 8856/14596 [1:56:28<1:02:01,  1.54it/s] 61%|██████    | 8864/14596 [1:56:33<1:02:01,  1.54it/s] 61%|██████    | 8872/14596 [1:56:39<1:02:23,  1.53it/s] 61%|██████    | 8880/14596 [1:56:44<1:02:36,  1.52it/s] 61%|██████    | 8888/14596 [1:56:49<1:00:59,  1.56it/s] 61%|██████    | 8896/14596 [1:56:54<59:57,  1.58it/s]   61%|██████    | 8904/14596 [1:56:59<1:00:24,  1.57it/s] 61%|██████    | 8912/14596 [1:57:04<1:00:30,  1.57it/s] 61%|██████    | 8920/14596 [1:57:09<1:00:32,  1.56it/s] 61%|██████    | 8928/14596 [1:57:14<1:00:44,  1.56it/s] 61%|██████    | 8936/14596 [1:57:20<1:00:54,  1.55it/s] 61%|██████▏   | 8944/14596 [1:57:25<1:00:53,  1.55it/s] 61%|██████▏   | 8952/14596 [1:57:30<1:01:19,  1.53it/s] 61%|██████▏   | 8960/14596 [1:57:35<1:01:30,  1.53it/s] 61%|██████▏   | 8968/14596 [1:57:40<59:36,  1.57it/s]   61%|██████▏   | 8976/14596 [1:57:45<59:05,  1.59it/s] 62%|██████▏   | 8984/14596 [1:57:50<58:44,  1.59it/s] 62%|██████▏   | 8992/14596 [1:57:55<58:41,  1.59it/s] 62%|██████▏   | 9000/14596 [1:58:00<59:37,  1.56it/s] 62%|██████▏   | 9008/14596 [1:58:06<1:00:13,  1.55it/s] 62%|██████▏   | 9016/14596 [1:58:11<1:00:11,  1.55it/s] 62%|██████▏   | 9024/14596 [1:58:16<1:00:07,  1.54it/s] 62%|██████▏   | 9032/14596 [1:58:21<59:20,  1.56it/s]   62%|██████▏   | 9040/14596 [1:58:26<58:07,  1.59it/s] 62%|██████▏   | 9048/14596 [1:58:31<58:12,  1.59it/s] 62%|██████▏   | 9056/14596 [1:58:36<57:43,  1.60it/s] 62%|██████▏   | 9064/14596 [1:58:41<58:04,  1.59it/s] 62%|██████▏   | 9072/14596 [1:58:46<58:17,  1.58it/s] 62%|██████▏   | 9080/14596 [1:58:51<58:38,  1.57it/s] 62%|██████▏   | 9088/14596 [1:58:56<58:42,  1.56it/s] 62%|██████▏   | 9096/14596 [1:59:02<58:36,  1.56it/s] 62%|██████▏   | 9104/14596 [1:59:06<57:21,  1.60it/s] 62%|██████▏   | 9112/14596 [1:59:11<56:18,  1.62it/s] 62%|██████▏   | 9120/14596 [1:59:16<56:10,  1.62it/s] 63%|██████▎   | 9128/14596 [1:59:21<56:11,  1.62it/s] 63%|██████▎   | 9136/14596 [1:59:26<56:37,  1.61it/s] 63%|██████▎   | 9144/14596 [1:59:31<56:59,  1.59it/s] 63%|██████▎   | 9152/14596 [1:59:36<56:43,  1.60it/s] 63%|██████▎   | 9160/14596 [1:59:41<55:45,  1.62it/s] 63%|██████▎   | 9168/14596 [1:59:46<56:19,  1.61it/s] 63%|██████▎   | 9176/14596 [1:59:51<56:03,  1.61it/s] 63%|██████▎   | 9184/14596 [1:59:56<56:25,  1.60it/s] 63%|██████▎   | 9192/14596 [2:00:01<55:26,  1.62it/s] 63%|██████▎   | 9200/14596 [2:00:06<55:42,  1.61it/s] 63%|██████▎   | 9208/14596 [2:00:11<55:20,  1.62it/s] 63%|██████▎   | 9216/14596 [2:00:16<55:30,  1.62it/s] 63%|██████▎   | 9224/14596 [2:00:21<55:50,  1.60it/s] 63%|██████▎   | 9232/14596 [2:00:26<55:49,  1.60it/s] 63%|██████▎   | 9240/14596 [2:00:30<54:47,  1.63it/s] 63%|██████▎   | 9248/14596 [2:00:35<53:36,  1.66it/s] 63%|██████▎   | 9256/14596 [2:00:40<53:17,  1.67it/s] 63%|██████▎   | 9264/14596 [2:00:45<53:53,  1.65it/s] 64%|██████▎   | 9272/14596 [2:00:50<54:40,  1.62it/s] 64%|██████▎   | 9280/14596 [2:00:55<55:11,  1.61it/s] 64%|██████▎   | 9288/14596 [2:01:00<53:55,  1.64it/s] 64%|██████▎   | 9296/14596 [2:01:04<53:25,  1.65it/s] 64%|██████▎   | 9304/14596 [2:01:09<54:05,  1.63it/s] 64%|██████▍   | 9312/14596 [2:01:14<54:07,  1.63it/s] 64%|██████▍   | 9320/14596 [2:01:19<54:06,  1.63it/s] 64%|██████▍   | 9328/14596 [2:01:24<53:51,  1.63it/s] 64%|██████▍   | 9336/14596 [2:01:29<54:06,  1.62it/s] 64%|██████▍   | 9344/14596 [2:01:34<54:08,  1.62it/s] 64%|██████▍   | 9352/14596 [2:01:39<53:53,  1.62it/s] 64%|██████▍   | 9360/14596 [2:01:44<52:31,  1.66it/s] 64%|██████▍   | 9368/14596 [2:01:48<51:32,  1.69it/s] 64%|██████▍   | 9376/14596 [2:01:53<51:38,  1.68it/s] 64%|██████▍   | 9384/14596 [2:01:58<52:12,  1.66it/s] 64%|██████▍   | 9392/14596 [2:02:03<52:27,  1.65it/s] 64%|██████▍   | 9400/14596 [2:02:08<52:48,  1.64it/s] 64%|██████▍   | 9408/14596 [2:02:12<51:51,  1.67it/s] 65%|██████▍   | 9416/14596 [2:02:17<52:29,  1.64it/s] 65%|██████▍   | 9424/14596 [2:02:22<52:44,  1.63it/s] 65%|██████▍   | 9432/14596 [2:02:27<52:32,  1.64it/s] 65%|██████▍   | 9440/14596 [2:02:32<51:50,  1.66it/s] 65%|██████▍   | 9448/14596 [2:02:37<51:45,  1.66it/s] 65%|██████▍   | 9456/14596 [2:02:42<52:05,  1.64it/s] 65%|██████▍   | 9464/14596 [2:02:47<53:07,  1.61it/s] 65%|██████▍   | 9472/14596 [2:02:52<52:47,  1.62it/s] 65%|██████▍   | 9480/14596 [2:02:57<52:28,  1.62it/s] 65%|██████▌   | 9488/14596 [2:03:01<50:55,  1.67it/s] 65%|██████▌   | 9496/14596 [2:03:06<50:34,  1.68it/s] 65%|██████▌   | 9504/14596 [2:03:11<50:46,  1.67it/s] 65%|██████▌   | 9512/14596 [2:03:15<50:30,  1.68it/s] 65%|██████▌   | 9520/14596 [2:03:20<50:38,  1.67it/s] 65%|██████▌   | 9528/14596 [2:03:25<50:38,  1.67it/s] 65%|██████▌   | 9536/14596 [2:03:30<51:12,  1.65it/s] 65%|██████▌   | 9544/14596 [2:03:35<50:54,  1.65it/s] 65%|██████▌   | 9552/14596 [2:03:40<50:29,  1.67it/s] 65%|██████▌   | 9560/14596 [2:03:44<50:14,  1.67it/s] 66%|██████▌   | 9568/14596 [2:03:50<51:27,  1.63it/s] 66%|██████▌   | 9576/14596 [2:03:55<51:46,  1.62it/s] 66%|██████▌   | 9584/14596 [2:04:00<52:02,  1.61it/s] 66%|██████▌   | 9592/14596 [2:04:04<51:12,  1.63it/s] 66%|██████▌   | 9600/14596 [2:04:09<50:31,  1.65it/s] 66%|██████▌   | 9608/14596 [2:04:14<49:21,  1.68it/s] 66%|██████▌   | 9616/14596 [2:04:19<49:50,  1.67it/s] 66%|██████▌   | 9624/14596 [2:04:23<49:21,  1.68it/s] 66%|██████▌   | 9632/14596 [2:04:28<49:10,  1.68it/s] 66%|██████▌   | 9640/14596 [2:04:33<48:56,  1.69it/s] 66%|██████▌   | 9648/14596 [2:04:37<48:59,  1.68it/s] 66%|██████▌   | 9656/14596 [2:04:42<48:45,  1.69it/s] 66%|██████▌   | 9664/14596 [2:04:47<49:04,  1.68it/s] 66%|██████▋   | 9672/14596 [2:04:52<48:50,  1.68it/s] 66%|██████▋   | 9680/14596 [2:04:56<48:00,  1.71it/s] 66%|██████▋   | 9688/14596 [2:05:02<50:00,  1.64it/s] 66%|██████▋   | 9696/14596 [2:05:07<50:04,  1.63it/s] 66%|██████▋   | 9704/14596 [2:05:12<50:14,  1.62it/s] 67%|██████▋   | 9712/14596 [2:05:16<49:10,  1.66it/s] 67%|██████▋   | 9720/14596 [2:05:21<47:53,  1.70it/s] 67%|██████▋   | 9728/14596 [2:05:25<47:32,  1.71it/s] 67%|██████▋   | 9736/14596 [2:05:30<48:37,  1.67it/s] 67%|██████▋   | 9744/14596 [2:05:35<48:06,  1.68it/s] 67%|██████▋   | 9752/14596 [2:05:40<47:39,  1.69it/s] 67%|██████▋   | 9760/14596 [2:05:45<48:53,  1.65it/s] 67%|██████▋   | 9768/14596 [2:05:49<48:09,  1.67it/s] 67%|██████▋   | 9776/14596 [2:05:54<47:28,  1.69it/s] 67%|██████▋   | 9784/14596 [2:05:59<47:59,  1.67it/s] 67%|██████▋   | 9792/14596 [2:06:04<48:25,  1.65it/s] 67%|██████▋   | 9800/14596 [2:06:08<46:47,  1.71it/s] 67%|██████▋   | 9808/14596 [2:06:13<48:06,  1.66it/s] 67%|██████▋   | 9816/14596 [2:06:18<48:22,  1.65it/s]/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
 67%|██████▋   | 9824/14596 [2:06:23<47:26,  1.68it/s] 67%|██████▋   | 9832/14596 [2:06:28<47:28,  1.67it/s] 67%|██████▋   | 9840/14596 [2:06:32<47:15,  1.68it/s] 67%|██████▋   | 9848/14596 [2:06:37<47:03,  1.68it/s] 68%|██████▊   | 9856/14596 [2:06:42<46:49,  1.69it/s] 68%|██████▊   | 9864/14596 [2:06:47<46:44,  1.69it/s] 68%|██████▊   | 9872/14596 [2:06:51<46:44,  1.68it/s] 68%|██████▊   | 9880/14596 [2:06:56<46:31,  1.69it/s] 68%|██████▊   | 9888/14596 [2:07:01<46:32,  1.69it/s] 68%|██████▊   | 9896/14596 [2:07:06<46:36,  1.68it/s] 68%|██████▊   | 9904/14596 [2:07:10<46:28,  1.68it/s] 68%|██████▊   | 9912/14596 [2:07:15<46:27,  1.68it/s] 68%|██████▊   | 9920/14596 [2:07:20<46:30,  1.68it/s] 68%|██████▊   | 9928/14596 [2:07:25<46:40,  1.67it/s] 68%|██████▊   | 9936/14596 [2:07:30<46:37,  1.67it/s] 68%|██████▊   | 9944/14596 [2:07:34<46:33,  1.67it/s] 68%|██████▊   | 9952/14596 [2:07:39<46:30,  1.66it/s] 68%|██████▊   | 9960/14596 [2:07:44<46:26,  1.66it/s] 68%|██████▊   | 9968/14596 [2:07:49<46:23,  1.66it/s] 68%|██████▊   | 9976/14596 [2:07:54<46:30,  1.66it/s] 68%|██████▊   | 9984/14596 [2:07:59<46:46,  1.64it/s] 68%|██████▊   | 9992/14596 [2:08:04<46:51,  1.64it/s] 69%|██████▊   | 10000/14596 [2:08:08<46:37,  1.64it/s] 69%|██████▊   | 10008/14596 [2:08:13<46:16,  1.65it/s] 69%|██████▊   | 10016/14596 [2:08:18<45:38,  1.67it/s] 69%|██████▊   | 10024/14596 [2:08:22<45:16,  1.68it/s] 69%|██████▊   | 10032/14596 [2:08:27<45:04,  1.69it/s] 69%|██████▉   | 10040/14596 [2:08:32<44:46,  1.70it/s] 69%|██████▉   | 10048/14596 [2:08:37<44:38,  1.70it/s] 69%|██████▉   | 10056/14596 [2:08:41<44:41,  1.69it/s] 69%|██████▉   | 10064/14596 [2:08:46<44:24,  1.70it/s] 69%|██████▉   | 10072/14596 [2:08:51<44:15,  1.70it/s] 69%|██████▉   | 10080/14596 [2:08:55<44:18,  1.70it/s] 69%|██████▉   | 10088/14596 [2:09:00<44:12,  1.70it/s] 69%|██████▉   | 10096/14596 [2:09:05<43:53,  1.71it/s] 69%|██████▉   | 10104/14596 [2:09:09<44:03,  1.70it/s] 69%|██████▉   | 10112/14596 [2:09:14<44:18,  1.69it/s] 69%|██████▉   | 10120/14596 [2:09:19<44:10,  1.69it/s] 69%|██████▉   | 10128/14596 [2:09:24<44:17,  1.68it/s] 69%|██████▉   | 10136/14596 [2:09:29<44:36,  1.67it/s] 69%|██████▉   | 10144/14596 [2:09:34<44:40,  1.66it/s] 70%|██████▉   | 10152/14596 [2:09:38<44:36,  1.66it/s] 70%|██████▉   | 10160/14596 [2:09:43<44:35,  1.66it/s] 70%|██████▉   | 10168/14596 [2:09:48<44:36,  1.65it/s] 70%|██████▉   | 10176/14596 [2:09:53<44:22,  1.66it/s] 70%|██████▉   | 10184/14596 [2:09:58<44:04,  1.67it/s] 70%|██████▉   | 10192/14596 [2:10:02<43:32,  1.69it/s] 70%|██████▉   | 10200/14596 [2:10:07<43:06,  1.70it/s] 70%|██████▉   | 10208/14596 [2:10:12<42:57,  1.70it/s] 70%|██████▉   | 10216/14596 [2:10:16<42:33,  1.72it/s] 70%|███████   | 10224/14596 [2:10:21<42:16,  1.72it/s] 70%|███████   | 10232/14596 [2:10:25<42:30,  1.71it/s] 70%|███████   | 10240/14596 [2:10:30<42:20,  1.71it/s] 70%|███████   | 10248/14596 [2:10:35<42:06,  1.72it/s] 70%|███████   | 10256/14596 [2:10:39<42:04,  1.72it/s] 70%|███████   | 10264/14596 [2:10:44<42:05,  1.72it/s] 70%|███████   | 10272/14596 [2:10:49<42:20,  1.70it/s] 70%|███████   | 10280/14596 [2:10:54<42:44,  1.68it/s] 70%|███████   | 10288/14596 [2:10:59<42:51,  1.68it/s] 71%|███████   | 10296/14596 [2:11:03<42:53,  1.67it/s] 71%|███████   | 10304/14596 [2:11:08<42:56,  1.67it/s] 71%|███████   | 10312/14596 [2:11:13<42:58,  1.66it/s] 71%|███████   | 10320/14596 [2:11:18<42:44,  1.67it/s] 71%|███████   | 10328/14596 [2:11:23<42:37,  1.67it/s] 71%|███████   | 10336/14596 [2:11:27<42:17,  1.68it/s] 71%|███████   | 10344/14596 [2:11:32<41:40,  1.70it/s] 71%|███████   | 10352/14596 [2:11:37<41:24,  1.71it/s] 71%|███████   | 10360/14596 [2:11:41<41:13,  1.71it/s] 71%|███████   | 10368/14596 [2:11:46<40:55,  1.72it/s] 71%|███████   | 10376/14596 [2:11:50<40:50,  1.72it/s] 71%|███████   | 10384/14596 [2:11:55<40:44,  1.72it/s] 71%|███████   | 10392/14596 [2:12:00<40:33,  1.73it/s] 71%|███████▏  | 10400/14596 [2:12:04<40:33,  1.72it/s] 71%|███████▏  | 10408/14596 [2:12:09<40:18,  1.73it/s] 71%|███████▏  | 10416/14596 [2:12:13<39:58,  1.74it/s] 71%|███████▏  | 10424/14596 [2:12:18<39:55,  1.74it/s] 71%|███████▏  | 10432/14596 [2:12:23<40:17,  1.72it/s] 72%|███████▏  | 10440/14596 [2:12:27<40:28,  1.71it/s] 72%|███████▏  | 10448/14596 [2:12:32<40:39,  1.70it/s] 72%|███████▏  | 10456/14596 [2:12:37<40:47,  1.69it/s] 72%|███████▏  | 10464/14596 [2:12:42<40:56,  1.68it/s] 72%|███████▏  | 10472/14596 [2:12:47<41:03,  1.67it/s] 72%|███████▏  | 10480/14596 [2:12:52<41:04,  1.67it/s] 72%|███████▏  | 10488/14596 [2:12:56<40:55,  1.67it/s] 72%|███████▏  | 10496/14596 [2:13:01<40:56,  1.67it/s] 72%|███████▏  | 10504/14596 [2:13:06<40:26,  1.69it/s] 72%|███████▏  | 10512/14596 [2:13:10<40:06,  1.70it/s] 72%|███████▏  | 10520/14596 [2:13:15<39:40,  1.71it/s] 72%|███████▏  | 10528/14596 [2:13:20<39:36,  1.71it/s] 72%|███████▏  | 10536/14596 [2:13:24<39:14,  1.72it/s] 72%|███████▏  | 10544/14596 [2:13:29<38:57,  1.73it/s] 72%|███████▏  | 10552/14596 [2:13:33<38:54,  1.73it/s] 72%|███████▏  | 10560/14596 [2:13:38<38:40,  1.74it/s] 72%|███████▏  | 10568/14596 [2:13:42<38:31,  1.74it/s] 72%|███████▏  | 10576/14596 [2:13:47<38:31,  1.74it/s] 73%|███████▎  | 10584/14596 [2:13:52<38:25,  1.74it/s] 73%|███████▎  | 10592/14596 [2:13:56<38:21,  1.74it/s] 73%|███████▎  | 10600/14596 [2:14:01<38:15,  1.74it/s] 73%|███████▎  | 10608/14596 [2:14:05<38:09,  1.74it/s] 73%|███████▎  | 10616/14596 [2:14:10<37:59,  1.75it/s] 73%|███████▎  | 10624/14596 [2:14:15<38:04,  1.74it/s] 73%|███████▎  | 10632/14596 [2:14:19<38:12,  1.73it/s] 73%|███████▎  | 10640/14596 [2:14:24<38:29,  1.71it/s] 73%|███████▎  | 10648/14596 [2:14:29<38:37,  1.70it/s] 73%|███████▎  | 10656/14596 [2:14:34<38:45,  1.69it/s] 73%|███████▎  | 10664/14596 [2:14:38<38:39,  1.70it/s] 73%|███████▎  | 10672/14596 [2:14:43<38:46,  1.69it/s] 73%|███████▎  | 10680/14596 [2:14:48<38:40,  1.69it/s] 73%|███████▎  | 10688/14596 [2:14:53<38:33,  1.69it/s] 73%|███████▎  | 10696/14596 [2:14:57<38:39,  1.68it/s] 73%|███████▎  | 10704/14596 [2:15:02<38:25,  1.69it/s] 73%|███████▎  | 10712/14596 [2:15:07<37:50,  1.71it/s] 73%|███████▎  | 10720/14596 [2:15:11<37:34,  1.72it/s] 73%|███████▎  | 10728/14596 [2:15:16<37:09,  1.74it/s] 74%|███████▎  | 10736/14596 [2:15:20<37:03,  1.74it/s] 74%|███████▎  | 10744/14596 [2:15:25<37:00,  1.73it/s] 74%|███████▎  | 10752/14596 [2:15:29<36:33,  1.75it/s] 74%|███████▎  | 10760/14596 [2:15:34<36:26,  1.75it/s] 74%|███████▍  | 10768/14596 [2:15:39<36:34,  1.74it/s] 74%|███████▍  | 10776/14596 [2:15:43<36:17,  1.75it/s] 74%|███████▍  | 10784/14596 [2:15:48<36:12,  1.75it/s] 74%|███████▍  | 10792/14596 [2:15:52<36:06,  1.76it/s] 74%|███████▍  | 10800/14596 [2:15:57<36:06,  1.75it/s] 74%|███████▍  | 10808/14596 [2:16:01<35:53,  1.76it/s] 74%|███████▍  | 10816/14596 [2:16:06<35:46,  1.76it/s] 74%|███████▍  | 10824/14596 [2:16:10<35:43,  1.76it/s] 74%|███████▍  | 10832/14596 [2:16:15<35:57,  1.74it/s] 74%|███████▍  | 10840/14596 [2:16:20<36:07,  1.73it/s] 74%|███████▍  | 10848/14596 [2:16:25<36:22,  1.72it/s] 74%|███████▍  | 10856/14596 [2:16:29<36:32,  1.71it/s] 74%|███████▍  | 10864/14596 [2:16:34<36:26,  1.71it/s] 74%|███████▍  | 10872/14596 [2:16:39<36:18,  1.71it/s] 75%|███████▍  | 10880/14596 [2:16:43<36:19,  1.71it/s] 75%|███████▍  | 10888/14596 [2:16:48<36:08,  1.71it/s] 75%|███████▍  | 10896/14596 [2:16:53<35:44,  1.73it/s] 75%|███████▍  | 10904/14596 [2:16:57<35:25,  1.74it/s] 75%|███████▍  | 10912/14596 [2:17:02<35:00,  1.75it/s] 75%|███████▍  | 10920/14596 [2:17:06<34:48,  1.76it/s] 75%|███████▍  | 10928/14596 [2:17:11<34:41,  1.76it/s] 75%|███████▍  | 10936/14596 [2:17:15<34:34,  1.76it/s] 75%|███████▍  | 10944/14596 [2:17:20<34:31,  1.76it/s] 75%|███████▌  | 10952/14596 [2:17:24<34:25,  1.76it/s] 75%|███████▌  | 10960/14596 [2:17:29<34:20,  1.76it/s] 75%|███████▌  | 10968/14596 [2:17:33<34:11,  1.77it/s] 75%|███████▌  | 10976/14596 [2:17:38<34:12,  1.76it/s] 75%|███████▌  | 10984/14596 [2:17:42<34:03,  1.77it/s] 75%|███████▌  | 10992/14596 [2:17:47<33:42,  1.78it/s] 75%|███████▌  | 11000/14596 [2:17:51<33:41,  1.78it/s] 75%|███████▌  | 11008/14596 [2:17:56<33:46,  1.77it/s] 75%|███████▌  | 11016/14596 [2:18:00<33:58,  1.76it/s] 76%|███████▌  | 11024/14596 [2:18:05<34:08,  1.74it/s] 76%|███████▌  | 11032/14596 [2:18:10<34:21,  1.73it/s] 76%|███████▌  | 11040/14596 [2:18:14<34:17,  1.73it/s] 76%|███████▌  | 11048/14596 [2:18:19<34:26,  1.72it/s] 76%|███████▌  | 11056/14596 [2:18:24<34:25,  1.71it/s] 76%|███████▌  | 11064/14596 [2:18:29<34:25,  1.71it/s] 76%|███████▌  | 11072/14596 [2:18:33<34:09,  1.72it/s] 76%|███████▌  | 11080/14596 [2:18:38<33:35,  1.74it/s] 76%|███████▌  | 11088/14596 [2:18:42<33:17,  1.76it/s] 76%|███████▌  | 11096/14596 [2:18:47<33:01,  1.77it/s] 76%|███████▌  | 11104/14596 [2:18:51<32:38,  1.78it/s] 76%|███████▌  | 11112/14596 [2:18:55<32:26,  1.79it/s] 76%|███████▌  | 11120/14596 [2:19:00<32:22,  1.79it/s] 76%|███████▌  | 11128/14596 [2:19:04<32:09,  1.80it/s] 76%|███████▋  | 11136/14596 [2:19:09<31:59,  1.80it/s] 76%|███████▋  | 11144/14596 [2:19:13<32:06,  1.79it/s] 76%|███████▋  | 11152/14596 [2:19:18<31:56,  1.80it/s] 76%|███████▋  | 11160/14596 [2:19:22<31:51,  1.80it/s] 77%|███████▋  | 11168/14596 [2:19:27<31:53,  1.79it/s] 77%|███████▋  | 11176/14596 [2:19:31<31:45,  1.79it/s] 77%|███████▋  | 11184/14596 [2:19:35<31:26,  1.81it/s] 77%|███████▋  | 11192/14596 [2:19:40<31:30,  1.80it/s] 77%|███████▋  | 11200/14596 [2:19:44<31:41,  1.79it/s] 77%|███████▋  | 11208/14596 [2:19:49<31:44,  1.78it/s] 77%|███████▋  | 11216/14596 [2:19:53<31:46,  1.77it/s] 77%|███████▋  | 11224/14596 [2:19:58<32:02,  1.75it/s] 77%|███████▋  | 11232/14596 [2:20:03<32:04,  1.75it/s] 77%|███████▋  | 11240/14596 [2:20:07<31:58,  1.75it/s] 77%|███████▋  | 11248/14596 [2:20:12<32:02,  1.74it/s] 77%|███████▋  | 11256/14596 [2:20:17<32:05,  1.73it/s] 77%|███████▋  | 11264/14596 [2:20:21<32:09,  1.73it/s] 77%|███████▋  | 11272/14596 [2:20:26<31:57,  1.73it/s] 77%|███████▋  | 11280/14596 [2:20:30<31:35,  1.75it/s] 77%|███████▋  | 11288/14596 [2:20:35<31:08,  1.77it/s] 77%|███████▋  | 11296/14596 [2:20:39<30:49,  1.78it/s] 77%|███████▋  | 11304/14596 [2:20:44<30:36,  1.79it/s] 78%|███████▊  | 11312/14596 [2:20:48<30:26,  1.80it/s] 78%|███████▊  | 11320/14596 [2:20:52<30:25,  1.79it/s] 78%|███████▊  | 11328/14596 [2:20:57<30:07,  1.81it/s] 78%|███████▊  | 11336/14596 [2:21:01<30:03,  1.81it/s] 78%|███████▊  | 11344/14596 [2:21:06<30:04,  1.80it/s] 78%|███████▊  | 11352/14596 [2:21:10<30:01,  1.80it/s] 78%|███████▊  | 11360/14596 [2:21:15<29:48,  1.81it/s] 78%|███████▊  | 11368/14596 [2:21:19<29:42,  1.81it/s] 78%|███████▊  | 11376/14596 [2:21:23<29:41,  1.81it/s] 78%|███████▊  | 11384/14596 [2:21:28<29:37,  1.81it/s] 78%|███████▊  | 11392/14596 [2:21:32<29:32,  1.81it/s] 78%|███████▊  | 11400/14596 [2:21:37<29:26,  1.81it/s] 78%|███████▊  | 11408/14596 [2:21:41<29:18,  1.81it/s] 78%|███████▊  | 11416/14596 [2:21:46<29:22,  1.80it/s] 78%|███████▊  | 11424/14596 [2:21:50<29:25,  1.80it/s] 78%|███████▊  | 11432/14596 [2:21:54<29:22,  1.79it/s] 78%|███████▊  | 11440/14596 [2:21:59<29:28,  1.78it/s] 78%|███████▊  | 11448/14596 [2:22:04<29:34,  1.77it/s] 78%|███████▊  | 11456/14596 [2:22:08<29:37,  1.77it/s] 79%|███████▊  | 11464/14596 [2:22:13<29:41,  1.76it/s] 79%|███████▊  | 11472/14596 [2:22:17<29:43,  1.75it/s] 79%|███████▊  | 11480/14596 [2:22:22<29:38,  1.75it/s] 79%|███████▊  | 11488/14596 [2:22:26<29:26,  1.76it/s] 79%|███████▉  | 11496/14596 [2:22:31<29:12,  1.77it/s] 79%|███████▉  | 11504/14596 [2:22:35<28:43,  1.79it/s] 79%|███████▉  | 11512/14596 [2:22:40<28:24,  1.81it/s] 79%|███████▉  | 11520/14596 [2:22:44<28:15,  1.81it/s] 79%|███████▉  | 11528/14596 [2:22:48<28:07,  1.82it/s] 79%|███████▉  | 11536/14596 [2:22:53<27:57,  1.82it/s] 79%|███████▉  | 11544/14596 [2:22:57<28:07,  1.81it/s] 79%|███████▉  | 11552/14596 [2:23:01<27:48,  1.82it/s] 79%|███████▉  | 11560/14596 [2:23:06<27:38,  1.83it/s] 79%|███████▉  | 11568/14596 [2:23:10<27:45,  1.82it/s] 79%|███████▉  | 11576/14596 [2:23:15<27:33,  1.83it/s] 79%|███████▉  | 11584/14596 [2:23:19<27:24,  1.83it/s] 79%|███████▉  | 11592/14596 [2:23:23<27:27,  1.82it/s] 79%|███████▉  | 11600/14596 [2:23:28<27:20,  1.83it/s] 80%|███████▉  | 11608/14596 [2:23:32<27:04,  1.84it/s] 80%|███████▉  | 11616/14596 [2:23:36<27:04,  1.83it/s] 80%|███████▉  | 11624/14596 [2:23:41<27:09,  1.82it/s] 80%|███████▉  | 11632/14596 [2:23:45<27:09,  1.82it/s] 80%|███████▉  | 11640/14596 [2:23:50<27:22,  1.80it/s] 80%|███████▉  | 11648/14596 [2:23:54<27:25,  1.79it/s] 80%|███████▉  | 11656/14596 [2:23:59<27:25,  1.79it/s] 80%|███████▉  | 11664/14596 [2:24:03<27:31,  1.78it/s] 80%|███████▉  | 11672/14596 [2:24:08<27:31,  1.77it/s] 80%|████████  | 11680/14596 [2:24:12<27:26,  1.77it/s] 80%|████████  | 11688/14596 [2:24:17<27:21,  1.77it/s] 80%|████████  | 11696/14596 [2:24:21<27:07,  1.78it/s] 80%|████████  | 11704/14596 [2:24:26<26:42,  1.81it/s] 80%|████████  | 11712/14596 [2:24:30<26:18,  1.83it/s] 80%|████████  | 11720/14596 [2:24:34<26:10,  1.83it/s] 80%|████████  | 11728/14596 [2:24:39<25:56,  1.84it/s] 80%|████████  | 11736/14596 [2:24:43<25:39,  1.86it/s] 80%|████████  | 11744/14596 [2:24:47<25:40,  1.85it/s] 81%|████████  | 11752/14596 [2:24:52<25:41,  1.85it/s] 81%|████████  | 11760/14596 [2:24:56<25:29,  1.85it/s] 81%|████████  | 11768/14596 [2:25:00<25:30,  1.85it/s] 81%|████████  | 11776/14596 [2:25:05<25:30,  1.84it/s] 81%|████████  | 11784/14596 [2:25:09<25:17,  1.85it/s] 81%|████████  | 11792/14596 [2:25:13<25:11,  1.85it/s] 81%|████████  | 11800/14596 [2:25:17<25:05,  1.86it/s] 81%|████████  | 11808/14596 [2:25:22<25:03,  1.85it/s] 81%|████████  | 11816/14596 [2:25:26<24:54,  1.86it/s] 81%|████████  | 11824/14596 [2:25:30<25:06,  1.84it/s] 81%|████████  | 11832/14596 [2:25:35<25:12,  1.83it/s] 81%|████████  | 11840/14596 [2:25:39<25:25,  1.81it/s] 81%|████████  | 11848/14596 [2:25:44<25:30,  1.80it/s] 81%|████████  | 11856/14596 [2:25:48<25:28,  1.79it/s] 81%|████████▏ | 11864/14596 [2:25:53<25:31,  1.78it/s] 81%|████████▏ | 11872/14596 [2:25:58<25:30,  1.78it/s] 81%|████████▏ | 11880/14596 [2:26:02<25:26,  1.78it/s] 81%|████████▏ | 11888/14596 [2:26:06<25:01,  1.80it/s] 82%|████████▏ | 11896/14596 [2:26:11<24:44,  1.82it/s] 82%|████████▏ | 11904/14596 [2:26:15<24:29,  1.83it/s] 82%|████████▏ | 11912/14596 [2:26:19<24:09,  1.85it/s] 82%|████████▏ | 11920/14596 [2:26:23<24:03,  1.85it/s] 82%|████████▏ | 11928/14596 [2:26:28<23:56,  1.86it/s] 82%|████████▏ | 11936/14596 [2:26:32<23:49,  1.86it/s] 82%|████████▏ | 11944/14596 [2:26:36<23:44,  1.86it/s] 82%|████████▏ | 11952/14596 [2:26:41<23:37,  1.86it/s] 82%|████████▏ | 11960/14596 [2:26:45<23:27,  1.87it/s] 82%|████████▏ | 11968/14596 [2:26:49<23:21,  1.87it/s] 82%|████████▏ | 11976/14596 [2:26:53<23:18,  1.87it/s] 82%|████████▏ | 11984/14596 [2:26:58<23:11,  1.88it/s] 82%|████████▏ | 11992/14596 [2:27:02<23:20,  1.86it/s] 82%|████████▏ | 12000/14596 [2:27:06<23:24,  1.85it/s] 82%|████████▏ | 12008/14596 [2:27:11<23:27,  1.84it/s] 82%|████████▏ | 12016/14596 [2:27:15<23:29,  1.83it/s] 82%|████████▏ | 12024/14596 [2:27:20<23:26,  1.83it/s] 82%|████████▏ | 12032/14596 [2:27:24<23:28,  1.82it/s] 82%|████████▏ | 12040/14596 [2:27:28<23:26,  1.82it/s] 83%|████████▎ | 12048/14596 [2:27:33<23:14,  1.83it/s] 83%|████████▎ | 12056/14596 [2:27:37<22:56,  1.85it/s] 83%|████████▎ | 12064/14596 [2:27:41<22:39,  1.86it/s] 83%|████████▎ | 12072/14596 [2:27:45<22:27,  1.87it/s] 83%|████████▎ | 12080/14596 [2:27:50<22:21,  1.88it/s] 83%|████████▎ | 12088/14596 [2:27:54<22:11,  1.88it/s] 83%|████████▎ | 12096/14596 [2:27:58<22:06,  1.88it/s] 83%|████████▎ | 12104/14596 [2:28:02<22:02,  1.88it/s] 83%|████████▎ | 12112/14596 [2:28:07<21:53,  1.89it/s] 83%|████████▎ | 12120/14596 [2:28:11<21:50,  1.89it/s] 83%|████████▎ | 12128/14596 [2:28:15<21:43,  1.89it/s] 83%|████████▎ | 12136/14596 [2:28:19<21:48,  1.88it/s] 83%|████████▎ | 12144/14596 [2:28:24<21:53,  1.87it/s] 83%|████████▎ | 12152/14596 [2:28:28<21:57,  1.85it/s] 83%|████████▎ | 12160/14596 [2:28:32<22:05,  1.84it/s] 83%|████████▎ | 12168/14596 [2:28:37<22:04,  1.83it/s] 83%|████████▎ | 12176/14596 [2:28:41<22:05,  1.83it/s] 83%|████████▎ | 12184/14596 [2:28:46<22:02,  1.82it/s] 84%|████████▎ | 12192/14596 [2:28:50<22:00,  1.82it/s] 84%|████████▎ | 12200/14596 [2:28:54<21:38,  1.84it/s] 84%|████████▎ | 12208/14596 [2:28:59<21:27,  1.85it/s] 84%|████████▎ | 12216/14596 [2:29:03<21:13,  1.87it/s] 84%|████████▎ | 12224/14596 [2:29:07<20:56,  1.89it/s] 84%|████████▍ | 12232/14596 [2:29:11<20:50,  1.89it/s] 84%|████████▍ | 12240/14596 [2:29:15<20:43,  1.89it/s] 84%|████████▍ | 12248/14596 [2:29:20<20:35,  1.90it/s] 84%|████████▍ | 12256/14596 [2:29:24<20:32,  1.90it/s] 84%|████████▍ | 12264/14596 [2:29:28<20:24,  1.91it/s] 84%|████████▍ | 12272/14596 [2:29:32<20:12,  1.92it/s] 84%|████████▍ | 12280/14596 [2:29:36<20:12,  1.91it/s] 84%|████████▍ | 12288/14596 [2:29:40<20:10,  1.91it/s] 84%|████████▍ | 12296/14596 [2:29:45<20:23,  1.88it/s] 84%|████████▍ | 12304/14596 [2:29:49<20:31,  1.86it/s] 84%|████████▍ | 12312/14596 [2:29:54<20:31,  1.85it/s] 84%|████████▍ | 12320/14596 [2:29:58<20:30,  1.85it/s] 84%|████████▍ | 12328/14596 [2:30:02<20:25,  1.85it/s] 85%|████████▍ | 12336/14596 [2:30:07<20:23,  1.85it/s] 85%|████████▍ | 12344/14596 [2:30:11<20:20,  1.85it/s] 85%|████████▍ | 12352/14596 [2:30:15<20:08,  1.86it/s] 85%|████████▍ | 12360/14596 [2:30:19<19:54,  1.87it/s] 85%|████████▍ | 12368/14596 [2:30:23<19:32,  1.90it/s] 85%|████████▍ | 12376/14596 [2:30:28<19:26,  1.90it/s] 85%|████████▍ | 12384/14596 [2:30:32<19:19,  1.91it/s] 85%|████████▍ | 12392/14596 [2:30:36<19:02,  1.93it/s] 85%|████████▍ | 12400/14596 [2:30:40<19:02,  1.92it/s] 85%|████████▌ | 12408/14596 [2:30:44<18:53,  1.93it/s] 85%|████████▌ | 12416/14596 [2:30:48<18:42,  1.94it/s] 85%|████████▌ | 12424/14596 [2:30:52<18:39,  1.94it/s] 85%|████████▌ | 12432/14596 [2:30:57<18:45,  1.92it/s] 85%|████████▌ | 12440/14596 [2:31:01<18:57,  1.90it/s] 85%|████████▌ | 12448/14596 [2:31:05<18:57,  1.89it/s] 85%|████████▌ | 12456/14596 [2:31:10<19:04,  1.87it/s] 85%|████████▌ | 12464/14596 [2:31:14<19:01,  1.87it/s] 85%|████████▌ | 12472/14596 [2:31:18<18:58,  1.87it/s] 86%|████████▌ | 12480/14596 [2:31:22<18:53,  1.87it/s] 86%|████████▌ | 12488/14596 [2:31:27<18:47,  1.87it/s] 86%|████████▌ | 12496/14596 [2:31:31<18:37,  1.88it/s] 86%|████████▌ | 12504/14596 [2:31:35<18:22,  1.90it/s] 86%|████████▌ | 12512/14596 [2:31:39<18:06,  1.92it/s] 86%|████████▌ | 12520/14596 [2:31:43<17:58,  1.92it/s] 86%|████████▌ | 12528/14596 [2:31:47<17:50,  1.93it/s] 86%|████████▌ | 12536/14596 [2:31:51<17:42,  1.94it/s] 86%|████████▌ | 12544/14596 [2:31:56<17:36,  1.94it/s] 86%|████████▌ | 12552/14596 [2:32:00<17:30,  1.95it/s] 86%|████████▌ | 12560/14596 [2:32:04<17:27,  1.94it/s] 86%|████████▌ | 12568/14596 [2:32:08<17:24,  1.94it/s] 86%|████████▌ | 12576/14596 [2:32:12<17:26,  1.93it/s] 86%|████████▌ | 12584/14596 [2:32:16<17:35,  1.91it/s] 86%|████████▋ | 12592/14596 [2:32:21<17:36,  1.90it/s] 86%|████████▋ | 12600/14596 [2:32:25<17:36,  1.89it/s] 86%|████████▋ | 12608/14596 [2:32:29<17:33,  1.89it/s] 86%|████████▋ | 12616/14596 [2:32:34<17:35,  1.88it/s] 86%|████████▋ | 12624/14596 [2:32:38<17:24,  1.89it/s] 87%|████████▋ | 12632/14596 [2:32:42<17:26,  1.88it/s] 87%|████████▋ | 12640/14596 [2:32:46<17:10,  1.90it/s] 87%|████████▋ | 12648/14596 [2:32:50<16:53,  1.92it/s] 87%|████████▋ | 12656/14596 [2:32:54<16:42,  1.94it/s] 87%|████████▋ | 12664/14596 [2:32:58<16:30,  1.95it/s] 87%|████████▋ | 12672/14596 [2:33:02<16:16,  1.97it/s] 87%|████████▋ | 12680/14596 [2:33:06<16:16,  1.96it/s] 87%|████████▋ | 12688/14596 [2:33:10<16:11,  1.96it/s] 87%|████████▋ | 12696/14596 [2:33:14<16:01,  1.98it/s] 87%|████████▋ | 12704/14596 [2:33:19<16:08,  1.95it/s] 87%|████████▋ | 12712/14596 [2:33:23<16:13,  1.93it/s] 87%|████████▋ | 12720/14596 [2:33:27<16:13,  1.93it/s] 87%|████████▋ | 12728/14596 [2:33:31<16:17,  1.91it/s] 87%|████████▋ | 12736/14596 [2:33:36<16:18,  1.90it/s] 87%|████████▋ | 12744/14596 [2:33:40<16:13,  1.90it/s] 87%|████████▋ | 12752/14596 [2:33:44<16:10,  1.90it/s] 87%|████████▋ | 12760/14596 [2:33:48<16:08,  1.90it/s] 87%|████████▋ | 12768/14596 [2:33:52<16:01,  1.90it/s] 88%|████████▊ | 12776/14596 [2:33:57<15:55,  1.90it/s] 88%|████████▊ | 12784/14596 [2:34:01<15:45,  1.92it/s] 88%|████████▊ | 12792/14596 [2:34:05<15:28,  1.94it/s] 88%|████████▊ | 12800/14596 [2:34:09<15:17,  1.96it/s] 88%|████████▊ | 12808/14596 [2:34:13<15:12,  1.96it/s] 88%|████████▊ | 12816/14596 [2:34:17<14:58,  1.98it/s] 88%|████████▊ | 12824/14596 [2:34:21<14:56,  1.98it/s] 88%|████████▊ | 12832/14596 [2:34:25<14:50,  1.98it/s] 88%|████████▊ | 12840/14596 [2:34:29<14:46,  1.98it/s] 88%|████████▊ | 12848/14596 [2:34:33<14:53,  1.96it/s] 88%|████████▊ | 12856/14596 [2:34:37<14:58,  1.94it/s] 88%|████████▊ | 12864/14596 [2:34:41<14:55,  1.93it/s] 88%|████████▊ | 12872/14596 [2:34:46<14:58,  1.92it/s] 88%|████████▊ | 12880/14596 [2:34:50<14:56,  1.91it/s] 88%|████████▊ | 12888/14596 [2:34:54<14:57,  1.90it/s] 88%|████████▊ | 12896/14596 [2:34:58<14:58,  1.89it/s] 88%|████████▊ | 12904/14596 [2:35:03<14:55,  1.89it/s] 88%|████████▊ | 12912/14596 [2:35:07<14:46,  1.90it/s] 89%|████████▊ | 12920/14596 [2:35:11<14:34,  1.92it/s] 89%|████████▊ | 12928/14596 [2:35:15<14:25,  1.93it/s] 89%|████████▊ | 12936/14596 [2:35:19<14:12,  1.95it/s] 89%|████████▊ | 12944/14596 [2:35:23<14:03,  1.96it/s] 89%|████████▊ | 12952/14596 [2:35:27<14:00,  1.96it/s] 89%|████████▉ | 12960/14596 [2:35:31<13:53,  1.96it/s] 89%|████████▉ | 12968/14596 [2:35:35<13:46,  1.97it/s] 89%|████████▉ | 12976/14596 [2:35:39<13:41,  1.97it/s] 89%|████████▉ | 12984/14596 [2:35:43<13:39,  1.97it/s] 89%|████████▉ | 12992/14596 [2:35:47<13:39,  1.96it/s] 89%|████████▉ | 13000/14596 [2:35:52<13:41,  1.94it/s] 89%|████████▉ | 13008/14596 [2:35:56<13:43,  1.93it/s] 89%|████████▉ | 13016/14596 [2:36:00<13:44,  1.92it/s] 89%|████████▉ | 13024/14596 [2:36:04<13:40,  1.92it/s] 89%|████████▉ | 13032/14596 [2:36:09<13:39,  1.91it/s] 89%|████████▉ | 13040/14596 [2:36:13<13:36,  1.90it/s] 89%|████████▉ | 13048/14596 [2:36:17<13:23,  1.93it/s] 89%|████████▉ | 13056/14596 [2:36:21<13:11,  1.95it/s] 90%|████████▉ | 13064/14596 [2:36:25<13:00,  1.96it/s] 90%|████████▉ | 13072/14596 [2:36:29<12:56,  1.96it/s] 90%|████████▉ | 13080/14596 [2:36:33<12:49,  1.97it/s] 90%|████████▉ | 13088/14596 [2:36:37<12:44,  1.97it/s] 90%|████████▉ | 13096/14596 [2:36:41<12:37,  1.98it/s] 90%|████████▉ | 13104/14596 [2:36:45<12:33,  1.98it/s] 90%|████████▉ | 13112/14596 [2:36:49<12:28,  1.98it/s] 90%|████████▉ | 13120/14596 [2:36:53<12:24,  1.98it/s] 90%|████████▉ | 13128/14596 [2:36:57<12:26,  1.97it/s] 90%|████████▉ | 13136/14596 [2:37:01<12:21,  1.97it/s] 90%|█████████ | 13144/14596 [2:37:05<12:23,  1.95it/s] 90%|█████████ | 13152/14596 [2:37:10<12:25,  1.94it/s] 90%|█████████ | 13160/14596 [2:37:14<12:23,  1.93it/s] 90%|█████████ | 13168/14596 [2:37:18<12:10,  1.95it/s] 90%|█████████ | 13176/14596 [2:37:22<12:04,  1.96it/s] 90%|█████████ | 13184/14596 [2:37:26<11:47,  2.00it/s] 90%|█████████ | 13192/14596 [2:37:30<11:40,  2.00it/s] 90%|█████████ | 13200/14596 [2:37:34<11:41,  1.99it/s] 90%|█████████ | 13208/14596 [2:37:38<11:32,  2.00it/s] 91%|█████████ | 13216/14596 [2:37:42<11:26,  2.01it/s] 91%|█████████ | 13224/14596 [2:37:46<11:28,  1.99it/s] 91%|█████████ | 13232/14596 [2:37:50<11:25,  1.99it/s] 91%|█████████ | 13240/14596 [2:37:54<11:22,  1.99it/s] 91%|█████████ | 13248/14596 [2:37:58<11:15,  2.00it/s] 91%|█████████ | 13256/14596 [2:38:02<11:09,  2.00it/s] 91%|█████████ | 13264/14596 [2:38:06<11:06,  2.00it/s] 91%|█████████ | 13272/14596 [2:38:10<11:03,  1.99it/s] 91%|█████████ | 13280/14596 [2:38:14<11:00,  1.99it/s] 91%|█████████ | 13288/14596 [2:38:18<10:53,  2.00it/s] 91%|█████████ | 13296/14596 [2:38:22<10:41,  2.03it/s] 91%|█████████ | 13304/14596 [2:38:25<10:32,  2.04it/s] 91%|█████████ | 13312/14596 [2:38:29<10:28,  2.04it/s] 91%|█████████▏| 13320/14596 [2:38:33<10:23,  2.04it/s] 91%|█████████▏| 13328/14596 [2:38:37<10:14,  2.06it/s] 91%|█████████▏| 13336/14596 [2:38:41<10:09,  2.07it/s] 91%|█████████▏| 13344/14596 [2:38:45<10:08,  2.06it/s] 91%|█████████▏| 13352/14596 [2:38:49<10:07,  2.05it/s] 92%|█████████▏| 13360/14596 [2:38:53<10:07,  2.03it/s] 92%|█████████▏| 13368/14596 [2:38:57<10:09,  2.02it/s] 92%|█████████▏| 13376/14596 [2:39:01<10:06,  2.01it/s] 92%|█████████▏| 13384/14596 [2:39:05<10:04,  2.01it/s] 92%|█████████▏| 13392/14596 [2:39:09<09:55,  2.02it/s] 92%|█████████▏| 13400/14596 [2:39:13<09:44,  2.05it/s] 92%|█████████▏| 13408/14596 [2:39:16<09:37,  2.06it/s] 92%|█████████▏| 13416/14596 [2:39:20<09:29,  2.07it/s] 92%|█████████▏| 13424/14596 [2:39:24<09:25,  2.07it/s] 92%|█████████▏| 13432/14596 [2:39:28<09:17,  2.09it/s] 92%|█████████▏| 13440/14596 [2:39:32<09:14,  2.08it/s] 92%|█████████▏| 13448/14596 [2:39:36<09:19,  2.05it/s] 92%|█████████▏| 13456/14596 [2:39:40<09:18,  2.04it/s] 92%|█████████▏| 13464/14596 [2:39:44<09:17,  2.03it/s] 92%|█████████▏| 13472/14596 [2:39:48<09:15,  2.02it/s] 92%|█████████▏| 13480/14596 [2:39:52<09:12,  2.02it/s] 92%|█████████▏| 13488/14596 [2:39:56<09:09,  2.02it/s] 92%|█████████▏| 13496/14596 [2:39:59<09:02,  2.03it/s] 93%|█████████▎| 13504/14596 [2:40:03<08:52,  2.05it/s] 93%|█████████▎| 13512/14596 [2:40:07<08:45,  2.06it/s] 93%|█████████▎| 13520/14596 [2:40:11<08:36,  2.08it/s] 93%|█████████▎| 13528/14596 [2:40:15<08:28,  2.10it/s] 93%|█████████▎| 13536/14596 [2:40:18<08:22,  2.11it/s] 93%|█████████▎| 13544/14596 [2:40:22<08:21,  2.10it/s] 93%|█████████▎| 13552/14596 [2:40:26<08:23,  2.08it/s] 93%|█████████▎| 13560/14596 [2:40:30<08:26,  2.04it/s] 93%|█████████▎| 13568/14596 [2:40:34<08:21,  2.05it/s] 93%|█████████▎| 13576/14596 [2:40:38<08:21,  2.03it/s] 93%|█████████▎| 13584/14596 [2:40:42<08:17,  2.04it/s] 93%|█████████▎| 13592/14596 [2:40:46<08:11,  2.04it/s] 93%|█████████▎| 13600/14596 [2:40:50<08:06,  2.05it/s] 93%|█████████▎| 13608/14596 [2:40:54<07:57,  2.07it/s] 93%|█████████▎| 13616/14596 [2:40:57<07:50,  2.08it/s] 93%|█████████▎| 13624/14596 [2:41:01<07:44,  2.09it/s] 93%|█████████▎| 13632/14596 [2:41:05<07:35,  2.12it/s] 93%|█████████▎| 13640/14596 [2:41:09<07:30,  2.12it/s] 94%|█████████▎| 13648/14596 [2:41:12<07:31,  2.10it/s] 94%|█████████▎| 13656/14596 [2:41:16<07:29,  2.09it/s] 94%|█████████▎| 13664/14596 [2:41:20<07:28,  2.08it/s] 94%|█████████▎| 13672/14596 [2:41:24<07:26,  2.07it/s] 94%|█████████▎| 13680/14596 [2:41:28<07:24,  2.06it/s] 94%|█████████▍| 13688/14596 [2:41:32<07:18,  2.07it/s] 94%|█████████▍| 13696/14596 [2:41:36<07:14,  2.07it/s] 94%|█████████▍| 13704/14596 [2:41:40<07:10,  2.07it/s] 94%|█████████▍| 13712/14596 [2:41:43<07:04,  2.08it/s] 94%|█████████▍| 13720/14596 [2:41:47<06:56,  2.10it/s] 94%|█████████▍| 13728/14596 [2:41:51<06:49,  2.12it/s] 94%|█████████▍| 13736/14596 [2:41:54<06:42,  2.14it/s] 94%|█████████▍| 13744/14596 [2:41:58<06:41,  2.12it/s] 94%|█████████▍| 13752/14596 [2:42:02<06:39,  2.11it/s] 94%|█████████▍| 13760/14596 [2:42:06<06:40,  2.09it/s] 94%|█████████▍| 13768/14596 [2:42:10<06:34,  2.10it/s] 94%|█████████▍| 13776/14596 [2:42:14<06:31,  2.09it/s] 94%|█████████▍| 13784/14596 [2:42:17<06:25,  2.10it/s] 94%|█████████▍| 13792/14596 [2:42:21<06:19,  2.12it/s] 95%|█████████▍| 13800/14596 [2:42:25<06:17,  2.11it/s] 95%|█████████▍| 13808/14596 [2:42:29<06:14,  2.10it/s] 95%|█████████▍| 13816/14596 [2:42:33<06:10,  2.11it/s] 95%|█████████▍| 13824/14596 [2:42:36<06:07,  2.10it/s] 95%|█████████▍| 13832/14596 [2:42:40<06:03,  2.10it/s] 95%|█████████▍| 13840/14596 [2:42:44<05:58,  2.11it/s] 95%|█████████▍| 13848/14596 [2:42:48<05:55,  2.11it/s] 95%|█████████▍| 13856/14596 [2:42:52<05:51,  2.10it/s] 95%|█████████▍| 13864/14596 [2:42:56<05:50,  2.09it/s] 95%|█████████▌| 13872/14596 [2:42:59<05:46,  2.09it/s] 95%|█████████▌| 13880/14596 [2:43:03<05:35,  2.13it/s] 95%|█████████▌| 13888/14596 [2:43:07<05:28,  2.15it/s] 95%|█████████▌| 13896/14596 [2:43:10<05:26,  2.14it/s] 95%|█████████▌| 13904/14596 [2:43:14<05:18,  2.17it/s] 95%|█████████▌| 13912/14596 [2:43:17<05:12,  2.19it/s] 95%|█████████▌| 13920/14596 [2:43:21<05:12,  2.16it/s] 95%|█████████▌| 13928/14596 [2:43:25<05:10,  2.15it/s] 95%|█████████▌| 13936/14596 [2:43:29<05:05,  2.16it/s] 96%|█████████▌| 13944/14596 [2:43:32<05:03,  2.15it/s] 96%|█████████▌| 13952/14596 [2:43:36<05:00,  2.14it/s] 96%|█████████▌| 13960/14596 [2:43:40<04:59,  2.13it/s] 96%|█████████▌| 13968/14596 [2:43:44<04:55,  2.13it/s] 96%|█████████▌| 13976/14596 [2:43:47<04:48,  2.15it/s] 96%|█████████▌| 13984/14596 [2:43:51<04:40,  2.18it/s] 96%|█████████▌| 13992/14596 [2:43:55<04:35,  2.19it/s] 96%|█████████▌| 14000/14596 [2:43:58<04:31,  2.19it/s] 96%|█████████▌| 14008/14596 [2:44:02<04:23,  2.23it/s] 96%|█████████▌| 14016/14596 [2:44:05<04:20,  2.23it/s] 96%|█████████▌| 14024/14596 [2:44:09<04:21,  2.19it/s] 96%|█████████▌| 14032/14596 [2:44:13<04:18,  2.18it/s] 96%|█████████▌| 14040/14596 [2:44:16<04:16,  2.17it/s] 96%|█████████▌| 14048/14596 [2:44:20<04:14,  2.16it/s] 96%|█████████▋| 14056/14596 [2:44:24<04:08,  2.17it/s] 96%|█████████▋| 14064/14596 [2:44:28<04:04,  2.17it/s] 96%|█████████▋| 14072/14596 [2:44:31<04:00,  2.18it/s] 96%|█████████▋| 14080/14596 [2:44:35<03:52,  2.22it/s] 97%|█████████▋| 14088/14596 [2:44:38<03:46,  2.24it/s] 97%|█████████▋| 14096/14596 [2:44:42<03:42,  2.25it/s] 97%|█████████▋| 14104/14596 [2:44:45<03:41,  2.22it/s] 97%|█████████▋| 14112/14596 [2:44:49<03:38,  2.21it/s] 97%|█████████▋| 14120/14596 [2:44:53<03:36,  2.20it/s] 97%|█████████▋| 14128/14596 [2:44:56<03:32,  2.20it/s] 97%|█████████▋| 14136/14596 [2:45:00<03:28,  2.21it/s] 97%|█████████▋| 14144/14596 [2:45:04<03:24,  2.21it/s] 97%|█████████▋| 14152/14596 [2:45:07<03:19,  2.23it/s] 97%|█████████▋| 14160/14596 [2:45:11<03:15,  2.23it/s] 97%|█████████▋| 14168/14596 [2:45:14<03:12,  2.22it/s] 97%|█████████▋| 14176/14596 [2:45:18<03:09,  2.22it/s] 97%|█████████▋| 14184/14596 [2:45:22<03:05,  2.22it/s] 97%|█████████▋| 14192/14596 [2:45:25<03:02,  2.21it/s] 97%|█████████▋| 14200/14596 [2:45:29<02:55,  2.26it/s] 97%|█████████▋| 14208/14596 [2:45:32<02:49,  2.29it/s] 97%|█████████▋| 14216/14596 [2:45:36<02:47,  2.27it/s] 97%|█████████▋| 14224/14596 [2:45:39<02:42,  2.29it/s] 98%|█████████▊| 14232/14596 [2:45:42<02:38,  2.29it/s] 98%|█████████▊| 14240/14596 [2:45:46<02:35,  2.28it/s] 98%|█████████▊| 14248/14596 [2:45:49<02:31,  2.29it/s] 98%|█████████▊| 14256/14596 [2:45:53<02:29,  2.27it/s] 98%|█████████▊| 14264/14596 [2:45:57<02:27,  2.26it/s] 98%|█████████▊| 14272/14596 [2:46:00<02:23,  2.26it/s] 98%|█████████▊| 14280/14596 [2:46:04<02:17,  2.29it/s] 98%|█████████▊| 14288/14596 [2:46:07<02:12,  2.32it/s] 98%|█████████▊| 14296/14596 [2:46:10<02:07,  2.36it/s] 98%|█████████▊| 14304/14596 [2:46:13<02:03,  2.37it/s] 98%|█████████▊| 14312/14596 [2:46:17<02:01,  2.34it/s] 98%|█████████▊| 14320/14596 [2:46:21<01:59,  2.31it/s] 98%|█████████▊| 14328/14596 [2:46:24<01:56,  2.30it/s] 98%|█████████▊| 14336/14596 [2:46:27<01:52,  2.31it/s] 98%|█████████▊| 14344/14596 [2:46:31<01:48,  2.33it/s] 98%|█████████▊| 14352/14596 [2:46:34<01:44,  2.34it/s] 98%|█████████▊| 14360/14596 [2:46:38<01:40,  2.34it/s] 98%|█████████▊| 14368/14596 [2:46:41<01:37,  2.34it/s] 98%|█████████▊| 14376/14596 [2:46:44<01:34,  2.34it/s] 99%|█████████▊| 14384/14596 [2:46:48<01:31,  2.33it/s] 99%|█████████▊| 14392/14596 [2:46:51<01:25,  2.39it/s] 99%|█████████▊| 14400/14596 [2:46:54<01:20,  2.42it/s] 99%|█████████▊| 14408/14596 [2:46:58<01:18,  2.41it/s] 99%|█████████▉| 14416/14596 [2:47:01<01:15,  2.40it/s] 99%|█████████▉| 14424/14596 [2:47:04<01:11,  2.41it/s] 99%|█████████▉| 14432/14596 [2:47:08<01:08,  2.39it/s] 99%|█████████▉| 14440/14596 [2:47:11<01:05,  2.39it/s] 99%|█████████▉| 14448/14596 [2:47:14<01:01,  2.40it/s] 99%|█████████▉| 14456/14596 [2:47:18<00:57,  2.43it/s] 99%|█████████▉| 14464/14596 [2:47:21<00:53,  2.46it/s] 99%|█████████▉| 14472/14596 [2:47:24<00:49,  2.49it/s] 99%|█████████▉| 14480/14596 [2:47:27<00:47,  2.45it/s] 99%|█████████▉| 14488/14596 [2:47:31<00:44,  2.44it/s] 99%|█████████▉| 14496/14596 [2:47:34<00:40,  2.45it/s] 99%|█████████▉| 14504/14596 [2:47:37<00:37,  2.47it/s] 99%|█████████▉| 14512/14596 [2:47:40<00:33,  2.48it/s] 99%|█████████▉| 14520/14596 [2:47:43<00:30,  2.48it/s]100%|█████████▉| 14528/14596 [2:47:47<00:27,  2.48it/s]100%|█████████▉| 14536/14596 [2:47:50<00:24,  2.49it/s]100%|█████████▉| 14544/14596 [2:47:53<00:20,  2.56it/s]100%|█████████▉| 14552/14596 [2:47:56<00:16,  2.59it/s]100%|█████████▉| 14560/14596 [2:47:59<00:13,  2.59it/s]100%|█████████▉| 14568/14596 [2:48:02<00:10,  2.61it/s]100%|█████████▉| 14576/14596 [2:48:05<00:07,  2.59it/s]100%|█████████▉| 14584/14596 [2:48:08<00:04,  2.58it/s]100%|█████████▉| 14592/14596 [2:48:11<00:01,  2.63it/s]100%|██████████| 14596/14596 [2:48:11<00:00,  1.45it/s]
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/root/.local/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
fatal: not a git repository (or any of the parent directories): .git
{'hellaswag_el': {'alias': 'hellaswag_el', 'acc,none': 0.3897645650438947, 'acc_stderr,none': 0.004871368939703113, 'acc_norm,none': 0.49511173184357543, 'acc_norm_stderr,none': 0.004994021216739113}, 'hellaswag_hu': {'alias': 'hellaswag_hu', 'acc,none': 0.3747121394889791, 'acc_stderr,none': 0.00506919603198379, 'acc_norm,none': 0.47779361772124135, 'acc_norm_stderr,none': 0.005231081252997762}, 'hellaswag_tr': {'alias': 'hellaswag_tr', 'acc,none': 0.37675530325664774, 'acc_stderr,none': 0.0048360649680255245, 'acc_norm,none': 0.47843840254954684, 'acc_norm_stderr,none': 0.004985387986709674}}
